2016-11-15 13:21:56 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:21:56 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:21:56 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:21:56 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:21:56 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:21:56 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:21:56 [scrapy] INFO: Spider opened
2016-11-15 13:21:56 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:22:00 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:22:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 507,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 84757,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 22, 0, 515166),
 'item_scraped_count': 140,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 11, 15, 5, 21, 56, 902065)}
2016-11-15 13:22:00 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:29:12 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:29:12 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:29:12 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:29:12 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:29:12 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:29:12 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:29:12 [scrapy] INFO: Spider opened
2016-11-15 13:29:12 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:29:12 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:29:12 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 507,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 84757,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 29, 12, 866671),
 'item_scraped_count': 140,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 11, 15, 5, 29, 12, 227550)}
2016-11-15 13:29:12 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:29:48 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:29:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:29:49 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:29:49 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:29:49 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:29:49 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:29:49 [scrapy] INFO: Spider opened
2016-11-15 13:29:49 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u63d0\u540d\u4eba\u53ca\u5019\u9009\u4eba\u58f0\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000862',
 'secName': u'\u94f6\u661f\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 11, 45, 2),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300549',
 'secName': u'\u4f18\u5fb7\u7cbe\u5bc6',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 52),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u300a\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u884c\u653f\u8bb8\u53ef\u9879\u76ee\u5ba1\u67e5\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u901a\u77e5\u4e66\u300b\u4e4b\u53cd\u9988\u610f\u89c1\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u56de\u590d',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u82cf\u5dde\u79d1\u73af\u73af\u4fdd\u79d1\u6280\u6709\u9650\u516c\u53f82014\u5e74-2016\u5e749\u6708\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u72ec\u7acb\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u9605\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u676d\u5dde\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u4e4b\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000633',
 'secName': u'*ST\u5408\u91d1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 53),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u4e2d\u4f26\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002655',
 'secName': u'\u5171\u8fbe\u7535\u58f0',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 47),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002262',
 'secName': u'\u6069\u534e\u836f\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 31),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u8fdb\u884c\u80a1\u7968\u8d28\u62bc\u5f0f\u56de\u8d2d\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002458',
 'secName': u'\u76ca\u751f\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 24),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u7ea6\u5b9a\u8d2d\u56de\u5f0f\u8bc1\u5238\u4ea4\u6613\u5230\u671f\u8d2d\u56de\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002471',
 'secName': u'\u4e2d\u8d85\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 9),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d77\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f82015\u5e74\u5ea6\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5174\u4e1a\u56fd\u9645\u4fe1\u6258\u6709\u9650\u516c\u53f8\u5174\u4e1a\u4fe1\u6258-\u4f17\u4fe1\u65c5\u6e381\u53f7\u5458\u5de5\u6301\u80a1\u96c6\u5408\u8d44\u91d1\u4fe1\u6258\u8ba1\u5212\u8d44\u91d1\u4fe1\u6258\u5408\u540c',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002707',
 'secName': u'\u4f17\u4fe1\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 11, 41),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u6c5f\u5929\u518c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u4fe1\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u6301\u7eed\u7763\u5bfc\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002729',
 'secName': u'\u597d\u5229\u6765',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 39),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u96c4\u53bf\u7ecf\u6d4e\u5f00\u53d1\u533a\u96c6\u4e2d\u4f9b\u70ed\u9879\u76ee\u83b7\u5f97\u6838\u51c6\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002616',
 'secName': u'\u957f\u9752\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 32),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300496',
 'secName': u'\u4e2d\u79d1\u521b\u8fbe',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 29),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u9009\u4e3e\u4ea7\u751f\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u83b7\u5f97\u201c\u56fd\u5bb6\u6280\u672f\u521b\u65b0\u793a\u8303\u4f01\u4e1a\u201d\u8ba4\u5b9a\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300066',
 'secName': u'\u4e09\u5ddd\u667a\u6167',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 19),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002528',
 'secName': u'\u82f1\u98de\u62d3',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u4e8b\u9879\u83b7\u5f97\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u6838\u51c6\u6279\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u7684\u4fee\u8ba2\u8bf4\u660e\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u6458\u8981',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\uff08\u4fee\u8ba2\u7a3f\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u8bf4\u660e\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u53d1\u884c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u6295\u8d44\u98ce\u9669\u7279\u522b\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e03\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u56db\u6b21\u4e34\u65f6\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5ef6\u671f\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535A',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5bf9\u5916\u6295\u8d44\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002646',
 'secName': u'\u9752\u9752\u7a1e\u9152',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e94\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5168\u8d44\u5b50\u516c\u53f8\u5b8c\u6210\u5de5\u5546\u53d8\u66f4\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u90e8\u5206\u6fc0\u52b1\u5bf9\u8c61\u540d\u5355',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u5341\u4e94\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5bf9\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u53d1\u8868\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u95ee\u8be2\u51fd\u56de\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002443',
 'secName': u'\u91d1\u6d32\u7ba1\u9053',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u610f\u5411\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u521d\u6b65\u8be2\u4ef7\u53ca\u63a8\u4ecb\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u63d0\u793a\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u56db\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2013\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u5173\u4e8e\u6838\u51c6\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u6279\u590d',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u975e\u7ecf\u5e38\u6027\u635f\u76ca\u7684\u4e13\u9879\u5ba1\u6838\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u56db\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u516d\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e94\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e09\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u610f\u89c1\u4e66\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u63a7\u80a1\u80a1\u4e1c\u53ca\u5b9e\u9645\u63a7\u5236\u4eba\u5bf9\u62db\u80a1\u8bf4\u660e\u4e66\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u8bbe\u7acb\u4ee5\u6765\u80a1\u672c\u6f14\u53d8\u60c5\u51b5\u7684\u8bf4\u660e\u53ca\u5176\u8463\u4e8b\u3001\u76d1\u4e8b\u3001\u9ad8\u7ea7\u7ba1\u7406\u4eba\u5458\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5185\u90e8\u63a7\u5236\u9274\u8bc1\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u53f8\u7ae0\u7a0b\uff08\u8349\u6848\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u4ea4\u6240\u95ee\u8be2\u51fd\u30102016\u3011\u7b2c469\u53f7\u7684\u56de\u590d\u8bf4\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u56fd\u67ab\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e2d\u5c0f\u677f\u516c\u53f8\u7ba1\u7406\u90e8\u300a\u5173\u4e8e\u5bf9\u5e7f\u4e1c\u56fd\u76db\u91d1\u63a7\u96c6\u56e2\u80a1\u4efd\u6709\u9650\u516c\u53f8\u7684\u95ee\u8be2\u51fd\u300b\u76f8\u5173\u4e8b\u9879\u7684\u4e13\u9879\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u6743\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000820',
 'secName': u'\u91d1\u57ce\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6743\u76ca\u53d8\u52a8\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002316',
 'secName': u'\u952e\u6865\u901a\u8baf',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u8463\u4e8b\u4f1a\u4e8c\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u8f6c\u8ba9\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u76d1\u4e8b\u4f1a\u5341\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u8f6c\u8ba9\u63a7\u80a1\u5b50\u516c\u53f8\u80a1\u6743\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u548c\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002497',
 'secName': u'\u96c5\u5316\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u534e\u6cf0\u8054\u5408\u8bc1\u5238\u6709\u9650\u8d23\u4efb\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300556',
 'secName': u'\u4e1d\u8def\u89c6\u89c9',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u62402016\u5e74\u534a\u5e74\u62a5\u95ee\u8be2\u51fd\u7684\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u9879\u76ee\u7533\u8bf7\u6062\u590d\u5ba1\u67e5\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8bc9\u8bbc\u4e8b\u9879\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000571',
 'secName': u'\u65b0\u5927\u6d32\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000807',
 'secName': u'\u4e91\u94dd\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u5f00\u53d1\u884c2016\u5e74\u516c\u53f8\u503a\u5238\uff08\u7b2c\u4e00\u671f\uff09\u53d1\u884c\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000883',
 'secName': u'\u6e56\u5317\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000595',
 'secName': u'\u5b9d\u5854\u5b9e\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b80\u5f0f\u6743\u76ca\u53d8\u52a8\u62a5\u544a\u4e66',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u9009\u4e3e\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u4e4b\u6cd5\u5f8b\u610f\u89c1',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66\uff08\u6458\u8981\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u548c\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u7684\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u73af\u7403\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884cA\u80a1\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u53ca\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u4e4b\u4e13\u9879\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u516c\u544a\u4e66\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u957f\u57ce\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u91d1\u675c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u7684\u80a1\u7968\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e0a\u5e02\u4e4b\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7f51\u4e0a\u6447\u53f7\u4e2d\u7b7e\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300567',
 'secName': u'\u7cbe\u6d4b\u7535\u5b50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u201c11\u51ef\u8fea\u503a\u201d2016\u5e74\u503a\u5238\u4ed8\u606f\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000939',
 'secName': u'\u51ef\u8fea\u751f\u6001',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300559',
 'secName': u'\u4f73\u53d1\u5b89\u6cf0',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u5185\u5e55\u77e5\u60c5\u4eba\u4e70\u5356\u516c\u53f8\u80a1\u7968\u60c5\u51b5\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF" }
2016-11-15 13:29:52 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF" }
2016-11-15 13:29:52 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:29:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 507,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 84757,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 29, 52, 739421),
 'log_count/ERROR': 140,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 11, 15, 5, 29, 49, 86544)}
2016-11-15 13:29:52 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:30:18 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:30:18 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:30:18 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:30:18 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:30:18 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:30:18 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:30:18 [scrapy] INFO: Spider opened
2016-11-15 13:30:18 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u63d0\u540d\u4eba\u53ca\u5019\u9009\u4eba\u58f0\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000862',
 'secName': u'\u94f6\u661f\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 11, 45, 2),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300549',
 'secName': u'\u4f18\u5fb7\u7cbe\u5bc6',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 52),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u300a\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u884c\u653f\u8bb8\u53ef\u9879\u76ee\u5ba1\u67e5\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u901a\u77e5\u4e66\u300b\u4e4b\u53cd\u9988\u610f\u89c1\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u56de\u590d',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u82cf\u5dde\u79d1\u73af\u73af\u4fdd\u79d1\u6280\u6709\u9650\u516c\u53f82014\u5e74-2016\u5e749\u6708\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u72ec\u7acb\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u9605\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u676d\u5dde\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u4e4b\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000633',
 'secName': u'*ST\u5408\u91d1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 53),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u4e2d\u4f26\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002655',
 'secName': u'\u5171\u8fbe\u7535\u58f0',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 47),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002262',
 'secName': u'\u6069\u534e\u836f\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 31),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u8fdb\u884c\u80a1\u7968\u8d28\u62bc\u5f0f\u56de\u8d2d\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002458',
 'secName': u'\u76ca\u751f\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 24),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u7ea6\u5b9a\u8d2d\u56de\u5f0f\u8bc1\u5238\u4ea4\u6613\u5230\u671f\u8d2d\u56de\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002471',
 'secName': u'\u4e2d\u8d85\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 9),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d77\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f82015\u5e74\u5ea6\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5174\u4e1a\u56fd\u9645\u4fe1\u6258\u6709\u9650\u516c\u53f8\u5174\u4e1a\u4fe1\u6258-\u4f17\u4fe1\u65c5\u6e381\u53f7\u5458\u5de5\u6301\u80a1\u96c6\u5408\u8d44\u91d1\u4fe1\u6258\u8ba1\u5212\u8d44\u91d1\u4fe1\u6258\u5408\u540c',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002707',
 'secName': u'\u4f17\u4fe1\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 11, 41),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u6c5f\u5929\u518c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u4fe1\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u6301\u7eed\u7763\u5bfc\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002729',
 'secName': u'\u597d\u5229\u6765',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 39),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u96c4\u53bf\u7ecf\u6d4e\u5f00\u53d1\u533a\u96c6\u4e2d\u4f9b\u70ed\u9879\u76ee\u83b7\u5f97\u6838\u51c6\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002616',
 'secName': u'\u957f\u9752\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 32),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300496',
 'secName': u'\u4e2d\u79d1\u521b\u8fbe',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 29),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u9009\u4e3e\u4ea7\u751f\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u83b7\u5f97\u201c\u56fd\u5bb6\u6280\u672f\u521b\u65b0\u793a\u8303\u4f01\u4e1a\u201d\u8ba4\u5b9a\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300066',
 'secName': u'\u4e09\u5ddd\u667a\u6167',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 19),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002528',
 'secName': u'\u82f1\u98de\u62d3',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u4e8b\u9879\u83b7\u5f97\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u6838\u51c6\u6279\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u7684\u4fee\u8ba2\u8bf4\u660e\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u6458\u8981',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\uff08\u4fee\u8ba2\u7a3f\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u8bf4\u660e\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u53d1\u884c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u6295\u8d44\u98ce\u9669\u7279\u522b\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e03\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u56db\u6b21\u4e34\u65f6\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5ef6\u671f\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535A',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5bf9\u5916\u6295\u8d44\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002646',
 'secName': u'\u9752\u9752\u7a1e\u9152',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e94\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5168\u8d44\u5b50\u516c\u53f8\u5b8c\u6210\u5de5\u5546\u53d8\u66f4\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u90e8\u5206\u6fc0\u52b1\u5bf9\u8c61\u540d\u5355',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u5341\u4e94\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5bf9\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u53d1\u8868\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u95ee\u8be2\u51fd\u56de\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002443',
 'secName': u'\u91d1\u6d32\u7ba1\u9053',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u610f\u5411\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u521d\u6b65\u8be2\u4ef7\u53ca\u63a8\u4ecb\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u63d0\u793a\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u56db\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'2013\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u5173\u4e8e\u6838\u51c6\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u6279\u590d',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u975e\u7ecf\u5e38\u6027\u635f\u76ca\u7684\u4e13\u9879\u5ba1\u6838\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u56db\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u516d\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e94\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e09\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u610f\u89c1\u4e66\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u63a7\u80a1\u80a1\u4e1c\u53ca\u5b9e\u9645\u63a7\u5236\u4eba\u5bf9\u62db\u80a1\u8bf4\u660e\u4e66\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u8bbe\u7acb\u4ee5\u6765\u80a1\u672c\u6f14\u53d8\u60c5\u51b5\u7684\u8bf4\u660e\u53ca\u5176\u8463\u4e8b\u3001\u76d1\u4e8b\u3001\u9ad8\u7ea7\u7ba1\u7406\u4eba\u5458\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5185\u90e8\u63a7\u5236\u9274\u8bc1\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u53f8\u7ae0\u7a0b\uff08\u8349\u6848\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u4ea4\u6240\u95ee\u8be2\u51fd\u30102016\u3011\u7b2c469\u53f7\u7684\u56de\u590d\u8bf4\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u56fd\u67ab\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e2d\u5c0f\u677f\u516c\u53f8\u7ba1\u7406\u90e8\u300a\u5173\u4e8e\u5bf9\u5e7f\u4e1c\u56fd\u76db\u91d1\u63a7\u96c6\u56e2\u80a1\u4efd\u6709\u9650\u516c\u53f8\u7684\u95ee\u8be2\u51fd\u300b\u76f8\u5173\u4e8b\u9879\u7684\u4e13\u9879\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u6743\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000820',
 'secName': u'\u91d1\u57ce\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6743\u76ca\u53d8\u52a8\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002316',
 'secName': u'\u952e\u6865\u901a\u8baf',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u8463\u4e8b\u4f1a\u4e8c\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u8f6c\u8ba9\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF" }
2016-11-15 13:30:18 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u76d1\u4e8b\u4f1a\u5341\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u8f6c\u8ba9\u63a7\u80a1\u5b50\u516c\u53f8\u80a1\u6743\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u548c\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002497',
 'secName': u'\u96c5\u5316\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u534e\u6cf0\u8054\u5408\u8bc1\u5238\u6709\u9650\u8d23\u4efb\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300556',
 'secName': u'\u4e1d\u8def\u89c6\u89c9',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u62402016\u5e74\u534a\u5e74\u62a5\u95ee\u8be2\u51fd\u7684\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u9879\u76ee\u7533\u8bf7\u6062\u590d\u5ba1\u67e5\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8bc9\u8bbc\u4e8b\u9879\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000571',
 'secName': u'\u65b0\u5927\u6d32\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000807',
 'secName': u'\u4e91\u94dd\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u5f00\u53d1\u884c2016\u5e74\u516c\u53f8\u503a\u5238\uff08\u7b2c\u4e00\u671f\uff09\u53d1\u884c\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000883',
 'secName': u'\u6e56\u5317\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000595',
 'secName': u'\u5b9d\u5854\u5b9e\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b80\u5f0f\u6743\u76ca\u53d8\u52a8\u62a5\u544a\u4e66',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u9009\u4e3e\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u4e4b\u6cd5\u5f8b\u610f\u89c1',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66\uff08\u6458\u8981\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u548c\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u7684\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u73af\u7403\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884cA\u80a1\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u53ca\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u4e4b\u4e13\u9879\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u516c\u544a\u4e66\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u957f\u57ce\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u91d1\u675c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u7684\u80a1\u7968\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e0a\u5e02\u4e4b\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7f51\u4e0a\u6447\u53f7\u4e2d\u7b7e\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300567',
 'secName': u'\u7cbe\u6d4b\u7535\u5b50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u201c11\u51ef\u8fea\u503a\u201d2016\u5e74\u503a\u5238\u4ed8\u606f\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000939',
 'secName': u'\u51ef\u8fea\u751f\u6001',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300559',
 'secName': u'\u4f73\u53d1\u5b89\u6cf0',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u5185\u5e55\u77e5\u60c5\u4eba\u4e70\u5356\u516c\u53f8\u80a1\u7968\u60c5\u51b5\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF" }
2016-11-15 13:30:19 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF" }
2016-11-15 13:30:19 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:30:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 507,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 84757,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 30, 19, 70414),
 'log_count/ERROR': 140,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 11, 15, 5, 30, 18, 501121)}
2016-11-15 13:30:19 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:31:47 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:31:47 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:31:47 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:31:47 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:31:47 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:31:47 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:31:47 [scrapy] INFO: Spider opened
2016-11-15 13:31:47 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u63d0\u540d\u4eba\u53ca\u5019\u9009\u4eba\u58f0\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000862',
 'secName': u'\u94f6\u661f\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 11, 45, 2),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300549',
 'secName': u'\u4f18\u5fb7\u7cbe\u5bc6',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 52),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u300a\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u884c\u653f\u8bb8\u53ef\u9879\u76ee\u5ba1\u67e5\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u901a\u77e5\u4e66\u300b\u4e4b\u53cd\u9988\u610f\u89c1\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u56de\u590d',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u82cf\u5dde\u79d1\u73af\u73af\u4fdd\u79d1\u6280\u6709\u9650\u516c\u53f82014\u5e74-2016\u5e749\u6708\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u72ec\u7acb\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u9605\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u676d\u5dde\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u4e4b\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000633',
 'secName': u'*ST\u5408\u91d1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 53),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u4e2d\u4f26\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002655',
 'secName': u'\u5171\u8fbe\u7535\u58f0',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 47),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002262',
 'secName': u'\u6069\u534e\u836f\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 31),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u8fdb\u884c\u80a1\u7968\u8d28\u62bc\u5f0f\u56de\u8d2d\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002458',
 'secName': u'\u76ca\u751f\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 24),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u7ea6\u5b9a\u8d2d\u56de\u5f0f\u8bc1\u5238\u4ea4\u6613\u5230\u671f\u8d2d\u56de\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002471',
 'secName': u'\u4e2d\u8d85\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 9),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d77\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f82015\u5e74\u5ea6\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5174\u4e1a\u56fd\u9645\u4fe1\u6258\u6709\u9650\u516c\u53f8\u5174\u4e1a\u4fe1\u6258-\u4f17\u4fe1\u65c5\u6e381\u53f7\u5458\u5de5\u6301\u80a1\u96c6\u5408\u8d44\u91d1\u4fe1\u6258\u8ba1\u5212\u8d44\u91d1\u4fe1\u6258\u5408\u540c',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002707',
 'secName': u'\u4f17\u4fe1\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 11, 41),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u6c5f\u5929\u518c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u4fe1\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u6301\u7eed\u7763\u5bfc\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002729',
 'secName': u'\u597d\u5229\u6765',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 39),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u96c4\u53bf\u7ecf\u6d4e\u5f00\u53d1\u533a\u96c6\u4e2d\u4f9b\u70ed\u9879\u76ee\u83b7\u5f97\u6838\u51c6\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002616',
 'secName': u'\u957f\u9752\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 32),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300496',
 'secName': u'\u4e2d\u79d1\u521b\u8fbe',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 29),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u9009\u4e3e\u4ea7\u751f\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u83b7\u5f97\u201c\u56fd\u5bb6\u6280\u672f\u521b\u65b0\u793a\u8303\u4f01\u4e1a\u201d\u8ba4\u5b9a\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300066',
 'secName': u'\u4e09\u5ddd\u667a\u6167',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 19),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002528',
 'secName': u'\u82f1\u98de\u62d3',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u4e8b\u9879\u83b7\u5f97\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u6838\u51c6\u6279\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u7684\u4fee\u8ba2\u8bf4\u660e\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u6458\u8981',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\uff08\u4fee\u8ba2\u7a3f\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u8bf4\u660e\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u53d1\u884c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u6295\u8d44\u98ce\u9669\u7279\u522b\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e03\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u56db\u6b21\u4e34\u65f6\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5ef6\u671f\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535A',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5bf9\u5916\u6295\u8d44\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002646',
 'secName': u'\u9752\u9752\u7a1e\u9152',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e94\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5168\u8d44\u5b50\u516c\u53f8\u5b8c\u6210\u5de5\u5546\u53d8\u66f4\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u90e8\u5206\u6fc0\u52b1\u5bf9\u8c61\u540d\u5355',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u5341\u4e94\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5bf9\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u53d1\u8868\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u95ee\u8be2\u51fd\u56de\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002443',
 'secName': u'\u91d1\u6d32\u7ba1\u9053',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u610f\u5411\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u521d\u6b65\u8be2\u4ef7\u53ca\u63a8\u4ecb\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u63d0\u793a\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u56db\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2013\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u5173\u4e8e\u6838\u51c6\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u6279\u590d',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u975e\u7ecf\u5e38\u6027\u635f\u76ca\u7684\u4e13\u9879\u5ba1\u6838\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u56db\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u516d\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e94\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e09\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u610f\u89c1\u4e66\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u63a7\u80a1\u80a1\u4e1c\u53ca\u5b9e\u9645\u63a7\u5236\u4eba\u5bf9\u62db\u80a1\u8bf4\u660e\u4e66\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u8bbe\u7acb\u4ee5\u6765\u80a1\u672c\u6f14\u53d8\u60c5\u51b5\u7684\u8bf4\u660e\u53ca\u5176\u8463\u4e8b\u3001\u76d1\u4e8b\u3001\u9ad8\u7ea7\u7ba1\u7406\u4eba\u5458\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5185\u90e8\u63a7\u5236\u9274\u8bc1\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u53f8\u7ae0\u7a0b\uff08\u8349\u6848\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u4ea4\u6240\u95ee\u8be2\u51fd\u30102016\u3011\u7b2c469\u53f7\u7684\u56de\u590d\u8bf4\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u56fd\u67ab\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e2d\u5c0f\u677f\u516c\u53f8\u7ba1\u7406\u90e8\u300a\u5173\u4e8e\u5bf9\u5e7f\u4e1c\u56fd\u76db\u91d1\u63a7\u96c6\u56e2\u80a1\u4efd\u6709\u9650\u516c\u53f8\u7684\u95ee\u8be2\u51fd\u300b\u76f8\u5173\u4e8b\u9879\u7684\u4e13\u9879\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u6743\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000820',
 'secName': u'\u91d1\u57ce\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6743\u76ca\u53d8\u52a8\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002316',
 'secName': u'\u952e\u6865\u901a\u8baf',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u8463\u4e8b\u4f1a\u4e8c\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u8f6c\u8ba9\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u76d1\u4e8b\u4f1a\u5341\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u8f6c\u8ba9\u63a7\u80a1\u5b50\u516c\u53f8\u80a1\u6743\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u548c\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002497',
 'secName': u'\u96c5\u5316\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u534e\u6cf0\u8054\u5408\u8bc1\u5238\u6709\u9650\u8d23\u4efb\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300556',
 'secName': u'\u4e1d\u8def\u89c6\u89c9',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u62402016\u5e74\u534a\u5e74\u62a5\u95ee\u8be2\u51fd\u7684\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u9879\u76ee\u7533\u8bf7\u6062\u590d\u5ba1\u67e5\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8bc9\u8bbc\u4e8b\u9879\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000571',
 'secName': u'\u65b0\u5927\u6d32\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000807',
 'secName': u'\u4e91\u94dd\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u5f00\u53d1\u884c2016\u5e74\u516c\u53f8\u503a\u5238\uff08\u7b2c\u4e00\u671f\uff09\u53d1\u884c\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000883',
 'secName': u'\u6e56\u5317\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000595',
 'secName': u'\u5b9d\u5854\u5b9e\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b80\u5f0f\u6743\u76ca\u53d8\u52a8\u62a5\u544a\u4e66',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u9009\u4e3e\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u4e4b\u6cd5\u5f8b\u610f\u89c1',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66\uff08\u6458\u8981\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u548c\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u7684\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u73af\u7403\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884cA\u80a1\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u53ca\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u4e4b\u4e13\u9879\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u516c\u544a\u4e66\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u957f\u57ce\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u91d1\u675c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u7684\u80a1\u7968\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e0a\u5e02\u4e4b\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7f51\u4e0a\u6447\u53f7\u4e2d\u7b7e\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300567',
 'secName': u'\u7cbe\u6d4b\u7535\u5b50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u201c11\u51ef\u8fea\u503a\u201d2016\u5e74\u503a\u5238\u4ed8\u606f\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000939',
 'secName': u'\u51ef\u8fea\u751f\u6001',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300559',
 'secName': u'\u4f73\u53d1\u5b89\u6cf0',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u5185\u5e55\u77e5\u60c5\u4eba\u4e70\u5356\u516c\u53f8\u80a1\u7968\u60c5\u51b5\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF" }
2016-11-15 13:31:48 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF" }
2016-11-15 13:31:48 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:31:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 507,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 84757,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 31, 48, 410913),
 'log_count/ERROR': 140,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 11, 15, 5, 31, 47, 752673)}
2016-11-15 13:31:48 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:32:55 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:32:55 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:32:55 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:32:55 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:32:55 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:32:55 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:32:55 [scrapy] INFO: Spider opened
2016-11-15 13:32:55 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:32:58 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:32:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 507,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 84757,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 32, 58, 874333),
 'item_scraped_count': 140,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 11, 15, 5, 32, 55, 255817)}
2016-11-15 13:32:58 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:34:26 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:34:26 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:34:26 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:34:26 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:34:26 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:34:26 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:34:26 [scrapy] INFO: Spider opened
2016-11-15 13:34:26 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u63d0\u540d\u4eba\u53ca\u5019\u9009\u4eba\u58f0\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000862',
 'secName': u'\u94f6\u661f\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 11, 45, 2),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829492.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300549',
 'secName': u'\u4f18\u5fb7\u7cbe\u5bc6',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 52),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829472.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u300a\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u884c\u653f\u8bb8\u53ef\u9879\u76ee\u5ba1\u67e5\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u901a\u77e5\u4e66\u300b\u4e4b\u53cd\u9988\u610f\u89c1\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829493.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u56de\u590d',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829498.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u82cf\u5dde\u79d1\u73af\u73af\u4fdd\u79d1\u6280\u6709\u9650\u516c\u53f82014\u5e74-2016\u5e749\u6708\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 15),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829494.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u7533\u8bf7\u6587\u4ef6\u4e8c\u6b21\u53cd\u9988\u610f\u89c1\u4e4b\u72ec\u7acb\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829497.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u9605\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829495.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u676d\u5dde\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u4e4b\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000925',
 'secName': u'\u4f17\u5408\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 42, 16),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829496.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000633',
 'secName': u'*ST\u5408\u91d1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 53),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829491.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u4e2d\u4f26\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002655',
 'secName': u'\u5171\u8fbe\u7535\u58f0',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 47),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829486.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829490.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829489.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e00\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002681',
 'secName': u'\u594b\u8fbe\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 40),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829488.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002262',
 'secName': u'\u6069\u534e\u836f\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 31),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829487.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u8fdb\u884c\u80a1\u7968\u8d28\u62bc\u5f0f\u56de\u8d2d\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002458',
 'secName': u'\u76ca\u751f\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 24),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829485.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u7ea6\u5b9a\u8d2d\u56de\u5f0f\u8bc1\u5238\u4ea4\u6613\u5230\u671f\u8d2d\u56de\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002471',
 'secName': u'\u4e2d\u8d85\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 9),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829484.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d77\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f82015\u5e74\u5ea6\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829479.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002479',
 'secName': u'\u5bcc\u6625\u73af\u4fdd',
 'time': datetime.datetime(2016, 11, 15, 11, 41, 3),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829478.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5174\u4e1a\u56fd\u9645\u4fe1\u6258\u6709\u9650\u516c\u53f8\u5174\u4e1a\u4fe1\u6258-\u4f17\u4fe1\u65c5\u6e381\u53f7\u5458\u5de5\u6301\u80a1\u96c6\u5408\u8d44\u91d1\u4fe1\u6258\u8ba1\u5212\u8d44\u91d1\u4fe1\u6258\u5408\u540c',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002707',
 'secName': u'\u4f17\u4fe1\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 11, 41),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829483.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829480.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u6d59\u6c5f\u5929\u518c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829482.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u4fe1\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u623f\u5730\u4ea7\u4e1a\u52a1\u4e4b\u4e13\u9879\u6838\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002244',
 'secName': u'\u6ee8\u6c5f\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 51),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829481.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u6301\u7eed\u7763\u5bfc\u5b9a\u671f\u73b0\u573a\u68c0\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002729',
 'secName': u'\u597d\u5229\u6765',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 39),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829477.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u96c4\u53bf\u7ecf\u6d4e\u5f00\u53d1\u533a\u96c6\u4e2d\u4f9b\u70ed\u9879\u76ee\u83b7\u5f97\u6838\u51c6\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002616',
 'secName': u'\u957f\u9752\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 32),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829476.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300496',
 'secName': u'\u4e2d\u79d1\u521b\u8fbe',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 29),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829475.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829473.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u9009\u4e3e\u4ea7\u751f\u7b2c\u4e09\u5c4a\u76d1\u4e8b\u4f1a\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300501',
 'secName': u'\u6d77\u987a\u65b0\u6750',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 20),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829474.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u83b7\u5f97\u201c\u56fd\u5bb6\u6280\u672f\u521b\u65b0\u793a\u8303\u4f01\u4e1a\u201d\u8ba4\u5b9a\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'300066',
 'secName': u'\u4e09\u5ddd\u667a\u6167',
 'time': datetime.datetime(2016, 11, 15, 11, 40, 19),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829471.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002528',
 'secName': u'\u82f1\u98de\u62d3',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829014.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u4e8b\u9879\u83b7\u5f97\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u6838\u51c6\u6279\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829003.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u7684\u4fee\u8ba2\u8bf4\u660e\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829006.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\u6458\u8981',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829005.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u53d1\u884c\u80a1\u4efd\u53ca\u652f\u4ed8\u73b0\u91d1\u8d2d\u4e70\u8d44\u4ea7\u5e76\u52df\u96c6\u914d\u5957\u8d44\u91d1\u66a8\u5173\u8054\u4ea4\u6613\u62a5\u544a\u4e66\uff08\u4fee\u8ba2\u7a3f\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'300331',
 'secName': u'\u82cf\u5927\u7ef4\u683c',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829004.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829001.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002492',
 'secName': u'\u6052\u57fa\u8fbe\u946b',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202829002.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u8bf4\u660e\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828979.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u53d1\u884c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828977.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u6295\u8d44\u98ce\u9669\u7279\u522b\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300569',
 'secName': u'\u5929\u80fd\u91cd\u5de5',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828978.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e03\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u56db\u6b21\u4e34\u65f6\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828912.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5ef6\u671f\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000037',
 'secName': u'*ST\u5357\u7535A',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828911.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5bf9\u5916\u6295\u8d44\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002646',
 'secName': u'\u9752\u9752\u7a1e\u9152',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828910.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e94\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828895.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828898.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u5168\u8d44\u5b50\u516c\u53f8\u5b8c\u6210\u5de5\u5546\u53d8\u66f4\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828894.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828896.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u90e8\u5206\u6fc0\u52b1\u5bf9\u8c61\u540d\u5355',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828900.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u56db\u5c4a\u76d1\u4e8b\u4f1a\u7b2c\u5341\u4e94\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828897.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u5411\u6fc0\u52b1\u5bf9\u8c61\u6388\u4e882015\u5e74\u7b2c\u4e8c\u671f\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u9884\u7559\u9650\u5236\u6027\u80a1\u7968\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828901.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5bf9\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u516d\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u53d1\u8868\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002334',
 'secName': u'\u82f1\u5a01\u817e',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828899.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u95ee\u8be2\u51fd\u56de\u590d\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002443',
 'secName': u'\u91d1\u6d32\u7ba1\u9053',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828875.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u62db\u80a1\u610f\u5411\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828848.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u521d\u6b65\u8be2\u4ef7\u53ca\u63a8\u4ecb\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828818.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u63d0\u793a\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828817.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u56db\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828846.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828845.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e00\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828844.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828843.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e8c\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828842.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828841.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e00\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u5341\u4e8c\u6b21\u4f1a\u8bae\u51b3\u8bae',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828840.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828823.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2015\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828822.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828821.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2014\u5e74\u7b2c\u4e00\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828820.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2013\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828819.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u5173\u4e8e\u6838\u51c6\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u6279\u590d',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828816.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u975e\u7ecf\u5e38\u6027\u635f\u76ca\u7684\u4e13\u9879\u5ba1\u6838\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828847.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828839.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u62db\u5546\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u53d1\u884c\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828838.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u56db\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828836.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u516d\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828835.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e94\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828834.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e8c\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828833.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u6cd5\u5f8b\u610f\u89c1\u4e66\uff08\u4e09\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828832.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u610f\u89c1\u4e66\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828831.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u8865\u5145\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a\uff08\u4e00\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828830.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828829.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56fd\u6d69\u5f8b\u5e08\uff08\u6df1\u5733\uff09\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u4eba\u6c11\u5e01\u666e\u901a\u80a1\uff08A\u80a1\uff09\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u5f8b\u5e08\u5de5\u4f5c\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828828.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u63a7\u80a1\u80a1\u4e1c\u53ca\u5b9e\u9645\u63a7\u5236\u4eba\u5bf9\u62db\u80a1\u8bf4\u660e\u4e66\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828827.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u516c\u53f8\u8bbe\u7acb\u4ee5\u6765\u80a1\u672c\u6f14\u53d8\u60c5\u51b5\u7684\u8bf4\u660e\u53ca\u5176\u8463\u4e8b\u3001\u76d1\u4e8b\u3001\u9ad8\u7ea7\u7ba1\u7406\u4eba\u5458\u7684\u786e\u8ba4\u610f\u89c1',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828826.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5185\u90e8\u63a7\u5236\u9274\u8bc1\u62a5\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828825.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u53f8\u7ae0\u7a0b\uff08\u8349\u6848\uff09',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828824.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'300570',
 'secName': u'\u592a\u8fb0\u5149',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828837.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u4ea4\u6240\u95ee\u8be2\u51fd\u30102016\u3011\u7b2c469\u53f7\u7684\u56de\u590d\u8bf4\u660e',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828810.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u56fd\u67ab\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e2d\u5c0f\u677f\u516c\u53f8\u7ba1\u7406\u90e8\u300a\u5173\u4e8e\u5bf9\u5e7f\u4e1c\u56fd\u76db\u91d1\u63a7\u96c6\u56e2\u80a1\u4efd\u6709\u9650\u516c\u53f8\u7684\u95ee\u8be2\u51fd\u300b\u76f8\u5173\u4e8b\u9879\u7684\u4e13\u9879\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002670',
 'secName': u'\u56fd\u76db\u91d1\u63a7',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828809.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u6743\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000820',
 'secName': u'\u91d1\u57ce\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828799.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6743\u76ca\u53d8\u52a8\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002316',
 'secName': u'\u952e\u6865\u901a\u8baf',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828733.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u8463\u4e8b\u4f1a\u4e8c\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828678.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u53ec\u5f002016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u901a\u77e5',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828680.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828687.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u8f6c\u8ba9\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828686.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u5b50\u516c\u53f8\u8f6c\u8ba9\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f8100%\u80a1\u6743\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828685.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e5d\u5c4a\u76d1\u4e8b\u4f1a\u5341\u4e5d\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u76d1\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828679.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u4fe1\u5229\u6c47\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828684.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u62d3\u5174\u6770\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828683.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u56db\u5ddd\u534e\u4ea8\u6570\u7801\u901a\u8baf\u6709\u9650\u516c\u53f82016\u5e748\u670831\u65e5\u5ba1\u8ba1\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828682.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u8f6c\u8ba9\u63a7\u80a1\u5b50\u516c\u53f8\u80a1\u6743\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'000584',
 'secName': u'\u53cb\u5229\u63a7\u80a1',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828681.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u63a7\u80a1\u80a1\u4e1c\u90e8\u5206\u80a1\u4efd\u89e3\u9664\u8d28\u62bc\u548c\u8d28\u62bc\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002497',
 'secName': u'\u96c5\u5316\u96c6\u56e2',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828676.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u8463\u4e8b\u4f1a\u516c\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828645.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828647.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u534e\u6cf0\u8054\u5408\u8bc1\u5238\u6709\u9650\u8d23\u4efb\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u4e0e\u4e13\u4e1a\u673a\u6784\u5408\u4f5c\u6295\u8d44\u66a8\u5173\u8054\u4ea4\u6613\u7684\u6838\u67e5\u610f\u89c1',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828648.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u72ec\u7acb\u8463\u4e8b\u5173\u4e8e\u7b2c\u4e09\u5c4a\u8463\u4e8b\u4f1a\u7b2c\u4e09\u5341\u4e03\u6b21\u4f1a\u8bae\u76f8\u5173\u4e8b\u9879\u7684\u72ec\u7acb\u610f\u89c1',
 'announcementTypeName': u'\u4e0a\u5e02\u516c\u53f8\u5236\u5ea6',
 'secCode': u'002373',
 'secName': u'\u5343\u65b9\u79d1\u6280',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828646.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300556',
 'secName': u'\u4e1d\u8def\u89c6\u89c9',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828644.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828638.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8d2d\u4e70\u7406\u8d22\u4ea7\u54c1\u7684\u516c\u544a',
 'announcementTypeName': u'\u4ea4\u6613',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828637.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u62402016\u5e74\u534a\u5e74\u62a5\u95ee\u8be2\u51fd\u7684\u56de\u590d\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002336',
 'secName': u'*ST\u4eba\u4e50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202827541.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828634.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u9879\u76ee\u7533\u8bf7\u6062\u590d\u5ba1\u67e5\u7684\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828636.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u8bc9\u8bbc\u4e8b\u9879\u7684\u8fdb\u5c55\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828633.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e03\u6b21\uff08\u4e34\u65f6\uff09\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002240',
 'secName': u'\u5a01\u534e\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828635.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u505c\u724c\u8fdb\u5c55\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'000571',
 'secName': u'\u65b0\u5927\u6d32\uff21',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828572.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000807',
 'secName': u'\u4e91\u94dd\u80a1\u4efd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828571.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u516c\u5f00\u53d1\u884c2016\u5e74\u516c\u53f8\u503a\u5238\uff08\u7b2c\u4e00\u671f\uff09\u53d1\u884c\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000883',
 'secName': u'\u6e56\u5317\u80fd\u6e90',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828563.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828562.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u56db\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000918',
 'secName': u'\u5609\u51ef\u57ce',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828561.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u7684\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'000595',
 'secName': u'\u5b9d\u5854\u5b9e\u4e1a',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828558.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828557.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u516d\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'000967',
 'secName': u'\u76c8\u5cf0\u73af\u5883',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828556.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u7684\u516c\u544a',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828549.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u7b80\u5f0f\u6743\u76ca\u53d8\u52a8\u62a5\u544a\u4e66',
 'announcementTypeName': u'\u80a1\u6743\u53d8\u52a8',
 'secCode': u'002097',
 'secName': u'\u5c71\u6cb3\u667a\u80fd',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828550.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828522.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e\u9009\u4e3e\u804c\u5de5\u4ee3\u8868\u76d1\u4e8b\u7684\u516c\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828521.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u4e4b\u6cd5\u5f8b\u610f\u89c1',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002033',
 'secName': u'\u4e3d\u6c5f\u65c5\u6e38',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828523.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66\uff08\u6458\u8981\uff09',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828519.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u60c5\u51b5\u62a5\u544a\u4e66\u66a8\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u589e\u53d1',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828520.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u548c\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u7684\u62a5\u544a',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828517.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u73af\u7403\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884cA\u80a1\u80a1\u7968\u53d1\u884c\u8fc7\u7a0b\u53ca\u8ba4\u8d2d\u5bf9\u8c61\u5408\u89c4\u6027\u4e4b\u4e13\u9879\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828516.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u4e1c\u5434\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7684\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u4e2d\u4ecb\u673a\u6784\u62a5\u544a',
 'secCode': u'002150',
 'secName': u'\u901a\u6da6\u88c5\u5907',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828518.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e0a\u5e02\u516c\u544a\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828467.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u516c\u544a\u4e66\u63d0\u793a\u6027\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828468.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u957f\u57ce\u8bc1\u5238\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u4e4b\u4e0a\u5e02\u4fdd\u8350\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828469.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5317\u4eac\u5e02\u91d1\u675c\u5f8b\u5e08\u4e8b\u52a1\u6240\u5173\u4e8e\u516c\u53f8\u9996\u6b21\u516c\u5f00\u53d1\u884c\u7684\u80a1\u7968\u4e8e\u6df1\u5733\u8bc1\u5238\u4ea4\u6613\u6240\u4e0a\u5e02\u4e4b\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300562',
 'secName': u'\u4e50\u5fc3\u533b\u7597',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828466.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u80a1\u7968\u5e76\u5728\u521b\u4e1a\u677f\u4e0a\u5e02\u7f51\u4e0a\u6447\u53f7\u4e2d\u7b7e\u7ed3\u679c\u516c\u544a',
 'announcementTypeName': u'\u9996\u6b21\u516c\u5f00\u53d1\u884c\u53ca\u4e0a\u5e02',
 'secCode': u'300567',
 'secName': u'\u7cbe\u6d4b\u7535\u5b50',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828465.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u201c11\u51ef\u8fea\u503a\u201d2016\u5e74\u503a\u5238\u4ed8\u606f\u516c\u544a',
 'announcementTypeName': u'\u503a\u5238\u516c\u544a',
 'secCode': u'000939',
 'secName': u'\u51ef\u8fea\u751f\u6001',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828464.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u80a1\u7968\u4ea4\u6613\u5f02\u5e38\u6ce2\u52a8\u516c\u544a',
 'announcementTypeName': u'\u6f84\u6e05\u3001\u98ce\u9669\u63d0\u793a\u3001\u4e1a\u7ee9\u9884\u544a\u4e8b\u9879',
 'secCode': u'300559',
 'secName': u'\u4f73\u53d1\u5b89\u6cf0',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828463.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828458.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'\u5173\u4e8e2016\u5e74\u9650\u5236\u6027\u80a1\u7968\u6fc0\u52b1\u8ba1\u5212\u5185\u5e55\u77e5\u60c5\u4eba\u4e70\u5356\u516c\u53f8\u80a1\u7968\u60c5\u51b5\u81ea\u67e5\u62a5\u544a',
 'announcementTypeName': u'\u5176\u5b83\u91cd\u5927\u4e8b\u9879',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828457.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e8c\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002195',
 'secName': u'\u4e8c\u4e09\u56db\u4e94',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828459.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u51b3\u8bae\u516c\u544a',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828455.PDF" }
2016-11-15 13:34:27 [scrapy] ERROR: Error processing {'announcementTitle': u'2016\u5e74\u7b2c\u4e09\u6b21\u4e34\u65f6\u80a1\u4e1c\u5927\u4f1a\u7684\u6cd5\u5f8b\u610f\u89c1\u4e66',
 'announcementTypeName': u'\u80a1\u4e1c\u5927\u4f1a',
 'secCode': u'002678',
 'secName': u'\u73e0\u6c5f\u94a2\u7434',
 'time': datetime.datetime(2016, 11, 15, 0, 0),
 'url': u'http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: announcements.cninfo index: url_1 dup key: { : "http://www.cninfo.com.cn/finalpage/2016-11-15/1202828456.PDF" }
2016-11-15 13:34:31 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:34:31 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5539,
 'downloader/request_count': 9,
 'downloader/request_method_count/POST': 9,
 'downloader/response_bytes': 607192,
 'downloader/response_count': 9,
 'downloader/response_status_count/200': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 34, 31, 336887),
 'item_scraped_count': 868,
 'log_count/ERROR': 140,
 'log_count/INFO': 7,
 'request_depth_max': 8,
 'response_received_count': 9,
 'scheduler/dequeued': 9,
 'scheduler/dequeued/memory': 9,
 'scheduler/enqueued': 9,
 'scheduler/enqueued/memory': 9,
 'start_time': datetime.datetime(2016, 11, 15, 5, 34, 26, 297590)}
2016-11-15 13:34:31 [scrapy] INFO: Spider closed (finished)
2016-11-15 13:51:14 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:51:14 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:51:14 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:51:14 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:51:14 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:51:14 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:51:14 [scrapy] INFO: Spider opened
2016-11-15 13:51:14 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:51:41 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-15 13:51:41 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-15 13:51:41 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-15 13:51:41 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-15 13:51:41 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-15 13:51:41 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-15 13:51:41 [scrapy] INFO: Spider opened
2016-11-15 13:51:41 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-15 13:51:43 [scrapy] INFO: Closing spider (finished)
2016-11-15 13:51:43 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3009,
 'downloader/request_count': 5,
 'downloader/request_method_count/POST': 5,
 'downloader/response_bytes': 386728,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 15, 5, 51, 43, 412208),
 'item_scraped_count': 636,
 'log_count/INFO': 7,
 'request_depth_max': 4,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2016, 11, 15, 5, 51, 41, 225908)}
2016-11-15 13:51:43 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:20:07 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:20:07 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:20:07 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:20:07 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:20:07 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:20:07 [twisted] CRITICAL: Unhandled error in Deferred:
2016-11-21 14:20:07 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 1260, in _inlineCallbacks
    result = g.send(result)
  File "/Library/Python/2.7/site-packages/scrapy/crawler.py", line 90, in crawl
    six.reraise(*exc_info)
  File "/Library/Python/2.7/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/Library/Python/2.7/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Library/Python/2.7/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.scraper = Scraper(crawler)
  File "/Library/Python/2.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/Library/Python/2.7/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/Library/Python/2.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/Library/Python/2.7/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'news.pipelines' doesn't define any object named 'MongoDBPipeline'
2016-11-21 14:20:58 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:20:58 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:20:58 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:20:58 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:20:58 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:20:58 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:20:58 [scrapy] INFO: Spider opened
2016-11-21 14:20:58 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:21:02 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 25, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:21:02 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:21:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11580,
 'downloader/request_count': 40,
 'downloader/request_method_count/GET': 40,
 'downloader/response_bytes': 382518,
 'downloader/response_count': 40,
 'downloader/response_status_count/200': 40,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 21, 2, 693948),
 'item_scraped_count': 38,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 40,
 'scheduler/dequeued': 40,
 'scheduler/dequeued/memory': 40,
 'scheduler/enqueued': 40,
 'scheduler/enqueued/memory': 40,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2016, 11, 21, 6, 20, 58, 716059)}
2016-11-21 14:21:02 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:37:30 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:37:30 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'news'}
2016-11-21 14:37:30 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:37:30 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:37:30 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:37:31 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:37:31 [scrapy] INFO: Spider opened
2016-11-21 14:37:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:37:31 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_5.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_3.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_6.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_9.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_8.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_4.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_2.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Redirecting (302) to <GET http://www.cs.com.cn/404error/index.html> from <GET http://www.cs.com.cn/ssgs/gsxw/index_10.html>
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/404error/index.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_7.html> (referer: None)
2016-11-21 14:37:34 [scrapy] DEBUG: Filtered duplicate request: <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097386.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097388.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097376.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097390.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097382.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097394.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097392.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097060.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097387.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097386.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:51',
 'title': u'\u795e\u601d\u7535\u5b50\u80a1\u4e1c\u51cf\u6301330\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097386.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097381.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097388.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:54',
 'title': u'\u56fd\u796f\u73af\u4fdd\u4e2d\u68072.6\u4ebf\u5143\u8499\u57ce\u6c61\u6c34\u5382\u7f51\u4e00\u4f53\u5316PPP\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097388.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095704.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097389.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096692.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097397.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097376.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:43',
 'title': u'\u6d77\u8fbe\u80a1\u4efd\u80a1\u4e1c\u51cf\u6301390\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097376.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097390.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:56',
 'title': u'\u6052\u6cf0\u827e\u666e\u62df\u6295\u8d448000\u4e07\u5143\u8bbe\u7acb\u5317\u4eac\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097390.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096361.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097689.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097382.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:48',
 'title': u'\u534e\u529b\u521b\u901a\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301590\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097382.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097394.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:39',
 'title': u'\u4e1c\u963f\u963f\u80f6\u4e09\u5927\u4e3b\u5bfc\u4ea7\u54c1\u5168\u7ebf\u63d0\u4ef7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097394.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097392.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:56',
 'title': u'\u6d77\u8054\u8baf\u7b2c\u4e8c\u5927\u80a1\u4e1c\u51cf\u6301500\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097392.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097403.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097060.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:41',
 'title': u'11\u670817\u65e5\u5348\u95f4\u516c\u544a:\u5317\u5df4\u4f20\u5a92\u3001\u4f17\u4e1a\u8fbe\u7ec8\u6b62\u53c2\u4e0e\u683c\u529b\u7535\u5668\u5b9a\u589e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097060.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097387.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:54',
 'title': u'\u529b\u6e90\u4fe1\u606f\u83b7\u5f97\u653f\u5e9c\u8865\u52a9900\u4e07\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097387.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097381.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:48',
 'title': u'\u534e\u8679\u8ba1\u901a\u80a1\u4e1c\u8ba1\u5212\u51cf\u6301\u4e0d\u8d85\u8fc7168\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097381.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095704.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:19',
 'title': u'80\u540e\u8463\u4e8b\u957f\u5927\u9605\u5175\uff1a38\u4eba\u9760\u5bb6\u65cf\u4f20\u627f 4\u4eba\u767d\u624b\u8d77\u5bb6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095704.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097389.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:55',
 'title': u'\u96f7\u66fc\u80a1\u4efd\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301600\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097389.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097395.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096692.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:01',
 'title': u'\u76d1\u7ba1\u90e8\u95e8\u6478\u5e95\u623f\u4f01\u53c2\u80a1\u5730\u65b9\u94f6\u884c \u623f\u4f01\u878d\u8d44\u538b\u529b\u589e\u5927',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096692.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097397.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:01',
 'title': u'\u7279\u9510\u5fb7\u5168\u8d44\u5b50\u516c\u53f8\u7b7e\u8ba23.52\u4ebf\u5143EPC\u603b\u627f\u5305\u5408\u540c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097397.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096366.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096318.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096361.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:31',
 'title': u'\u91d1\u5cad\u77ff\u4e1a\u62df\u7ec8\u6b62\u7b79\u5212\u8d2d\u4e70\u8d44\u4ea7 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096361.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096362.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097689.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:07',
 'title': u'\u5357\u73bbA\u539f\u9ad8\u7ba1\u4e0e\u524d\u6d77\u4eba\u5bff\u7ea0\u7eb7\u518d\u8d77\u6ce2\u6f9c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097689.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097881.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096381.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096363.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097403.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:04',
 'title': u'11\u670818\u65e5\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1\uff1a\u6c49\u9f0e\u5b87\u4f51\u62df13\u4ebf\u5143\u5e76\u8d2d\u6e38\u620f\u516c\u53f8 \u5e03\u5c40\u5a31\u4e50\u4ea7\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097403.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097395.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:00',
 'title': u'\u56db\u65b9\u7cbe\u521b\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u51cf\u6301150\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097395.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096397.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096366.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:23',
 'title': u'\u6df1\u4ea4\u6240\u5411\u5357\u73bbA\u518d\u53d1\u5173\u6ce8\u51fd \u5357\u73bbA\u8463\u79d8\u53ca\u4e24\u72ec\u7acb\u8463\u4e8b\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096366.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096318.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 17:04',
 'title': u'11\u670817\u65e5\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096318.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096382.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096399.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096362.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:31',
 'title': u'\u683c\u529b\u7535\u5668\u62df\u7ec8\u6b62\u6536\u8d2d\u73e0\u6d77\u94f6\u9686 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096362.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097881.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:47',
 'title': u'\u4e1c\u963f\u963f\u80f6\u4e09\u5927\u4e3b\u5bfc\u4ea7\u54c1\u63d0\u4ef7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097881.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096398.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096410.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096381.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:35',
 'title': u'11\u670817\u65e5\u589e\u51cf\u6301\uff1a\u4ebf\u6676\u5149\u7535\u906d\u63a7\u80a1\u80a1\u4e1c\u51cf\u63011500\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096381.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096363.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:34',
 'title': u'11\u670817\u65e5\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1\uff1a\u4e2d\u7535\u5e7f\u901a\u62df\u5265\u79bb\u4f20\u7edf\u4e1a\u52a1 \u7f6e\u5165\u519b\u5de5\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096363.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096411.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096415.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096412.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096397.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:24',
 'title': u'\u683c\u529b\u7535\u5668\u7ec8\u6b62\u53d1\u884c\u80a1\u4efd\u6536\u8d2d\u73e0\u6d77\u94f6\u9686',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096397.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096402.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096416.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096382.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:34',
 'title': u'11\u670817\u65e5\u91cd\u5927\u505c\u590d\u724c\uff1a\u683c\u529b\u7535\u5668\u62df\u7ec8\u6b62\u6536\u8d2d\u73e0\u6d77\u94f6\u9686 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096382.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096399.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:27',
 'title': u'\u673a\u5668\u4eba1.2\u4ebf\u80a1\u9650\u552e\u80a1\u89e3\u7981 1\u4ebf\u80a121\u65e5\u53ef\u4e0a\u5e02\u6d41\u901a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096399.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096398.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:26',
 'title': u'\u592a\u6781\u5b9e\u4e1a\u63a7\u80a1\u5b50\u516c\u53f8\u4e2d\u6807\u91d1\u989d\u903e10.5\u4ebf\u5143\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096398.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096410.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4ebf\u6676\u5149\u7535\u906d\u63a7\u80a1\u80a1\u4e1c\u51cf\u63011500\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096410.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096417.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096411.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e91\u5357\u767d\u836f\uff1a\u96c6\u56e2\u6df7\u6539\u65b0\u5b9e\u65bd\u8def\u5f84\u5df2\u5f97\u5230\u5404\u65b9\u8ba4\u53ef',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096411.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096418.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096415.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:42',
 'title': u'\u7eff\u53f6\u96c6\u56e2\u5218\u6bbf\u6ce2\u56de\u5e94\uff1a\u4e50\u89c6\u6709\u96be \u4e2a\u4eba\u62c9\u5144\u5f1f\u4e00\u628a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096415.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096412.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u56fd\u52a8\u529b\u80a1\u4e1c\u589e\u6301\u8ba1\u5212\u5b9e\u65bd\u5b8c\u6bd5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096412.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096420.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096402.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:45',
 'title': u'\u5357\u73bbA\u56e0\u7ba1\u7406\u5c42\u52a8\u8361\u518d\u6536\u6df1\u4ea4\u6240\u5173\u6ce8\u51fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096402.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096416.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u9c81\u4ebf\u901a\u80a1\u4e1c\u9646\u91d1\u6d77\u51cf\u63012.35%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096416.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096414.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096421.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096423.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:34 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096417.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u5e7f\u751f\u5802\u63a7\u80a1\u80a1\u4e1c\u589e\u6301\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096417.html'}
2016-11-21 14:37:34 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096427.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096418.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u6d77\u53d1\u5c55\u66f4\u540d\u201c\u4e2d\u8fdc\u6d77\u80fd\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096418.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096424.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096430.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096425.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096420.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u5e0c\u52aa\u5c14\u7ec8\u6b62\u7b79\u5212\u91cd\u5927\u4e8b\u9879 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096420.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096434.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096446.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096414.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:42',
 'title': u'\u5357\u73bb\u8463\u79d8\u53ca\u603b\u4f1a\u8ba1\u5e08\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096414.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096421.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e1c\u6770\u667a\u80fd\u80a1\u4e1c\u5883\u754c\u6295\u8d44\u51cf\u63011.42%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096421.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096465.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096422.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096423.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u8fbd\u5b81\u6210\u5927\u62df4.2\u4ebf\u5143\u51fa\u552e\u5bb6\u4e50\u798f\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096423.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096428.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096429.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096427.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u9c81\u6297\u533b\u836f\u505c\u724c\u7b79\u5212\u975e\u516c\u5f00\u53d1\u884c\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096427.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096424.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u7eff\u53f6\u5236\u836f\u6f84\u6e05 \u5e76\u65e0\u4e0e\u4e50\u89c6\u8ba2\u7acb\u4efb\u4f55\u6295\u8d44\u5b89\u6392',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096424.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096430.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u7535\u5e7f\u901a\u62df\u5265\u79bb\u4f20\u7edf\u4e1a\u52a1 \u7f6e\u5165\u519b\u5de5\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096430.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096487.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096425.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u897f\u85cf\u836f\u4e1a\u5b9a\u589e\u7533\u8bf7\u83b7\u8bc1\u76d1\u4f1a\u5ba1\u6838\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096425.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096431.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096464.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096434.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:47',
 'title': u'\u6842\u53d1\u7965\u3001\u51ef\u83b1\u82f118\u65e5\u4e2d\u5c0f\u677f\u4e0a\u5e02',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096434.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096446.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:28',
 'title': u'\u79d1\u529b\u8fdc\uff1a\u62df\u51fa\u8d4414\u4ebf\u5143\u5171\u540c\u8bbe\u7acb\u6df7\u5408\u52a8\u529b\u6280\u672f\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096446.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096484.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096500.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097694.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096465.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:01',
 'title': u'\u5929\u80fd\u91cd\u5de5\u4e2d\u7b7e\u73870.02613%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096465.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097713.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096422.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u82f1\u98de\u62d3\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096422.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096428.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u6bc5\u8fbe\u56e0\u6d89\u5acc\u4fe1\u62ab\u8fdd\u6cd5\u8fdd\u89c4\u906d\u7acb\u6848\u8c03\u67e5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096428.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096429.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u84dd\u5149\u53d1\u5c55\u906d\u80a1\u4e1c\u51cf\u63012300\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096429.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097733.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097742.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096487.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:45',
 'title': u'\u8fbd\u5b81\u6210\u5927\uff1a\u62df4.2\u4ebf\u5143\u51fa\u552e\u5bb6\u4e50\u798f\u5168\u90e8\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096487.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096538.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097746.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096431.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u5e7f\u7530\u96c6\u56e2\u505c\u724c\u7b79\u5212\u6536\u8d2d\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096431.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097696.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096497.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096464.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:01',
 'title': u'\u534e\u9e4f\u98de\u80a1\u4e1c\u51cf\u63011100\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096464.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096484.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:47',
 'title': u'\u4eba\u4e8b\u53d8\u52a8\u7ee7\u7eed \u5357\u73bbA\u8463\u79d8\u53ca\u4e24\u72ec\u7acb\u8463\u4e8b\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096484.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096500.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 21:08',
 'title': u'\u5eb7\u5f97\u65b0\uff1a\u62df\u63a8\u603b\u89c4\u6a216\u4ebf\u5143\u5458\u5de5\u6301\u80a1\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096500.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097745.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097768.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097694.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:09',
 'title': u'\u524d\u6d77\u4eba\u5bff\u5357\u73bbA\u8f9e\u804c\u9ad8\u7ba1\u5404\u6267\u4e00\u8bcd \u5b9d\u80fd\u7cfb\u9762\u4e34\u7ba1\u7406\u6311\u6218',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097694.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097775.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097713.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:10',
 'title': u'\u5230\u5e95\u662f\u8c01"\u73bb\u7483\u5fc3"\uff1f\u5357\u73bbA\u98ce\u6ce2\u591a\u65b9\u5404\u6267\u4e00\u8bcd\u6ce2\u6f9c\u4e0d\u65ad',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097713.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097733.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:30',
 'title': u'\u4e07\u79d1\u80a1\u6743\u4e89\u593a\u6218\u6108\u6f14\u6108\u70c8\uff1a\u6052\u5927\u7ee7\u7eed\u589e\u6301 \u4e2d\u7b56\u5bcc\u6c47\u201c\u62cd\u9a6c\u6740\u5165\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097733.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097765.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097776.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097742.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:32',
 'title': u'\u4e0a\u5e02\u516c\u53f8\u5e76\u8d2d\u95ef\u5173\u5b58\u4e09\u5927\u6740\u5668 \u63a7\u5236\u6743\u6210\u5173\u6ce8\u65b0\u7126\u70b9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097742.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096538.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 21:37',
 'title': u'\u5149\u660e\u5730\u4ea7\uff1a\u62df10\u4ebf\u5143\u8f6c\u8ba9\u6240\u6301\u90e8\u5206\u7269\u4e1a\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096538.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097767.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097796.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097746.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:31',
 'title': u'\u76d1\u7ba1\u201c\u96f7\u9706\u51fa\u51fb\u201d\u623f\u5730\u4ea7\u4fe1\u6258\u4e1a\u52a1 \u4fe1\u6258\u516c\u53f8\u4e25\u9635\u4ee5\u5f85',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097746.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097797.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097696.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:10',
 'title': u'\u5b9d\u80fd\u7cfb\u5168\u9762\u63a5\u7ba1\u5357\u73bb \u76d1\u7ba1\u90e8\u95e8\u8fde\u53d1\u5173\u6ce8\u51fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097696.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096497.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 21:00',
 'title': u'\u683c\u529b\u7535\u5668\uff1a\u7ec8\u6b62\u7b79\u5212\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u4e8b\u5b9c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096497.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097798.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097247.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097783.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097882.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097819.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097745.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:32',
 'title': u'\u5b89\u90a6\u51fa\u624b\uff01113\u4ebf\u5143\u4e3e\u724c\u4e2d\u56fd\u5efa\u7b51\u56fe\u4e2a\u5565\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097745.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097774.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097768.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:43',
 'title': u'\u6b4c\u534e\u6709\u7ebf\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u8868\u73b0\u62a2\u773c \u65b0\u5a92\u4f53\u8f6c\u578b\u6548\u679c\u663e\u73b0',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097768.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097775.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:44',
 'title': u'28\u4ebf\u9a70\u63f4\u8d5b\u7ef4\u7834\u4ea7\u91cd\u6574 \u6613\u6210\u65b0\u80fd\u8bd5\u6c34\u53e6\u7c7b\u201c\u503a\u8f6c\u80a1\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097775.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097765.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:42',
 'title': u'\u529b\u5e06\u80a1\u4efd\u62df1.7\u4ebf\u5143\u5265\u79bb\u5b89\u8bda\u4fdd\u9669\u80a1\u4efd \u6536\u7f29\u91d1\u878d\u201c\u8f93\u8840\u201d\u65b0\u80fd\u6e90',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097765.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097776.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:47',
 'title': u'\u201c\u95e8\u53e3\u7684\u91ce\u86ee\u4eba\u201d\u518d\u73b0 \u6da8\u505c\u7684\u5357\u73bbA\u80cc\u540e\u8fd8\u6709\u8fd9\u4e9b\u65e0\u4e3b\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097776.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097767.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:43',
 'title': u'\u91cd\u6574\u8ba1\u5212\u83b7\u901a\u8fc7 *ST\u4e91\u7ef4\u4fdd\u58f3\u9700\u626d\u8f6c\u8fd110\u4ebf\u5de8\u4e8f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097767.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097809.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097796.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:56',
 'title': u'\u906d\u9047\u5f3a\u52bf\u5165\u4e3b\u201c\u540e\u9057\u75c7\u201d \u5916\u6765\u8d44\u672c\u5982\u4f55\u6597\u800c\u4e0d\u7834',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097796.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097797.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:57',
 'title': u'\u6d77\u6da6\u5149\u4f0f\u4ea7\u4e1a\u57fa\u91d1\u8ba1\u5212\u88ab\u95ee\u8be2 \u671d\u4ee4\u5915\u6539\u4e14\u8bbe\u4e0d\u5e73\u7b49\u6761\u7ea6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097797.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097798.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:57',
 'title': u'\u9996\u6279\u5e74\u62a5\u201c\u9884\u9001\u8f6c\u201d\u65b9\u6848\u51fa\u7089',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097798.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097247.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 16:26',
 'title': u'11\u670818\u65e5\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a\uff1a\u4e07\u79d1A\uff1a\u6536\u8d2d\u524d\u6d77\u56fd\u9645\u65b9\u6848\u5c1a\u672a\u8fbe\u6210\u5171\u8bc6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097247.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097799.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097783.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:47',
 'title': u'A\u80a1\u201c\u58f3\u201d\u751f\u610f\u98ce\u751f\u6c34\u8d77 \u5404\u8def\u8d44\u672c\u7eb7\u5230\u201c\u7897\u91cc\u6765\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097783.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097882.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:48',
 'title': u'11\u5bb6\u516c\u53f8\u8054\u624b\u7b79\u5efa\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097882.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097819.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:04',
 'title': u'\u4e2d\u56fd\u6052\u5927\u589e\u6301\u4e07\u79d1\u81f39.45% \u4e07\u79d1\u91cd\u7ec4\u65b9\u6848\u5c1a\u672a\u5c18\u57c3\u843d\u5b9a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097819.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097884.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097943.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097774.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:45',
 'title': u'\u957f\u57ce\u52a8\u6f2b\u51fa\u552e\u5723\u8fbe\u7126\u5316 \u62d6\u6b20\u8d27\u6b3e\u5ba2\u6237\u5fb7\u80dc\u96c6\u56e28\u6298\u63a5\u76d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097774.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097937.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097886.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097947.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097809.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:02',
 'title': u'\u6052\u5927\u80fd\u633d\u56de\u201c\u77ed\u7092\u201d\u4e8b\u4ef6\u4e2d\u53d7\u635f\u7684\u58f0\u8a89\u5417\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097809.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097988.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097964.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098024.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097948.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098025.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098067.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097799.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:56',
 'title': u'\u80a1\u5e02\u8d5a\u94b1\u6548\u5e94\u663e\u73b0 \u5458\u5de5\u6301\u80a1\u8ba1\u5212\u5bc6\u96c6\u5efa\u4ed3',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097799.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097968.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097884.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:49',
 'title': u'\u534e\u661f\u521b\u4e1a\u7ec8\u6b62\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097884.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097943.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5b87\u901a\u5ba2\u8f66\u56de\u5e94\u4e0b\u8dcc\u539f\u56e0\uff1a\u6216\u56e0\u65b0\u80fd\u6e90\u6c7d\u8f66\u8865\u8d34\u53d6\u6d88\u4f20\u95fb',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097943.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098066.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098023.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098022.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095707.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097966.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097937.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:26',
 'title': u'\u4e0a\u6d77\u94f6\u884c\u4e0a\u5e02\u7b2c\u4e09\u5929\u5373\u6253\u5f00\u6da8\u505c\u677f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097937.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097886.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:51',
 'title': u'11\u670818\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097886.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097947.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u4e07\u79d1A\u5927\u6da86% \u518d\u521b\u5386\u53f2\u65b0\u9ad8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097947.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095708.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097988.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:57',
 'title': u'\u4e0d\u6b62\u5357\u73bbA \u8fd9\u4e9b\u516c\u53f8\u540c\u6837\u7206\u53d1\u4eba\u4e8b\u5730\u9707\uff01(\u9644\u540d\u5355)',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097988.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097964.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5fb7\u8d5b\u7535\u6c60\u900f\u9732\u516c\u53f8\u4e3a\u534e\u4e3aMate9\u63d0\u4f9b\u7535\u6c60\u4ea7\u54c1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097964.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098024.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:05',
 'title': u'\u5409\u827e\u79d1\u6280\u7ec8\u6b62\u6536\u8d2d\u54c8\u8428\u514b\u65af\u5766\u70bc\u5316\u4f01\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098024.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097948.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5eb7\u5f97\u65b0\uff1a\u4e0e\u534e\u4e3a\u7ec8\u6b62\u88f8\u773c3D\u4e1a\u52a1\u5408\u4f5c\u4f20\u95fb\u4e0d\u5b9e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097948.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098025.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:23',
 'title': u'11\u670818\u65e5\u5348\u95f4\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098025.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095765.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098067.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:22',
 'title': u'\u6842\u53d1\u7965\u4eca\u65e5\u4e0a\u5e02',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098067.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097968.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u8fce\u5b89\u90a6\u4e3e\u724c \u4e2d\u56fd\u5efa\u7b51\u4eca\u65e5\u9ad8\u5f00\u4f4e\u8d70',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097968.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095763.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095715.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098066.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:23',
 'title': u'\u817e\u90a6\u65c5\u6e38\u96c6\u56e2\u4e1a\u52a1\u5c06\u5411\u76ee\u7684\u5730\u5ef6\u4f38',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098066.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095785.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098023.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:05',
 'title': u'\u6c49\u738b\u79d1\u6280\u62df\u63a8\u80a1\u6743\u6fc0\u52b1\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098023.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098022.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:05',
 'title': u'\u666e\u90a6\u80a1\u4efd\u4e2d\u6807\u90d1\u5ddePPP\u9879\u76ee \u6709\u671b\u63d0\u632f\u5341\u5e74\u4e1a\u7ee9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098022.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095712.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095791.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095707.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:21',
 'title': u'\u6df1\u6e2f\u901a\u4e34\u8fd1 \u673a\u6784\u5bc6\u96c6\u8c03\u7814\u4e2d\u5c0f\u521b\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095707.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097966.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5c71\u4e1c\u534e\u9e4f\u91cd\u5927\u4e8b\u9879\u4e34\u505c \u9ad8\u9001\u8f6c\u662f\u8bef\u4f20',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097966.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095708.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:14',
 'title': u'\u5ddd\u73af\u79d1\u6280\u5b9e\u63a7\u4eba\u610f\u89c1\u201c\u53cd\u590d\u201d\uff1f \u848b\u9752\u6625\u8463\u4e8b\u804c\u4f4d\u201c\u5f97\u800c\u590d\u5931\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095708.html'}
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095778.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:35 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095797.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095819.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095765.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:49',
 'title': u'\u4fe1\u62ab\u4e25\u91cd\u5931\u5b9e*ST\u5de5\u65b0\u906d\u4e0a\u4ea4\u6240\u8c34\u8d23',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095765.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095763.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:48',
 'title': u'\u4e0a\u6d77\u94f6\u884c\u4eca\u65e5\u4e0a\u5e02 \u6279\u91cf\u9020\u5bcc\u8fd16000\u5458\u5de5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095763.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095824.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095825.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095715.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:24',
 'title': u'\u201c\u5927\u91d1\u4e3b\u201d\u63a8\u6ce2\u52a9\u6f9c\u58f3\u4f30\u503c\u534a\u5e74\u7ffb\u756a\uff1a100\u4ebf\u5143\u6210\u6807\u914d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095715.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095783.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095785.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:00',
 'title': u'\u9c7c\u8dc3\u533b\u7597\u62df8.63\u4ebf\u5165\u4e3b\u4e2d\u4f18\u533b\u836f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095785.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095795.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095712.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:14',
 'title': u'\u5265\u79bb\u71c3\u6c14\u5177\u8d44\u4ea7\u81f4\u4e3b\u4e1a\u201c\u60ac\u7a7a\u201d \u4e07\u5bb6\u4e50\u91cd\u7ec4\u906d\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095712.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095791.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:08',
 'title': u'\u94a2\u6784\u5de5\u7a0b\u5265\u79bb\u4f4e\u6548\u4e1a\u52a1 \u62df\u51fa\u552e\u4e24\u5bb6\u5b50\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095791.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095370.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095778.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:58',
 'title': u'\u4e0a\u4ea4\u6240\u76d1\u7ba1\u95ee\u8be2\u51fb\u8981\u5bb3 \u6052\u5927\u7cfb\u660e\u786e\u4e3e\u724c\u6885\u96c1\u5409\u7965\u610f\u56fe',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095778.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095822.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095797.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:12',
 'title': u'\u8d3e\u8dc3\u4ead\u662f\u600e\u6837\u62ff\u4e0b\u957f\u6c5f\u5546\u5b66\u9662\u540c\u5b66\u76846\u4ebf\u6295\u8d44\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095797.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095838.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095819.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:29',
 'title': u'\u73c8\u4f1f\u80a1\u4efd\u53d1\u5e03\u56fa\u6001\u9502\u7535\u6c60\u4ea7\u54c1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095819.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095824.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:13',
 'title': u'\u5feb\u4e50\u65f6\u4ee3\u4f30\u503c\u6210\u8c1c \u56fd\u76db\u91d1\u63a7\u6ea2\u4ef7\u6536\u8d2d5%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095824.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095825.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:13',
 'title': u'\u4e0a\u6d77\u56fd\u8d44\u6539\u9769\u5927\u5c3a\u5ea6\u7a81\u7834 \u88c5\u5165\u4f18\u8d28\u8d44\u4ea7\u76d8\u6d3b\u201c\u58f3\u201d\u8d44\u6e90',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095825.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095783.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:00',
 'title': u'\u5929\u76ee\u836f\u4e1a\u91cd\u7ec4\u516d\u8fde\u8d25 \u201c\u957f\u57ce\u7cfb\u201d\u8fdb\u9000\u7ef4\u8c37',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095783.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095860.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095795.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:16',
 'title': u'\u4eba\u6c11\u5e01\u51fb\u7a7f\u201c\u94c1\u5e95\u201d \u4e00\u5927\u6ce2\u4e0a\u5e02\u516c\u53f8\u635f\u5931\u8fc7\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095795.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095372.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095370.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 18:46',
 'title': u'\u4e50\u89c6\u63a7\u80a1\u64a4\u6362\u4e9a\u592a\u533a\u603b\u88c1 \u9999\u6e2f\u516c\u53f8\u88ab\u4f20\u4e24\u4e2a\u6708\u524d\u5df2\u5f00\u59cb\u88c1\u5458',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095370.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095373.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095822.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:13',
 'title': u'\u623f\u4f01\u878d\u8d44\u5168\u7ebf\u6536\u7d27\uff1a\u53ea\u8981\u8fd8\u6ca1\u653e\u6b3e\u7684\u90fd\u505c\u4e0b\u6765',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095822.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095378.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095838.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:53',
 'title': u'11\u670816\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095838.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095375.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095860.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:17',
 'title': u'\u5357\u73bbA\u7ba1\u7406\u5c42\u52a8\u8361\u5f15\u53d1\u6df1\u4ea4\u6240\u5173\u6ce8 \u524d\u6d77\u4eba\u5bff\u7d27\u6025\u58f0\u660e\uff1a\u4ece\u672a\u5e72\u6d89\u65e5\u5e38\u7ecf\u8425',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095860.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095390.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095371.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095385.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095372.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:00',
 'title': u'\u5174\u6e90\u73af\u5883\u7b7e\u8ba2\u4f9b\u6392\u6c34\u5de5\u7a0bPPP\u9879\u76eePPP\u534f\u8bae',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095372.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095386.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095388.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095373.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:01',
 'title': u'\u534e\u5e73\u80a1\u4efd\u6301\u80a15%\u4ee5\u4e0a\u7684\u80a1\u4e1c\u51cf\u6301673.5\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095373.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095387.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095378.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u534e\u8c0a\u96c6\u56e2\u56fd\u6709\u80a1\u4efd\u65e0\u507f\u5212\u8f6c\u5b8c\u6210',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095378.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095375.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:01',
 'title': u'\u65b0\u5b81\u7269\u6d41\u63a7\u80a1\u80a1\u4e1c\u53ca\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u5206\u522b\u51cf\u6301300\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095375.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095394.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095390.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u4f20\u5316\u80a1\u4efd\u8bc1\u5238\u7b80\u79f0\u53d8\u66f4\u4e3a\u201c\u4f20\u5316\u667a\u8054\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095390.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095371.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 18:50',
 'title': u'\u5b9d\u5854\u5b9e\u4e1a\uff1a\u4ea4\u6613\u5f02\u5e38\u906d\u6df1\u4ea4\u6240\u95ee\u8be2 \u8981\u6c42\u8bf4\u660e\u662f\u5426\u5b58\u5728\u5185\u5e55\u4ea4\u6613',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095371.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095385.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u79d1\u8fbe\u80a1\u4efd16\u65e5\u590d\u724c \u91cd\u7ec4\u83b7\u8bc1\u76d1\u4f1a\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095385.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095386.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u4e1c\u65b9\u521b\u4e1a\u53c2\u80a1\u516c\u53f8IPO\u83b7\u6279',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095386.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095393.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095711.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095391.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095388.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'*ST\u73e0\u6c5f\u91cd\u7ec4\u83b7\u5317\u4eac\u56fd\u8d44\u59d4\u6279\u590d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095388.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095396.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095395.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095399.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095387.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u6df1\u8d5b\u683c16\u65e5\u590d\u724c \u91cd\u7ec4\u83b7\u8bc1\u76d1\u4f1a\u6709\u6761\u4ef6\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095387.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095397.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095394.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5eb7\u8010\u7279\u5b50\u516c\u53f8\u4e2a\u522b\u4eba\u5458\u6d89\u5acc\u804c\u52a1\u4fb5\u5360',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095394.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095393.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5367\u9f99\u5730\u4ea7\u62df\u7ec8\u6b62\u8de8\u754c\u6536\u8d2d\u6e38\u620f\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095393.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095392.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095711.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:15',
 'title': u'\u9646\u5bb6\u5634\u56e0\u4fe1\u606f\u62ab\u9732\u906d\u4e0a\u4ea4\u6240\u95ee\u8be2 \u51fa\u552e\u8d44\u4ea7\u6d89\u5acc\u4e0d\u5f53\u5173\u8054\u4ea4\u6613',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095711.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095391.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5929\u5eb7\u751f\u7269\u80a1\u4e1c\u4e2d\u65b0\u5efa\u62db\u5546\u62ab\u9732\u51cf\u6301\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095391.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095396.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u677e\u53d1\u80a1\u4efd\u63a7\u80a1\u80a1\u4e1c\u589e\u6301\u8ba1\u5212\u5b9e\u65bd\u5b8c\u6210',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095396.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095395.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u6d77\u9646\u91cd\u5de5\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u63015%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095395.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095399.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u9ec4\u5c71\u65c5\u6e38\u53c2\u80a1\u516c\u53f8IPO\u83b7\u6279',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095399.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095408.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095398.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095410.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095397.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5229\u4e9a\u5fb7\u5458\u5de5\u6301\u80a1\u8ba1\u5212\u4e70\u51651.1%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095397.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095443.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095413.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095442.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095444.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095500.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095392.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u79d1\u6797\u73af\u4fdd\u80a1\u6743\u8f6c\u8ba9\u5b8c\u6210 \u4e1c\u8bda\u745e\u4e1a\u6210\u5927\u80a1\u4e1c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095392.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095665.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095640.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095411.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095485.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095644.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095408.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:21',
 'title': u'\u5b81\u6ce2\u5bcc\u90a6\u8c03\u6574\u91cd\u7ec4\u65b9\u6848\u3000\u575a\u5b9a\u63a8\u8fdb\u6218\u7565\u8f6c\u578b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095408.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095672.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095398.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u9ad8\u4f1f\u8fbe\u80a1\u4e1c\u94f6\u8054\u79d1\u6280\u62ab\u9732\u51cf\u6301\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095398.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095410.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:40',
 'title': u'\u4e1c\u9633\u5149\u79d1\u56e0\u5173\u6d89\u91cd\u5927\u4e8b\u987916 \u65e5\u8d77\u505c\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095410.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095443.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:15',
 'title': u'\u6c38\u6cf0\u80fd\u6e90\uff1a\u5408\u8d44\u5b50\u516c\u53f8\u62df\u5411\u5357\u9633\u7535\u5382\u589e\u8d4410\u4ebf\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095443.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095413.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:42',
 'title': u'\u4e2d\u822a\u4e09\u946b\u80a1\u4e1c\u97e9\u5e73\u5143\u51cf\u63011.87%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095413.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095442.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:18',
 'title': u'\u6c47\u91d1\u79d1\u628011\u670817\u65e5\u767b\u9646\u521b\u4e1a\u677f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095442.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095445.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095444.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:07',
 'title': u'\u5b81\u6ce2\u97f5\u5347\uff1a\u62df\u51fa\u8d443200\u4e07\u5143\u5171\u540c\u8bbe\u7acb\u97f5\u5347\u7535\u5b50\u516c\u53f8 \u6301\u80a140%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095444.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095500.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 21:18',
 'title': u'\u73c8\u4f1f\u80a1\u4efd\u53d1\u5e03\u5168\u7403\u9996\u4f8b\u56fa\u6001\u9502\u7535\u6c60\u4e0e\u5feb\u5145\u9502\u7535\u6c60',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095500.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095648.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095665.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:57',
 'title': u'\u5e74\u7ec8\u5957\u73b0"\u6697\u6d41\u6d8c" \u6076\u610f\u51cf\u6301"\u5957\u8def\u6df1"',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095665.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095640.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:50',
 'title': u'\u5357\u73bbA\u4e03\u540d\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095640.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095411.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:41',
 'title': u'\u4e2d\u56fd\u94c1\u5efa\u53ca\u5b50\u516c\u53f8\u7ec4\u8054\u5408\u4f53\u4e2d\u6807\u6295\u8d44\u989d\u7ea6229.19 \u4ebf\u5143PPP \u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095411.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095671.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095485.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:57',
 'title': u'\u9c7c\u8dc3\u533b\u7597\u62df8.6\u4ebf\u5143\u6536\u8d2d\u533b\u7528\u6d88\u6bd2\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095485.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095675.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095644.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:51',
 'title': u'\u4e1c\u822a\u6837\u672c\uff1a\u56fd\u8d44\u63a7\u5236\u4e0b\u591a\u4e3e\u63a8\u8fdb\u6df7\u6539',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095644.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095693.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095672.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:04',
 'title': u'\u5de5\u5927\u9ad8\u65b0\u53ca\u76f8\u5173\u9ad8\u7ba1\u88ab\u516c\u5f00\u8c34\u8d23',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095672.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095699.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096696.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096714.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096701.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095445.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:04',
 'title': u'\u7696\u6c5f\u7269\u6d41\uff1a\u5168\u8d44\u5b50\u516c\u53f8\u903e5\u4ebf\u5143\u6536\u8d2d\u63a7\u80a1\u80a1\u4e1c\u7535\u5382\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095445.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095648.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:53',
 'title': u'\u4e50\u89c6\u5c06\u83b7\u201c\u597d\u540c\u5b66\u201d6\u4ebf\u7f8e\u5143\u6295\u8d44',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095648.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096698.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096717.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095671.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:01',
 'title': u'\u6559\u80b2\u4ea7\u4e1a\u8d44\u6e90\u6574\u5408\u52a0\u901f\uff08\u9644\u80a1\uff09',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095671.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095675.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:05',
 'title': u'\u5ef6\u671f\u62ab\u9732\u91cd\u5927\u8bc9\u8bbc\u4e8b\u9879 \u5339\u51f8\u5339\u88ab\u4e0a\u4ea4\u6240\u8b66\u793a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095675.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096793.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095693.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:09',
 'title': u'\u6052\u5927\u9ad8\u4f4d\u63a5\u76d8\u4e07\u79d1\u7384\u673a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095693.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095699.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:16',
 'title': u'\u5357\u73bb7\u540d\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c \u5b9d\u80fd\u7cfb\u79f0\u5e76\u672a\u5e72\u6d89\u516c\u53f8\u7ecf\u8425',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095699.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096696.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:02',
 'title': u'\u6052\u5927\u7cfb\u79f0\u6218\u7565\u6295\u8d44\u6885\u96c1\u5409\u7965',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096696.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096714.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:14',
 'title': u'IPO\u53d1\u884c\u63d0\u901f \u5f71\u5b50\u80a1\u6709\u671b\u53d7\u76ca',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096714.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096701.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:06',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c\u7f57\u751f\u95e8\uff1a\u544a\u522b\u4fe1\u8be6\u8ff0\u7f18\u7531 \u5b9d\u80fd\u7cfb\u4e00\u4e00\u5426\u8ba4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096701.html'}
2016-11-21 14:37:36 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096740.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096698.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:04',
 'title': u'\u683c\u529b\u7535\u5668\u6536\u8d2d\u73e0\u6d77\u94f6\u9686\u7ec8\u6b62',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096698.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096750.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096741.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096717.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:15',
 'title': u'\u4e24\u516c\u53f8\u6f84\u6e05\u65e0\u6295\u8d44\u4e50\u89c6\u8ba1\u5212 \u7cfb\u8463\u4e8b\u957f\u4e2a\u4eba\u6295\u8d44',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096717.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096794.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096747.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096801.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096793.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:40',
 'title': u'463\u5bb6\u516c\u53f8\u4e34\u8fd1\u88ab\u4e3e\u724c \u89e3\u5bc6\u4e09\u884c\u4e1a74\u53ea\u4e3e\u724c\u6f5c\u529b\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096793.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096740.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:26',
 'title': u'\u817e\u4fe1\u80a1\u4efd\u53ca\u5b9e\u63a7\u4eba\u6d89\u5acc\u5411\u6700\u9ad8\u9662\u539f\u526f\u9662\u957f\u4e4b\u5b50\u884c\u8d3f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096740.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096810.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096814.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096811.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096750.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:29',
 'title': u'\u201c\u5b9d\u80fd\u7cfb\u201d\u5bf9\u51b3\u5357\u73bb\u7ba1\u7406\u5c42 \u4e09\u5927\u7591\u70b9\u5f85\u89e3',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096750.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096827.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096741.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:26',
 'title': u'\u83ab\u9ad8\u80a1\u4efd\u906d\u4e09\u5ea6\u4e3e\u724c \u63a7\u80a1\u80a1\u4e1c\u7b79\u5212\u5b9a\u589e\u53cd\u51fb\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096741.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096863.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096794.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:40',
 'title': u'\u4e0a\u6d77\u56fd\u4f01\u6539\u9769\u518d\u6380\u9ad8\u6f6e \u673a\u6784\u9884\u8ba16\u53ea\u9f99\u5934\u80a1\u76ee\u6807\u6da8\u5e45\u8d8550%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096794.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096747.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:28',
 'title': u'\u5357\u73bbA\u539f\u9ad8\u7ba1\u8bb2\u8ff0\u96c6\u4f53\u79bb\u804c\u539f\u56e0\uff1a\u524d\u6d77\u4eba\u5bff5\u4efd\u8bae\u6848\u4e5f\u662f\u5bfc\u706b\u7d22',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096747.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096801.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:45',
 'title': u'\u52df\u6295\u9879\u76ee\u8fdb\u5c55\u4e0d\u53ca\u9884\u671f \u5305\u94a2\u80a1\u4efd\u906d\u4e0a\u4ea4\u6240\u4e8c\u6b21\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096801.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096864.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096859.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096810.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:47',
 'title': u'\u77f3\u69b4\u96c6\u56e2\u81ea\u66dd\u589e\u6301\u52a8\u5411 \u9996\u94a2\u80a1\u4efd\u80a1\u4ef7\u5e94\u58f0\u800c\u6da8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096810.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096862.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096813.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096861.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096814.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:46',
 'title': u'\u5468\u9e3f\u794e\u8c08360\u56de\u5f52\u56de\u5f52:\u786e\u4e0e\u56fd\u5bb6\u7f51\u7edc\u5b89\u5168\u6218\u7565\u6709\u5173',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096814.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096811.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:46',
 'title': u'\u5927\u8fde\u4e0a\u5e02\u516c\u53f8\u91cd\u7ec4\u201c\u751f\u610f\u7ecf\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096811.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096868.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096827.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:51',
 'title': u'\u8bc4\u8bba:\u5357\u73bb\u4e8b\u4ef6\u6298\u5c04\u8d44\u672c\u4e0e\u804c\u4e1a\u7ecf\u7406\u4eba\u5171\u5904\u56f0\u5883',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096827.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096858.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096863.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u4e2d\u7535\u5e7f\u901a\u5265\u79bb\u539f\u4e1a\u52a1 \u63fd\u5165\u519b\u5de5\u7535\u5b50\u6807\u7684',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096863.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096871.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096878.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096864.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u79bb\u804c\u80cc\u540e \u6838\u5fc3\u6280\u672f\u53bbor\u7559',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096864.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096859.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bbA\u8001\u5458\u5de5\u8f9e\u804c\u98ce\u6ce2\u8d8a\u95f9\u8d8a\u5927 \u5357\u73bb\u5b9d\u80fd\u5404\u6267\u4e00\u8bcd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096859.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096867.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096862.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bb8\u9ad8\u7ba1\u8f9e\u804c \u524d\u6d77\u4eba\u5bff\uff1a\u80a1\u6743\u6fc0\u52b1\u53ea\u662f\u501f\u53e3',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096862.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096813.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:46',
 'title': u'PPP\u6982\u5ff5\u201c\u62db\u8702\u5f15\u8776\u201d \u673a\u6784\u7784\u4e0a\u5efa\u7b51\u88c5\u9970\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096813.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096861.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bbA\u4ee3\u7406\u8463\u4e8b\u957f\u9648\u7433\u9996\u53d1\u58f0\uff1a\u8981\u4fdd\u62a4\u597d\u5168\u4f53\u80a1\u4e1c\u6743\u76ca',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096861.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096872.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096868.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u4e09\u6cf0\u63a7\u80a1\u5b9a\u589e\u4ef7\u5012\u6302 \u89e3\u7981\u80a1\u4e1c\u201c\u5e72\u77aa\u773c\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096868.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096992.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096858.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bb\u5bab\u6597\u771f\u76f8\u53e3\u6c34\u6218\u4e2d\u6108\u53d1\u6a21\u7cca \u5f53\u4e8b\u53cc\u65b9\u5404\u6267\u4e00\u8bcd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096858.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096869.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097049.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096873.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097050.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097051.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096932.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096871.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u7f8e\u56fd\u4e50\u89c6\u6c7d\u8f66\u56de\u5e94\u505c\u4ea7:\u9879\u76ee\u4ece\u672a\u505c\u5de5 \u8d44\u91d1\u5c06\u5230\u4f4d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096871.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096736.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096870.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096878.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:54',
 'title': u'\u91d1\u660e\u7cbe\u673a\u6301\u7eed\u63a8\u8fdb\u201c\u667a\u80fd\u5236\u9020+\u5927\u5065\u5eb7\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096878.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096867.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bbA\u518d\u6536\u6df1\u4ea4\u6240\u5173\u6ce8\u51fd \u8981\u6c42\u5176\u5bf9\u5a92\u4f53\u62a5\u9053\u53ca\u6295\u8bc9\u4e3e\u62a5\u4e88\u4ee5\u6838\u67e5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096867.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097493.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096872.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u6668\u9e23\u7eb8\u4e1a\u8fde\u7eed\u591a\u6b21\u63d0\u4ef7 \u201c\u6d1b\u9633\u7eb8\u8d35\u201d\u535a\u5f08\u4eba\u6c11\u5e01\u8d2c\u503c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096872.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096992.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 11:01',
 'title': u'\u5357\u73bbA\u79bb\u804c\u9ad8\u7ba1\u79f0\u96c6\u4f53\u8df3\u69fd\u81f3\u65d7\u6ee8\u96c6\u56e2\u662f\u8c23\u4f20',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096992.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096869.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u4e2d\u6c47\u5f71\u89c6\u9690\u7792\u5bf9\u8d4c \u4e09\u4e03\u4e92\u5a31\u65e7\u6807\u7684\u518d\u9047\u632b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096869.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097049.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:42',
 'title': u'\u5317\u5df4\u4f20\u5a92\u3001\u4f17\u4e1a\u8fbe\u7ec8\u6b62\u53c2\u4e0e\u683c\u529b\u7535\u5668\u5b9a\u589e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097049.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096873.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u6885\u96c1\u5409\u7965\u5982\u4f55\u6f14\u7ece\u201c\u540e\u6052\u5927\u65f6\u4ee3\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096873.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097050.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:42',
 'title': u'\u6d59\u5bcc\u63a7\u80a1\u4e2d\u68071.3\u4ebf\u5143\u8001\u631d\u6c34\u7535\u7ad9\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097050.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097051.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:42',
 'title': u'\u5b9c\u660c\u4ea4\u8fd0\u5b50\u516c\u53f8\u4e24\u5904\u623f\u5c4b\u5c06\u88ab\u5f81\u6536',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097051.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096932.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 10:12',
 'title': u'11\u670817\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096932.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097485.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096736.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:23',
 'title': u'\u683c\u529b\u8463\u660e\u73e0\u9020\u8f66\u201c\u68a6\u788e\u201d \u7ec8\u6b62\u6536\u8d2d\u73e0\u6d77\u94f6\u9686\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096736.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097511.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096870.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c\uff1a\u4e07\u79d1\u5267\u60c5\u7684\u9884\u6f14?',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096870.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097512.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097493.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:24',
 'title': u'\u5357\u73bbA17\u65e5\u518d\u906d\u6df1\u4ea4\u6240\u95ee\u8be2 \u8981\u6c42\u8bf4\u660e\u524d\u6d77\u4eba\u5bff\u662f\u5426\u5e72\u9884\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097493.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097497.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097525.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097519.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099071.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097059.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099070.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097532.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099073.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099113.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097485.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 17:18',
 'title': u'\u201c\u5bfc\u706b\u7d22\u201d\u5357\u73bbA\u80a1\u6743\u8ba1\u5212\u7ec6\u8282\u62ab\u9732 6.2\u5143\u6fc0\u52b1\u4ef7\u4ec5\u4e3a\u5f53\u65f6\u5e02\u4ef7\u4e00\u534a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097485.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099112.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099111.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097511.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:24',
 'title': u'\u5929\u9f99\u96c6\u56e2\uff1a2016\u5e74\u5ea6\u62df10\u8f6c15\u6d3e0.5 \u591a\u4f4d\u80a1\u4e1c\u62df\u5de8\u91cf\u51cf\u6301',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097511.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097528.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097512.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:24',
 'title': u'\u4e50\u89c6\u9ad8\u5c42\u56de\u5e94\u201c\u5e9e\u6c0f\u9a97\u5c40\u8bf4\u201d \uff1a\u6b63\u5168\u529b\u4ee5\u8d74\u628a\u94b1\u8f6c\u5230\u7f8e\u56fd\u6c7d\u8f66\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097512.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099114.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099115.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099116.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099121.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097497.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:25',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u96c6\u4f53\u79bb\u804c\u5185\u5e55\uff1a\u59da\u632f\u534e\u6ca1\u63a5\u524d\u8463\u4e8b\u957f\u66fe\u5357\u7535\u8bdd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097497.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097525.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:58',
 'title': u'\u82cf\u5b81\u6613\u8d2d\u201c\u7b11\u503e\u57ce\u201d\u63ed\u5e55',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097525.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099123.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099122.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097519.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:57',
 'title': u'\u90d1\u7164\u673a\u56e0\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4e8b\u9879\u5c06\u4e0a\u4f1a17\u65e5\u5f00\u5e02\u8d77\u505c\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097519.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099124.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u8d44\u672c\u4e0e\u5b9e\u4e1a\u7684\u77db\u4e0e\u76fe\uff1a\u5357\u73bbA\u5f00\u542f\u524d\u6d77\u4eba\u5bff\u65f6\u4ee3 \u8d70\u5411\u5f15\u5173\u6ce8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099071.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099071.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097059.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:45',
 'title': u'\u6b65\u68ee\u80a1\u4efd\u7ec8\u6b62\u670d\u88c5\u52df\u6295\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097059.html'}
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u5357\u73bbA\u98ce\u6ce2\uff1a\u4ece\u8001\u724c\u5408\u8d44\u4f01\u4e1a\u5230\u8d44\u672c\u730e\u7269\u4e4b\u65c5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099070.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099070.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097532.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:06',
 'title': u'\u4e2d\u901a\u56fd\u810911\u670818\u65e5\u7f51\u4e0a\u7533\u8d2d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097532.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099126.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099146.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099148.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u63a2\u8bbf\u5357\u73bbA\u6210\u90fd\u5206\u516c\u53f8\uff1a\u8463\u4e8b\u957f\u6302\u9774\u603b\u7ecf\u7406\u4ecd\u5728\u5c97',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099073.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099073.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u534e\u95fb\u4f20\u5a92\u7b4910\u5bb6\u516c\u53f8\u6d89\u80a1\u6743\u8f6c\u8ba9 3\u4ebf\u6e38\u8d44\u8ffd\u63676\u53ea\u6982\u5ff5\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099113.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099113.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u5411\u65e5\u8475\u6536\u8d2d\u5965\u80fd\u7535\u6e90\u589e\u503c\u8d8510\u500d\u906d\u95ee\u8be2 \u79f0\u5145\u7535\u6869\u524d\u666f\u5e7f\u9614',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099112.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099112.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u903e\u4e03\u6210\u4e0a\u5e02\u516c\u53f8\u5927\u80a1\u4e1c\u6301\u80a1\u4f4e\u4e8e50% \u63a7\u5236\u6743\u4e4b\u4e89\u6709\u201c\u8fc7\u6ee5\u201d\u4e4b\u5acc',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099111.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099111.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097528.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:50',
 'title': u'11\u5bb6\u4e0a\u5e02\u516c\u53f8\u62df\u53c2\u4e0e\u7b79\u529e\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097528.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099154.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097530.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u738b\u77f36\u5e74\u6765\u9996\u6b21\u53c2\u52a0\u5a92\u4f53\u4f1a \u5173\u4e8e\u5b9d\u4e07\u4e4b\u4e89\u8bf4\u4e86\u4e94\u4ef6\u91cd\u8981\u7684\u4e8b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099114.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099114.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:55',
 'title': u'\u5168\u90e8\u505c\u4ea7\uff01\u77f3\u836f\u96c6\u56e2\u534e\u5317\u5236\u836f\u7b49\u591a\u5bb6\u4e0a\u5e02\u836f\u4f01\u8eba\u67aa\u73af\u4fdd\u4ee4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099115.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099115.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 09:19',
 'title': u'\u300a\u6f58\u91d1\u83b2\u300b\u7275\u51fa\u5bf9\u8d4c\u534f\u8bae\uff1a\u51af\u5bfc\u4e3a6000\u4e07\u4e1a\u7ee9\u627f\u8bfa\u4e0d\u60dc\u6495\u7834\u8138',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099116.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099116.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u534e\u5851\u63a7\u80a1\u7529\u591a\u5e74\u201c\u5305\u88b1\u201d\uff1a\u63a7\u80a1\u5b50\u516c\u53f8\u7533\u8bf7\u7834\u4ea7\u6e05\u7b97',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099121.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099121.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099125.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099155.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099156.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099157.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u4e50\u89c6\u6f6e\u9000\u516c\u52df\u4e50\u7c89\u4f55\u53bb\u4f55\u4ece\uff1a\u91cd\u4ed3\u673a\u6784\u6295\u8d44\u8005\u6216\u906d\u91cd\u632b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099123.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099123.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u4e50\u89c6\u6c7d\u8f66200\u4ebf\u83ab\u5e72\u5c71\u5de5\u5382\u4e0b\u6708\u5960\u57fa\uff1a\u5b98\u5458\u79f0\u4e50\u89c6\u80af\u5b9a\u62ff\u5730',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099122.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099122.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u76d8\u70b95\u5927\u795e\u5947\u58f3\u516c\u53f8\uff1a\u62ff\u5230\u4e00\u4e2a\u5341\u591a\u5929\u5c31\u80fd\u8d5a\u51e0\u5341\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099124.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099124.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099158.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:44',
 'title': u'\u4e07\u8fbe\u9662\u7ebf\u6b32\u6253\u901a\u5168\u4ea7\u4e1a\u94fe \u767e\u4f59\u673a\u6784\u8c03\u7814',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099126.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099126.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:00',
 'title': u'11\u670821\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099146.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099146.html" }
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u6d77\u80fd\u8fbe\u62df\u5b9a\u589e\u52df\u8d4410\u4ebf \u672c\u6b21\u5b9a\u589e\u5168\u90e8\u7531\u81ea\u5bb6\u4eba\u5305\u63fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099148.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099148.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099170.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099171.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099168.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099169.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u4e2d\u5b89\u6d88\u83b7\u65e5\u672c3.13\u4ebf\u5143\u5927\u5355 \u5c06\u6709\u5229\u4e8e\u8fdb\u4e00\u6b65\u62d3\u5bbd\u5883\u5916\u5e02\u573a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099154.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099154.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099172.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099163.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097530.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:10',
 'title': u'\u5c71\u4e1c\u534e\u9e4f\u516c\u544a\u9ad8\u9001\u8f6c\u7cfb\u8bef\u4f20',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097530.html'}
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099232.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099352.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099360.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u4e50\u89c6\u4e24\u9879\u76ee\u672a\u73b0\u65bd\u5de5\u8ff9\u8c61 \u6d89\u6295\u8d44\u989d600\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099125.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099125.html" }
2016-11-21 14:37:37 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099365.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:37 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u80a1\u4ef7\u8fde\u521b\u65b0\u9ad8\u80cc\u540e \u91d1\u83b1\u7279\u62ff\u4ec0\u4e48\u6491\u8d77\u9ad8\u4f30\u503c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099155.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099155.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u6807\u7684\u8d44\u4ea7\u4e1a\u7ee9\u672a\u8fbe\u9884\u671f \u76db\u6d0b\u79d1\u6280\u7ec8\u6b62\u91cd\u7ec4\u906d\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099156.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099156.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098986.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:09',
 'title': u'\u56de\u590d\u6df1\u4ea4\u6240\u91cd\u7ec4\u95ee\u8be2\u51fd \u4e1c\u65b9\u7f51\u7edc\u610f\u5728\u589e\u5f3a\u5185\u5bb9\u63d0\u4f9b\u80fd\u529b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099157.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099157.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098996.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:09',
 'title': u'\u4e0a\u6d77\u5929\u73ae100%\u80a1\u67433.42\u4ebf\u5143\u6302\u724c\u8f6c\u8ba9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099158.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099158.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098999.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095782.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099368.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:21',
 'title': u'8\u59294\u6b21 \u96f7\u67cf\u79d1\u6280\u63a7\u80a1\u80a1\u4e1c\u51cf\u6301\u4e0a\u763e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099170.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099170.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099358.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097700.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:22',
 'title': u'\u65b9\u6848\u4e24\u6b21\u88ab\u5426 \u5965\u7ef4\u901a\u4fe1\u7ec8\u6b62\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099171.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099171.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:21',
 'title': u'\u745e\u548c\u80a1\u4efd\u6da8\u505c \u62df10\u8f6c25\u6d3e2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099168.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099168.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:21',
 'title': u'\u897f\u90e8\u8d44\u6e90\u7b499\u516c\u53f8\u56e0\u91cd\u8981\u4e8b\u987921\u65e5\u8d77\u505c\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099169.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099169.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:22',
 'title': u'11\u6708\u795e\u534e5500\u52a8\u529b\u7164\u518d\u4e0b\u8c035\u5143/\u5428',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099172.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099172.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 09:58',
 'title': u'\u745e\u4e30\u9ad8\u6750\u62df\u6536\u8d2d\u62df\u4e0a\u5e02\u516c\u53f8\u6c5f\u82cf\u548c\u65f6\u5229',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099163.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099163.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 10:50',
 'title': u'\u91d1\u5c71\u8f6f\u4ef6\u7b2c\u4e09\u5b63\u5ea6\u8425\u6536\u540c\u6bd4\u589e\u957f\u8fd1\u4e94\u6210',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099232.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099232.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 12:13',
 'title': u'\u901a\u5bcc\u5fae\u7535\u83b7\u5f97\u653f\u5e9c\u8865\u52a93080\u4e07\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099352.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099352.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 12:39',
 'title': u'\u4e09\u836f\u4f01\u62ab\u9732\u505c\u724c\u539f\u7531 \u5609\u5e94\u5236\u836f\u63a7\u80a1\u6743\u6216\u8f6c\u8ba9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099360.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099360.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097407.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 13:03',
 'title': u'\u5929\u745e\u4eea\u5668\u62df3.6\u4ebf\u6536\u8d2d\u4f53\u5916\u8bca\u65ad\u4ea7\u54c1\u4f01\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099365.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099365.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 07:58',
 'title': u'11\u670821\u65e5\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098986.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098986.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:05',
 'title': u'11\u670821\u65e5\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098996.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098996.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097446.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 08:09',
 'title': u'11\u670821\u65e5\u91cd\u5927\u505c\u590d\u724c\uff1a*ST\u5357\u7535\u7ec8\u6b62\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4 21\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098999.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098999.html" }
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097406.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095782.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:00',
 'title': u'\u591a\u673a\u6784\u7ec4\u56e2\u5f0f\u8fdb\u9a7b\u91cd\u7ec4\u6982\u5ff5\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095782.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097411.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 13:04',
 'title': u'11\u670821\u65e5\u5348\u95f4\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099368.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099368.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-21 12:33',
 'title': u'\u91d1\u57ce\u80a1\u4efd\u62df\u66f4\u540d\u795e\u96fe\u8282\u80fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099358.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099358.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Error processing {'content': u'<div class="Dte',
 'time': u'2016-11-18 08:11',
 'title': u'\u539f\u9ad8\u7ba1\u7ec6\u8ff01114\u8463\u4e8b\u4f1a\u5185\u60c5 \u5357\u73bbA\u4e71\u5c40\u7f18\u8d77\u65e9\u751f\u5acc\u9699\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097700.html'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/pipelines.py", line 33, in process_item
    self.db[self.collection_name].insert(dict(item))
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 2212, in insert
    check_keys, manipulate, write_concern)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 535, in _insert
    check_keys, manipulate, write_concern, op_id, bypass_doc_val)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 517, in _insert_one
    _check_write_command_response([(0, result)])
  File "/Library/Python/2.7/site-packages/pymongo/helpers.py", line 309, in _check_write_command_response
    raise DuplicateKeyError(error.get("errmsg"), 11000, error)
DuplicateKeyError: E11000 duplicate key error collection: news.news index: url_1 dup key: { : "http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097700.html" }
2016-11-21 14:37:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 34, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097412.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097413.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097454.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097407.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:10',
 'title': u'\u5bcc\u745e\u7279\u88c5\u7b7e\u7f72\u5408\u4f5c\u5f00\u53d1\u6846\u67b6\u534f\u8bae',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097407.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097452.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097446.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:45',
 'title': u'\u4e2d\u56fd\u8fdc\u6d0b\uff1a\u62df7234\u4e07\u5143\u6536\u8d2d\u4e2d\u8fdc\u5e0c\u814a\u7b49\u5883\u5916\u516c\u53f8\u90e8\u5206\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097446.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097406.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:10',
 'title': u'\u6a2a\u6cb3\u6a21\u5177\u6536\u5230796\u4e07\u5143\u653f\u5e9c\u8865\u8d34',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097406.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097411.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:13',
 'title': u'11\u670818\u65e5\u91cd\u5927\u505c\u590d\u724c\uff1a\u534e\u5cf0\u8d85\u7ea4\u5468\u4e94\u590d\u724c \u62df18\u4ebf\u5143\u6536\u8d2d\u79fb\u52a8\u652f\u4ed8\u670d\u52a1\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097411.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097457.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097463.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097412.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:13',
 'title': u'11\u670818\u65e5\u9ad8\u9001\u8f6c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097412.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097455.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097459.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097461.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097413.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:15',
 'title': u'11\u670818\u65e5\u91cd\u8981\u589e\u51cf\u6301',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097413.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097464.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097454.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:00',
 'title': u'\u5168\u7b51\u80a1\u4efd\uff1a\u7b7e\u8ba2\u5408\u4f5c\u6846\u67b6\u534f\u8bae \u6709\u671b\u83b7\u5f97\u5927\u91cf\u8ba2\u5355',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097454.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097470.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097452.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:05',
 'title': u'\u4e09\u529b\u58eb\u667a\u80fd\u88c5\u5907\u5c55\u4f1a\u60ca\u8273\u4eae\u76f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097452.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097457.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:03',
 'title': u'\u65b0\u6e56\u4e2d\u5b9d\uff1a\u62df7.1\u4ebf\u5143\u8f6c\u8ba9\u5b50\u516c\u53f8\u65b0\u6e56\u5b9d\u534e65%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097457.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097471.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097463.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:10',
 'title': u'\u65b0\u6e56\u4e2d\u5b9d\u5168\u8d44\u5b50\u516c\u53f8\u65a5\u903e14.69\u4ebf\u5143\u62ff\u5730',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097463.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097455.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:51',
 'title': u'\u6b65\u68ee\u80a1\u4efd\uff1a\u8fdb\u519b\u91d1\u878d\u79d1\u6280  \u6398\u91d1\u4e07\u4ebf\u5e02\u573a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097455.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097459.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:09',
 'title': u'\u4e2d\u79d1\u66d9\u5149\u80a1\u4e1c\u5929\u5bcc\u521b\u6295\u51cf\u63013.11%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097459.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097472.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097461.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:09',
 'title': u'\u6885\u6cf0\u8bfa\u62df3000\u4e07\u5143\u6536\u8d2d\u9f0e\u5143\u4fe1\u5e7f49%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097461.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097480.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097464.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:10',
 'title': u'\u5927\u5bcc\u79d1\u62802016\u5e74\u5ea6\u4e1a\u7ee9\u9884\u589e108%-137%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097464.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097479.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097476.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097473.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097474.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097470.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u6613\u6210\u65b0\u80fd\u62df\u903e28\u4ebf\u5143\u6536\u8d2d\u6c5f\u897f\u8d5b\u7ef4\u53ca\u65b0\u4f59\u8d5b\u7ef4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097470.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097471.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u7528\u53cb\u7f51\u7edc\u62df\u53d1\u8d77\u8bbe\u7acb\u5317\u4eac\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097471.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097472.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u70bc\u77f3\u6709\u8272\u505c\u724c\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097472.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097480.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 17:19',
 'title': u'\u89e3\u8bfb\u4e50\u89c6\u7f51\u8d22\u62a5 \u4e50\u89c6\u6a21\u5f0f\u9700\u7834\u89e3\u201c\u4f9b\u8840\u4e0d\u8db3\u201d\u96be\u9898',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097480.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097479.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 17:19',
 'title': u'\u77f3\u69b4\u96c6\u56e2\u6536\u5173\u6ce8\u51fd\uff1a\u56e0\u5728\u975e\u6307\u5b9a\u5a92\u4f53\u4e0a\u53d1\u58f0',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097479.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097476.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u534e\u661f\u521b\u4e1a\u7ec8\u6b62\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097476.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097473.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u7ef4\u5c14\u522918\u65e5\u590d\u724c \u62df\u6536\u8d2d\u4e24\u5bb6\u73af\u4fdd\u4f01\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097473.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097474.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u4e07\u79d1A\uff1a\u6536\u8d2d\u524d\u6d77\u56fd\u9645\u65b9\u6848\u5c1a\u672a\u8fbe\u6210\u5171\u8bc6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097474.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u5929\u836f\u80a1\u4efd\u62df11.59\u4ebf\u5143\u6536\u8d2d\u91d1\u8000\u836f\u4e1a62%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html'}
2016-11-21 14:37:38 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097475.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:37:38 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097475.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u534e\u5cf0\u8d85\u7ea4\u5468\u4e94\u590d\u724c \u62df18\u4ebf\u5143\u6536\u8d2d\u79fb\u52a8\u652f\u4ed8\u670d\u52a1\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097475.html'}
2016-11-21 14:37:41 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097518.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:37:41 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097518.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:56',
 'title': u'\u5929\u9f99\u96c6\u56e2\uff1a2016\u5e74\u5ea6\u62df10\u8f6c15',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097518.html'}
2016-11-21 14:37:41 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:37:41 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 82916,
 'downloader/request_count': 277,
 'downloader/request_method_count/GET': 277,
 'downloader/response_bytes': 2394141,
 'downloader/response_count': 277,
 'downloader/response_status_count/200': 276,
 'downloader/response_status_count/302': 1,
 'dupefilter/filtered': 85,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 37, 41, 183232),
 'item_scraped_count': 227,
 'log_count/DEBUG': 506,
 'log_count/ERROR': 39,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 276,
 'scheduler/dequeued': 277,
 'scheduler/dequeued/memory': 277,
 'scheduler/enqueued': 277,
 'scheduler/enqueued/memory': 277,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2016, 11, 21, 6, 37, 31, 29078)}
2016-11-21 14:37:41 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:42:14 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:42:14 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'news'}
2016-11-21 14:42:14 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:42:14 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:42:14 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:42:14 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:42:14 [scrapy] INFO: Spider opened
2016-11-21 14:42:14 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:42:14 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_1.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_2.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_5.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_4.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_3.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_7.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Filtered duplicate request: <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098371.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_6.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_8.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098432.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098431.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/index_9.html> (referer: None)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098430.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098429.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098463.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098454.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098428.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098432.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:59',
 'title': u'\u5eb7\u8010\u727923.4\u4ebf\u5143\u8d2d\u4e70\u65d7\u8ba1\u667a\u80fd100%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098432.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098431.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:36',
 'title': u'\u54c8\u6295\u80a1\u4efd\uff1a\u5168\u8d44\u5b50\u516c\u53f8\u6c5f\u6d77\u8bc1\u5238\u62df5\u4ebf\u5143\u8bbe\u7acb\u5b50\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098431.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098433.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098498.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097799.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098497.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098466.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097809.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098430.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:44',
 'title': u'\u4e30\u5143\u80a1\u4efd\uff1a\u62df4.2\u4ebf\u5143\u5efa\u8bbe\u5e74\u4ea7\u4e07\u5428\u9502\u7535\u6c60\u6b63\u6781\u6750\u6599\u78f7\u9178\u94c1\u9502\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098430.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098429.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u5367\u9f99\u5730\u4ea7\u7ec8\u6b62\u6536\u8d2d\u58a8\u9e9f\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098429.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098463.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 20:37',
 'title': u'\u4e1c\u65b9\u7f51\u7edc\u62df35.36\u4ebf\u5143\u6536\u8d2d3\u5bb6\u5f71\u89c6\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098463.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098454.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 20:07',
 'title': u'\u5e7f\u6c47\u6c7d\u8f66\uff1a\u9644\u5c5e\u516c\u53f8\u62df66\u4ebf\u5143\u8bbe\u7acb\u5927\u8fde\u5b9d\u4fe1\u6c47\u8a89\u6c7d\u8f66\u6295\u8d44\u7ba1\u7406\u6709\u9650\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098454.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098428.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u534e\u4eea\u7535\u6c14\u906d\u63a7\u80a1\u80a1\u4e1c\u51cf\u63011030.39\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098428.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097819.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097882.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099071.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098433.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 20:01',
 'title': u'\u5929\u9f99\u5149\u7535\u8f6c\u8ba94\u5bb6\u5b50\u516c\u53f8\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098433.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098498.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 20:33',
 'title': u'\u7f8e\u5c14\u96c5\uff1a\u62df\u51fa\u8d442.55\u4ebf\u5143\u5171\u540c\u8bbe\u7acb\u4e2d\u690d\u91d1\u878d\u8d44\u4ea7\u4ea4\u6613\u4e2d\u5fc3 \u6301\u80a151%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098498.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097799.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:56',
 'title': u'\u80a1\u5e02\u8d5a\u94b1\u6548\u5e94\u663e\u73b0 \u5458\u5de5\u6301\u80a1\u8ba1\u5212\u5bc6\u96c6\u5efa\u4ed3',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097799.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099073.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099070.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098497.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 21:18',
 'title': u'\u4e09\u6c5f\u8d2d\u7269\uff1a\u62df\u52df\u8d4415\u4ebf\u5143\u7528\u4e8e\u95e8\u5e97\u6e20\u9053\u6539\u9020\u53ca\u4ed3\u50a8\u7269\u6d41\u57fa\u5730\u5347\u7ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098497.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099112.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099111.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098466.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 20:39',
 'title': u'\u4e2d\u5b89\u6d88\u65e5\u672c\u5168\u8d44\u516c\u53f8\u83b73.13\u4ebf\u5143\u8ba2\u5355',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098466.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097809.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:02',
 'title': u'\u6052\u5927\u80fd\u633d\u56de\u201c\u77ed\u7092\u201d\u4e8b\u4ef6\u4e2d\u53d7\u635f\u7684\u58f0\u8a89\u5417\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097809.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096692.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097819.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:04',
 'title': u'\u4e2d\u56fd\u6052\u5927\u589e\u6301\u4e07\u79d1\u81f39.45% \u4e07\u79d1\u91cd\u7ec4\u65b9\u6848\u5c1a\u672a\u5c18\u57c3\u843d\u5b9a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097819.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097882.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:48',
 'title': u'11\u5bb6\u516c\u53f8\u8054\u624b\u7b79\u5efa\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097882.html'}
2016-11-21 14:42:14 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099071.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u8d44\u672c\u4e0e\u5b9e\u4e1a\u7684\u77db\u4e0e\u76fe\uff1a\u5357\u73bbA\u5f00\u542f\u524d\u6d77\u4eba\u5bff\u65f6\u4ee3 \u8d70\u5411\u5f15\u5173\u6ce8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099071.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099073.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u63a2\u8bbf\u5357\u73bbA\u6210\u90fd\u5206\u516c\u53f8\uff1a\u8463\u4e8b\u957f\u6302\u9774\u603b\u7ecf\u7406\u4ecd\u5728\u5c97',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099073.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099070.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u5357\u73bbA\u98ce\u6ce2\uff1a\u4ece\u8001\u724c\u5408\u8d44\u4f01\u4e1a\u5230\u8d44\u672c\u730e\u7269\u4e4b\u65c5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099070.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099112.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u5411\u65e5\u8475\u6536\u8d2d\u5965\u80fd\u7535\u6e90\u589e\u503c\u8d8510\u500d\u906d\u95ee\u8be2 \u79f0\u5145\u7535\u6869\u524d\u666f\u5e7f\u9614',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099112.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099111.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u903e\u4e03\u6210\u4e0a\u5e02\u516c\u53f8\u5927\u80a1\u4e1c\u6301\u80a1\u4f4e\u4e8e50% \u63a7\u5236\u6743\u4e4b\u4e89\u6709\u201c\u8fc7\u6ee5\u201d\u4e4b\u5acc',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099111.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097881.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095704.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096692.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:01',
 'title': u'\u76d1\u7ba1\u90e8\u95e8\u6478\u5e95\u623f\u4f01\u53c2\u80a1\u5730\u65b9\u94f6\u884c \u623f\u4f01\u878d\u8d44\u538b\u529b\u589e\u5927',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096692.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095711.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095375.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095370.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095708.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095371.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095707.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097881.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:47',
 'title': u'\u4e1c\u963f\u963f\u80f6\u4e09\u5927\u4e3b\u5bfc\u4ea7\u54c1\u63d0\u4ef7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097881.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095704.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:19',
 'title': u'80\u540e\u8463\u4e8b\u957f\u5927\u9605\u5175\uff1a38\u4eba\u9760\u5bb6\u65cf\u4f20\u627f 4\u4eba\u767d\u624b\u8d77\u5bb6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095704.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095378.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095372.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095711.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:15',
 'title': u'\u9646\u5bb6\u5634\u56e0\u4fe1\u606f\u62ab\u9732\u906d\u4e0a\u4ea4\u6240\u95ee\u8be2 \u51fa\u552e\u8d44\u4ea7\u6d89\u5acc\u4e0d\u5f53\u5173\u8054\u4ea4\u6613',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095711.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095375.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:01',
 'title': u'\u65b0\u5b81\u7269\u6d41\u63a7\u80a1\u80a1\u4e1c\u53ca\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u5206\u522b\u51cf\u6301300\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095375.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095370.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 18:46',
 'title': u'\u4e50\u89c6\u63a7\u80a1\u64a4\u6362\u4e9a\u592a\u533a\u603b\u88c1 \u9999\u6e2f\u516c\u53f8\u88ab\u4f20\u4e24\u4e2a\u6708\u524d\u5df2\u5f00\u59cb\u88c1\u5458',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095370.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095708.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:14',
 'title': u'\u5ddd\u73af\u79d1\u6280\u5b9e\u63a7\u4eba\u610f\u89c1\u201c\u53cd\u590d\u201d\uff1f \u848b\u9752\u6625\u8463\u4e8b\u804c\u4f4d\u201c\u5f97\u800c\u590d\u5931\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095708.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095371.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 18:50',
 'title': u'\u5b9d\u5854\u5b9e\u4e1a\uff1a\u4ea4\u6613\u5f02\u5e38\u906d\u6df1\u4ea4\u6240\u95ee\u8be2 \u8981\u6c42\u8bf4\u660e\u662f\u5426\u5b58\u5728\u5185\u5e55\u4ea4\u6613',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095371.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095707.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:21',
 'title': u'\u6df1\u6e2f\u901a\u4e34\u8fd1 \u673a\u6784\u5bc6\u96c6\u8c03\u7814\u4e2d\u5c0f\u521b\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095707.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095373.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095378.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u534e\u8c0a\u96c6\u56e2\u56fd\u6709\u80a1\u4efd\u65e0\u507f\u5212\u8f6c\u5b8c\u6210',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095378.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095386.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095387.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095385.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095372.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:00',
 'title': u'\u5174\u6e90\u73af\u5883\u7b7e\u8ba2\u4f9b\u6392\u6c34\u5de5\u7a0bPPP\u9879\u76eePPP\u534f\u8bae',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095372.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095390.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095391.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095395.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095373.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:01',
 'title': u'\u534e\u5e73\u80a1\u4efd\u6301\u80a15%\u4ee5\u4e0a\u7684\u80a1\u4e1c\u51cf\u6301673.5\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095373.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095386.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u4e1c\u65b9\u521b\u4e1a\u53c2\u80a1\u516c\u53f8IPO\u83b7\u6279',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095386.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095387.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u6df1\u8d5b\u683c16\u65e5\u590d\u724c \u91cd\u7ec4\u83b7\u8bc1\u76d1\u4f1a\u6709\u6761\u4ef6\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095387.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095392.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095385.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u79d1\u8fbe\u80a1\u4efd16\u65e5\u590d\u724c \u91cd\u7ec4\u83b7\u8bc1\u76d1\u4f1a\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095385.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095397.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095394.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095390.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u4f20\u5316\u80a1\u4efd\u8bc1\u5238\u7b80\u79f0\u53d8\u66f4\u4e3a\u201c\u4f20\u5316\u667a\u8054\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095390.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095393.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095391.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5929\u5eb7\u751f\u7269\u80a1\u4e1c\u4e2d\u65b0\u5efa\u62db\u5546\u62ab\u9732\u51cf\u6301\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095391.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095399.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095395.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u6d77\u9646\u91cd\u5de5\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u63015%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095395.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095408.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095388.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095410.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095396.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095398.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095392.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u79d1\u6797\u73af\u4fdd\u80a1\u6743\u8f6c\u8ba9\u5b8c\u6210 \u4e1c\u8bda\u745e\u4e1a\u6210\u5927\u80a1\u4e1c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095392.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095397.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5229\u4e9a\u5fb7\u5458\u5de5\u6301\u80a1\u8ba1\u5212\u4e70\u51651.1%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095397.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095411.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095394.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5eb7\u8010\u7279\u5b50\u516c\u53f8\u4e2a\u522b\u4eba\u5458\u6d89\u5acc\u804c\u52a1\u4fb5\u5360',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095394.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095393.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u5367\u9f99\u5730\u4ea7\u62df\u7ec8\u6b62\u8de8\u754c\u6536\u8d2d\u6e38\u620f\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095393.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095444.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095399.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u9ec4\u5c71\u65c5\u6e38\u53c2\u80a1\u516c\u53f8IPO\u83b7\u6279',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095399.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095485.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095408.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:21',
 'title': u'\u5b81\u6ce2\u5bcc\u90a6\u8c03\u6574\u91cd\u7ec4\u65b9\u6848\u3000\u575a\u5b9a\u63a8\u8fdb\u6218\u7565\u8f6c\u578b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095408.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095388.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'*ST\u73e0\u6c5f\u91cd\u7ec4\u83b7\u5317\u4eac\u56fd\u8d44\u59d4\u6279\u590d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095388.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095410.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:40',
 'title': u'\u4e1c\u9633\u5149\u79d1\u56e0\u5173\u6d89\u91cd\u5927\u4e8b\u987916 \u65e5\u8d77\u505c\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095410.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095396.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u677e\u53d1\u80a1\u4efd\u63a7\u80a1\u80a1\u4e1c\u589e\u6301\u8ba1\u5212\u5b9e\u65bd\u5b8c\u6210',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095396.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095398.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:05',
 'title': u'\u9ad8\u4f1f\u8fbe\u80a1\u4e1c\u94f6\u8054\u79d1\u6280\u62ab\u9732\u51cf\u6301\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095398.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095413.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095442.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095411.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:41',
 'title': u'\u4e2d\u56fd\u94c1\u5efa\u53ca\u5b50\u516c\u53f8\u7ec4\u8054\u5408\u4f53\u4e2d\u6807\u6295\u8d44\u989d\u7ea6229.19 \u4ebf\u5143PPP \u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095411.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095500.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095640.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095443.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095444.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:07',
 'title': u'\u5b81\u6ce2\u97f5\u5347\uff1a\u62df\u51fa\u8d443200\u4e07\u5143\u5171\u540c\u8bbe\u7acb\u97f5\u5347\u7535\u5b50\u516c\u53f8 \u6301\u80a140%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095444.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095485.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:57',
 'title': u'\u9c7c\u8dc3\u533b\u7597\u62df8.6\u4ebf\u5143\u6536\u8d2d\u533b\u7528\u6d88\u6bd2\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095485.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095665.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095644.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095413.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 19:42',
 'title': u'\u4e2d\u822a\u4e09\u946b\u80a1\u4e1c\u97e9\u5e73\u5143\u51cf\u63011.87%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095413.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095445.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095442.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:18',
 'title': u'\u6c47\u91d1\u79d1\u628011\u670817\u65e5\u767b\u9646\u521b\u4e1a\u677f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095442.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095500.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 21:18',
 'title': u'\u73c8\u4f1f\u80a1\u4efd\u53d1\u5e03\u5168\u7403\u9996\u4f8b\u56fa\u6001\u9502\u7535\u6c60\u4e0e\u5feb\u5145\u9502\u7535\u6c60',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095500.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095693.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095640.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:50',
 'title': u'\u5357\u73bbA\u4e03\u540d\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095640.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095648.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095671.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095443.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:15',
 'title': u'\u6c38\u6cf0\u80fd\u6e90\uff1a\u5408\u8d44\u5b50\u516c\u53f8\u62df\u5411\u5357\u9633\u7535\u5382\u589e\u8d4410\u4ebf\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095443.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095665.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:57',
 'title': u'\u5e74\u7ec8\u5957\u73b0"\u6697\u6d41\u6d8c" \u6076\u610f\u51cf\u6301"\u5957\u8def\u6df1"',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095665.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095644.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:51',
 'title': u'\u4e1c\u822a\u6837\u672c\uff1a\u56fd\u8d44\u63a7\u5236\u4e0b\u591a\u4e3e\u63a8\u8fdb\u6df7\u6539',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095644.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095445.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-15 20:04',
 'title': u'\u7696\u6c5f\u7269\u6d41\uff1a\u5168\u8d44\u5b50\u516c\u53f8\u903e5\u4ebf\u5143\u6536\u8d2d\u63a7\u80a1\u80a1\u4e1c\u7535\u5382\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161115_5095445.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095693.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:09',
 'title': u'\u6052\u5927\u9ad8\u4f4d\u63a5\u76d8\u4e07\u79d1\u7384\u673a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095693.html'}
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095675.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095672.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095699.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_9.html)
2016-11-21 14:42:15 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095715.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098443.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095648.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 07:53',
 'title': u'\u4e50\u89c6\u5c06\u83b7\u201c\u597d\u540c\u5b66\u201d6\u4ebf\u7f8e\u5143\u6295\u8d44',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095648.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095671.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:01',
 'title': u'\u6559\u80b2\u4ea7\u4e1a\u8d44\u6e90\u6574\u5408\u52a0\u901f\uff08\u9644\u80a1\uff09',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095671.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095782.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095712.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095785.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095675.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:05',
 'title': u'\u5ef6\u671f\u62ab\u9732\u91cd\u5927\u8bc9\u8bbc\u4e8b\u9879 \u5339\u51f8\u5339\u88ab\u4e0a\u4ea4\u6240\u8b66\u793a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095675.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095672.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:04',
 'title': u'\u5de5\u5927\u9ad8\u65b0\u53ca\u76f8\u5173\u9ad8\u7ba1\u88ab\u516c\u5f00\u8c34\u8d23',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095672.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095765.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095795.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095763.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095699.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:16',
 'title': u'\u5357\u73bb7\u540d\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c \u5b9d\u80fd\u7cfb\u79f0\u5e76\u672a\u5e72\u6d89\u516c\u53f8\u7ecf\u8425',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095699.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095715.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:24',
 'title': u'\u201c\u5927\u91d1\u4e3b\u201d\u63a8\u6ce2\u52a9\u6f9c\u58f3\u4f30\u503c\u534a\u5e74\u7ffb\u756a\uff1a100\u4ebf\u5143\u6210\u6807\u914d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095715.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098443.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 20:03',
 'title': u'\u91d1\u9685\u5609\u4e1a\u5357\u4eac\u516c\u53f8\uff1a\u79ef\u6781\u5145\u5b9e\u571f\u5730\u50a8\u5907 \u5168\u5e74\u9884\u8ba1\u5b8c\u6210\u5408\u540c\u91d1\u989d30\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098443.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095782.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:00',
 'title': u'\u591a\u673a\u6784\u7ec4\u56e2\u5f0f\u8fdb\u9a7b\u91cd\u7ec4\u6982\u5ff5\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095782.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095712.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:14',
 'title': u'\u5265\u79bb\u71c3\u6c14\u5177\u8d44\u4ea7\u81f4\u4e3b\u4e1a\u201c\u60ac\u7a7a\u201d \u4e07\u5bb6\u4e50\u91cd\u7ec4\u906d\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095712.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095797.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095822.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095825.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095785.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:00',
 'title': u'\u9c7c\u8dc3\u533b\u7597\u62df8.63\u4ebf\u5165\u4e3b\u4e2d\u4f18\u533b\u836f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095785.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095765.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:49',
 'title': u'\u4fe1\u62ab\u4e25\u91cd\u5931\u5b9e*ST\u5de5\u65b0\u906d\u4e0a\u4ea4\u6240\u8c34\u8d23',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095765.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095795.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:16',
 'title': u'\u4eba\u6c11\u5e01\u51fb\u7a7f\u201c\u94c1\u5e95\u201d \u4e00\u5927\u6ce2\u4e0a\u5e02\u516c\u53f8\u635f\u5931\u8fc7\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095795.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095791.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095763.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:48',
 'title': u'\u4e0a\u6d77\u94f6\u884c\u4eca\u65e5\u4e0a\u5e02 \u6279\u91cf\u9020\u5bcc\u8fd16000\u5458\u5de5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095763.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095819.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095783.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095778.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095797.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:12',
 'title': u'\u8d3e\u8dc3\u4ead\u662f\u600e\u6837\u62ff\u4e0b\u957f\u6c5f\u5546\u5b66\u9662\u540c\u5b66\u76846\u4ebf\u6295\u8d44\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095797.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095822.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:13',
 'title': u'\u623f\u4f01\u878d\u8d44\u5168\u7ebf\u6536\u7d27\uff1a\u53ea\u8981\u8fd8\u6ca1\u653e\u6b3e\u7684\u90fd\u505c\u4e0b\u6765',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095822.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095825.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:13',
 'title': u'\u4e0a\u6d77\u56fd\u8d44\u6539\u9769\u5927\u5c3a\u5ea6\u7a81\u7834 \u88c5\u5165\u4f18\u8d28\u8d44\u4ea7\u76d8\u6d3b\u201c\u58f3\u201d\u8d44\u6e90',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095825.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095907.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095915.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095902.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095860.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095791.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:08',
 'title': u'\u94a2\u6784\u5de5\u7a0b\u5265\u79bb\u4f4e\u6548\u4e1a\u52a1 \u62df\u51fa\u552e\u4e24\u5bb6\u5b50\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095791.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095838.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095819.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:29',
 'title': u'\u73c8\u4f1f\u80a1\u4efd\u53d1\u5e03\u56fa\u6001\u9502\u7535\u6c60\u4ea7\u54c1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095819.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095824.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095917.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095783.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:00',
 'title': u'\u5929\u76ee\u836f\u4e1a\u91cd\u7ec4\u516d\u8fde\u8d25 \u201c\u957f\u57ce\u7cfb\u201d\u8fdb\u9000\u7ef4\u8c37',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095783.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095778.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 08:58',
 'title': u'\u4e0a\u4ea4\u6240\u76d1\u7ba1\u95ee\u8be2\u51fb\u8981\u5bb3 \u6052\u5927\u7cfb\u660e\u786e\u4e3e\u724c\u6885\u96c1\u5409\u7965\u610f\u56fe',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095778.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095913.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095907.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:33',
 'title': u'\u4e2d\u56fd\u4f53\u80b2\u603b\u5c40\u6b32\u51fa\u552e\u4e2d\u4f53\u4ea7\u4e1a \u4e07\u8fbe\u6216\u63a5\u68d2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095907.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095993.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095915.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:33',
 'title': u'\u524d\u6d77\u4eba\u5bff\u56de\u5e94\u5357\u73bb\u9ad8\u7ba1\u8f9e\u804c\uff1a\u672a\u5e72\u7ecf\u8425 \u591a\u6b21\u5584\u610f\u633d\u7559',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095915.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095995.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095902.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:34',
 'title': u'\u201c\u6700\u706b\u201d\u6e38\u8d44\u9ad8\u4f4d\u786c\u63a5\u65b0\u534e\u7f51 \u5f00\u677f\u65b0\u80a1\u706b\u4e2d\u53d6\u6817\u80dc\u7b97\u51e0\u4f55',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095902.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095860.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:17',
 'title': u'\u5357\u73bbA\u7ba1\u7406\u5c42\u52a8\u8361\u5f15\u53d1\u6df1\u4ea4\u6240\u5173\u6ce8 \u524d\u6d77\u4eba\u5bff\u7d27\u6025\u58f0\u660e\uff1a\u4ece\u672a\u5e72\u6d89\u65e5\u5e38\u7ecf\u8425',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095860.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095838.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:53',
 'title': u'11\u670816\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095838.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095824.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 09:13',
 'title': u'\u5feb\u4e50\u65f6\u4ee3\u4f30\u503c\u6210\u8c1c \u56fd\u76db\u91d1\u63a7\u6ea2\u4ef7\u6536\u8d2d5%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095824.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095917.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:33',
 'title': u'\u8d3e\u8dc3\u4ead\u597d\u540c\u5b666\u4ebf\u7f8e\u5143\u529b\u633a\u4e50\u89c6 \u79f0\u8fd9\u4e0d\u662f\u8d48\u707e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095917.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095919.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095913.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:33',
 'title': u'\u9996\u94a2\u8001\u5382\u533a\u5730\u4ef7\u4e0d\u65ad\u98d9\u6da8 \u5730\u4ea7\u5546\u79f0\u62bc\u5b9d\u4eac\u6d25\u5180\u4e00\u4f53\u5316',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095913.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095904.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095925.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095993.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 12:29',
 'title': u'\u4eac\u7cae\u5411*ST\u73e0\u6c5f\u63d0\u4f9b10\u4ebf\u5143\u8fdb\u884c\u6536\u8d2d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095993.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095994.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095996.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095995.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 12:30',
 'title': u'\u76ca\u751f\u80a1\u4efd\u505c\u724c\u7b79\u5212\u755c\u7267\u4e1a\u8d44\u4ea7\u6536\u8d2d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095995.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096082.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095919.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:33',
 'title': u'\u6052\u5927\u8bc1\u5b9e\u672a\u9ad8\u4f4d\u51cf\u6301\u6885\u96c1\u5409\u7965 \u738b\u7684\u5973\u4eba\u5230\u5e95\u88ab\u8c01\u5f03\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095919.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095904.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:34',
 'title': u'\u5b8f\u660c\u7535\u5b50\u4e0a\u5e02\u540e\u8425\u6536\u5f00\u5012\u8f66 4\u5e74\u4e70\u4e8662\u7b14\u7406\u8d22\u4ea7\u54c1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095904.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095925.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 10:37',
 'title': u'\u79d1\u8fbe\u80a1\u4efd\u4e8c\u6b21\u91cd\u7ec4\u83b7\u8bc1\u76d1\u4f1a\u65e0\u6761\u4ef6\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095925.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096071.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096182.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095994.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 12:29',
 'title': u'\u4e1c\u65b9\u5e02\u573a11%\u80a1\u6743\u65e0\u507f\u5212\u8f6c\u5434\u6c5f\u4e1c\u65b9\u56fd\u8d44',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095994.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096085.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095996.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 12:28',
 'title': u'11\u670816\u65e5\u5348\u95f4\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5095996.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096082.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 13:46',
 'title': u'\u4e0a\u6d77\u4fdd\u4ea4\u6240\u9996\u6279\u4ea7\u54c1\u4e0a\u7ebf \u6052\u751f\u7535\u5b50\u63d0\u4f9b\u6280\u672f\u652f\u6301',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096082.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096717.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096189.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096698.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096260.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_8.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096696.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096071.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 14:01',
 'title': u'\u77f3\u69b4\u96c6\u56e2\u56de\u5e94\u4e3e\u724c\u9996\u94a2\uff1a\u662f\u6218\u7565\u6295\u8d44\u8005 \u5df2\u589e\u6301\u81f37%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096071.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096182.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 15:21',
 'title': u'\u6052\u5927\u96c6\u56e2\u4ee3\u8868\uff1a\u770b\u597d\u6c34\u529b\u53d1\u7535\u884c\u4e1a\u53d1\u5c55\u524d\u666f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096182.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096085.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 13:48',
 'title': u'\u4e1c\u822a\u6210\u4e3a\u9996\u5bb6\u8363\u83b7\u4e9a\u592a\u5730\u533a\u5e74\u5ea6\u5353\u8d8a\u822a\u7a7a\u5927\u5956\u7684\u4e2d\u56fd\u822a\u7a7a\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096085.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096701.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096747.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096793.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096717.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:15',
 'title': u'\u4e24\u516c\u53f8\u6f84\u6e05\u65e0\u6295\u8d44\u4e50\u89c6\u8ba1\u5212 \u7cfb\u8463\u4e8b\u957f\u4e2a\u4eba\u6295\u8d44',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096717.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096189.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 15:35',
 'title': u'\u6052\u5927\u96c6\u56e2\u4ee3\u8868\uff1a\u9501\u5b9a12\u4e2a\u6708  \u5207\u5b9e\u7ef4\u62a4\u201c\u4e09\u516c\u201d\u79e9\u5e8f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096189.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096698.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:04',
 'title': u'\u683c\u529b\u7535\u5668\u6536\u8d2d\u73e0\u6d77\u94f6\u9686\u7ec8\u6b62',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096698.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096714.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096260.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 15:39',
 'title': u'\u6295\u670d\u4e2d\u5fc3\u4ee3\u8868\u63d0\u51fa\u4e09\u5927\u95ee\u9898',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096260.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096696.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:02',
 'title': u'\u6052\u5927\u7cfb\u79f0\u6218\u7565\u6295\u8d44\u6885\u96c1\u5409\u7965',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096696.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096794.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096736.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096810.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096740.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096750.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096701.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:06',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c\u7f57\u751f\u95e8\uff1a\u544a\u522b\u4fe1\u8be6\u8ff0\u7f18\u7531 \u5b9d\u80fd\u7cfb\u4e00\u4e00\u5426\u8ba4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096701.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096747.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:28',
 'title': u'\u5357\u73bbA\u539f\u9ad8\u7ba1\u8bb2\u8ff0\u96c6\u4f53\u79bb\u804c\u539f\u56e0\uff1a\u524d\u6d77\u4eba\u5bff5\u4efd\u8bae\u6848\u4e5f\u662f\u5bfc\u706b\u7d22',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096747.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096741.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096793.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:40',
 'title': u'463\u5bb6\u516c\u53f8\u4e34\u8fd1\u88ab\u4e3e\u724c \u89e3\u5bc6\u4e09\u884c\u4e1a74\u53ea\u4e3e\u724c\u6f5c\u529b\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096793.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096814.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096827.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096714.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:14',
 'title': u'IPO\u53d1\u884c\u63d0\u901f \u5f71\u5b50\u80a1\u6709\u671b\u53d7\u76ca',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096714.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096794.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:40',
 'title': u'\u4e0a\u6d77\u56fd\u4f01\u6539\u9769\u518d\u6380\u9ad8\u6f6e \u673a\u6784\u9884\u8ba16\u53ea\u9f99\u5934\u80a1\u76ee\u6807\u6da8\u5e45\u8d8550%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096794.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096736.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:23',
 'title': u'\u683c\u529b\u8463\u660e\u73e0\u9020\u8f66\u201c\u68a6\u788e\u201d \u7ec8\u6b62\u6536\u8d2d\u73e0\u6d77\u94f6\u9686\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096736.html'}
2016-11-21 14:42:16 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096801.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096810.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:47',
 'title': u'\u77f3\u69b4\u96c6\u56e2\u81ea\u66dd\u589e\u6301\u52a8\u5411 \u9996\u94a2\u80a1\u4efd\u80a1\u4ef7\u5e94\u58f0\u800c\u6da8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096810.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096740.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:26',
 'title': u'\u817e\u4fe1\u80a1\u4efd\u53ca\u5b9e\u63a7\u4eba\u6d89\u5acc\u5411\u6700\u9ad8\u9662\u539f\u526f\u9662\u957f\u4e4b\u5b50\u884c\u8d3f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096740.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096863.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096813.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096750.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:29',
 'title': u'\u201c\u5b9d\u80fd\u7cfb\u201d\u5bf9\u51b3\u5357\u73bb\u7ba1\u7406\u5c42 \u4e09\u5927\u7591\u70b9\u5f85\u89e3',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096750.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096741.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:26',
 'title': u'\u83ab\u9ad8\u80a1\u4efd\u906d\u4e09\u5ea6\u4e3e\u724c \u63a7\u80a1\u80a1\u4e1c\u7b79\u5212\u5b9a\u589e\u53cd\u51fb\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096741.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096811.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096814.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:46',
 'title': u'\u5468\u9e3f\u794e\u8c08360\u56de\u5f52\u56de\u5f52:\u786e\u4e0e\u56fd\u5bb6\u7f51\u7edc\u5b89\u5168\u6218\u7565\u6709\u5173',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096814.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096859.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096827.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:51',
 'title': u'\u8bc4\u8bba:\u5357\u73bb\u4e8b\u4ef6\u6298\u5c04\u8d44\u672c\u4e0e\u804c\u4e1a\u7ecf\u7406\u4eba\u5171\u5904\u56f0\u5883',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096827.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096858.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096801.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:45',
 'title': u'\u52df\u6295\u9879\u76ee\u8fdb\u5c55\u4e0d\u53ca\u9884\u671f \u5305\u94a2\u80a1\u4efd\u906d\u4e0a\u4ea4\u6240\u4e8c\u6b21\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096801.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096870.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096863.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u4e2d\u7535\u5e7f\u901a\u5265\u79bb\u539f\u4e1a\u52a1 \u63fd\u5165\u519b\u5de5\u7535\u5b50\u6807\u7684',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096863.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096862.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096813.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:46',
 'title': u'PPP\u6982\u5ff5\u201c\u62db\u8702\u5f15\u8776\u201d \u673a\u6784\u7784\u4e0a\u5efa\u7b51\u88c5\u9970\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096813.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096871.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096811.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:46',
 'title': u'\u5927\u8fde\u4e0a\u5e02\u516c\u53f8\u91cd\u7ec4\u201c\u751f\u610f\u7ecf\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096811.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096864.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096861.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096859.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bbA\u8001\u5458\u5de5\u8f9e\u804c\u98ce\u6ce2\u8d8a\u95f9\u8d8a\u5927 \u5357\u73bb\u5b9d\u80fd\u5404\u6267\u4e00\u8bcd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096859.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096868.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096858.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bb\u5bab\u6597\u771f\u76f8\u53e3\u6c34\u6218\u4e2d\u6108\u53d1\u6a21\u7cca \u5f53\u4e8b\u53cc\u65b9\u5404\u6267\u4e00\u8bcd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096858.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096867.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096870.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u96c6\u4f53\u8f9e\u804c\uff1a\u4e07\u79d1\u5267\u60c5\u7684\u9884\u6f14?',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096870.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096862.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bb8\u9ad8\u7ba1\u8f9e\u804c \u524d\u6d77\u4eba\u5bff\uff1a\u80a1\u6743\u6fc0\u52b1\u53ea\u662f\u501f\u53e3',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096862.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096869.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096871.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u7f8e\u56fd\u4e50\u89c6\u6c7d\u8f66\u56de\u5e94\u505c\u4ea7:\u9879\u76ee\u4ece\u672a\u505c\u5de5 \u8d44\u91d1\u5c06\u5230\u4f4d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096871.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096864.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u79bb\u804c\u80cc\u540e \u6838\u5fc3\u6280\u672f\u53bbor\u7559',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096864.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096861.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bbA\u4ee3\u7406\u8463\u4e8b\u957f\u9648\u7433\u9996\u53d1\u58f0\uff1a\u8981\u4fdd\u62a4\u597d\u5168\u4f53\u80a1\u4e1c\u6743\u76ca',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096861.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096868.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u4e09\u6cf0\u63a7\u80a1\u5b9a\u589e\u4ef7\u5012\u6302 \u89e3\u7981\u80a1\u4e1c\u201c\u5e72\u77aa\u773c\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096868.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096878.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096363.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096867.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:03',
 'title': u'\u5357\u73bbA\u518d\u6536\u6df1\u4ea4\u6240\u5173\u6ce8\u51fd \u8981\u6c42\u5176\u5bf9\u5a92\u4f53\u62a5\u9053\u53ca\u6295\u8bc9\u4e3e\u62a5\u4e88\u4ee5\u6838\u67e5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096867.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096873.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096872.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096932.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_6.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096362.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096366.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096361.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096869.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u4e2d\u6c47\u5f71\u89c6\u9690\u7792\u5bf9\u8d4c \u4e09\u4e03\u4e92\u5a31\u65e7\u6807\u7684\u518d\u9047\u632b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096869.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096318.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096878.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 08:54',
 'title': u'\u91d1\u660e\u7cbe\u673a\u6301\u7eed\u63a8\u8fdb\u201c\u667a\u80fd\u5236\u9020+\u5927\u5065\u5eb7\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096878.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096363.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:34',
 'title': u'11\u670817\u65e5\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1\uff1a\u4e2d\u7535\u5e7f\u901a\u62df\u5265\u79bb\u4f20\u7edf\u4e1a\u52a1 \u7f6e\u5165\u519b\u5de5\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096363.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096873.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u6885\u96c1\u5409\u7965\u5982\u4f55\u6f14\u7ece\u201c\u540e\u6052\u5927\u65f6\u4ee3\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096873.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096872.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 09:01',
 'title': u'\u6668\u9e23\u7eb8\u4e1a\u8fde\u7eed\u591a\u6b21\u63d0\u4ef7 \u201c\u6d1b\u9633\u7eb8\u8d35\u201d\u535a\u5f08\u4eba\u6c11\u5e01\u8d2c\u503c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096872.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096932.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 10:12',
 'title': u'11\u670817\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096932.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096398.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096410.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096362.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:31',
 'title': u'\u683c\u529b\u7535\u5668\u62df\u7ec8\u6b62\u6536\u8d2d\u73e0\u6d77\u94f6\u9686 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096362.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096366.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:23',
 'title': u'\u6df1\u4ea4\u6240\u5411\u5357\u73bbA\u518d\u53d1\u5173\u6ce8\u51fd \u5357\u73bbA\u8463\u79d8\u53ca\u4e24\u72ec\u7acb\u8463\u4e8b\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096366.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096361.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:31',
 'title': u'\u91d1\u5cad\u77ff\u4e1a\u62df\u7ec8\u6b62\u7b79\u5212\u8d2d\u4e70\u8d44\u4ea7 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096361.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096318.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 17:04',
 'title': u'11\u670817\u65e5\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096318.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096381.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096397.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096382.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096399.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096402.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096411.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096398.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:26',
 'title': u'\u592a\u6781\u5b9e\u4e1a\u63a7\u80a1\u5b50\u516c\u53f8\u4e2d\u6807\u91d1\u989d\u903e10.5\u4ebf\u5143\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096398.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096410.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4ebf\u6676\u5149\u7535\u906d\u63a7\u80a1\u80a1\u4e1c\u51cf\u63011500\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096410.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096420.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096381.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:35',
 'title': u'11\u670817\u65e5\u589e\u51cf\u6301\uff1a\u4ebf\u6676\u5149\u7535\u906d\u63a7\u80a1\u80a1\u4e1c\u51cf\u63011500\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096381.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096397.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:24',
 'title': u'\u683c\u529b\u7535\u5668\u7ec8\u6b62\u53d1\u884c\u80a1\u4efd\u6536\u8d2d\u73e0\u6d77\u94f6\u9686',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096397.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096414.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096382.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:34',
 'title': u'11\u670817\u65e5\u91cd\u5927\u505c\u590d\u724c\uff1a\u683c\u529b\u7535\u5668\u62df\u7ec8\u6b62\u6536\u8d2d\u73e0\u6d77\u94f6\u9686 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096382.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096399.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:27',
 'title': u'\u673a\u5668\u4eba1.2\u4ebf\u80a1\u9650\u552e\u80a1\u89e3\u7981 1\u4ebf\u80a121\u65e5\u53ef\u4e0a\u5e02\u6d41\u901a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096399.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096402.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 18:45',
 'title': u'\u5357\u73bbA\u56e0\u7ba1\u7406\u5c42\u52a8\u8361\u518d\u6536\u6df1\u4ea4\u6240\u5173\u6ce8\u51fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096402.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096411.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e91\u5357\u767d\u836f\uff1a\u96c6\u56e2\u6df7\u6539\u65b0\u5b9e\u65bd\u8def\u5f84\u5df2\u5f97\u5230\u5404\u65b9\u8ba4\u53ef',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096411.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096416.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096412.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096415.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096421.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096418.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096420.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u5e0c\u52aa\u5c14\u7ec8\u6b62\u7b79\u5212\u91cd\u5927\u4e8b\u9879 17\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096420.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096417.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096414.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:42',
 'title': u'\u5357\u73bb\u8463\u79d8\u53ca\u603b\u4f1a\u8ba1\u5e08\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096414.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096422.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096416.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u9c81\u4ebf\u901a\u80a1\u4e1c\u9646\u91d1\u6d77\u51cf\u63012.35%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096416.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096427.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096412.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u56fd\u52a8\u529b\u80a1\u4e1c\u589e\u6301\u8ba1\u5212\u5b9e\u65bd\u5b8c\u6bd5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096412.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096430.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096415.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:42',
 'title': u'\u7eff\u53f6\u96c6\u56e2\u5218\u6bbf\u6ce2\u56de\u5e94\uff1a\u4e50\u89c6\u6709\u96be \u4e2a\u4eba\u62c9\u5144\u5f1f\u4e00\u628a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096415.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096421.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e1c\u6770\u667a\u80fd\u80a1\u4e1c\u5883\u754c\u6295\u8d44\u51cf\u63011.42%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096421.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096423.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096418.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u6d77\u53d1\u5c55\u66f4\u540d\u201c\u4e2d\u8fdc\u6d77\u80fd\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096418.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096424.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096417.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u5e7f\u751f\u5802\u63a7\u80a1\u80a1\u4e1c\u589e\u6301\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096417.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096422.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u82f1\u98de\u62d3\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096422.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096425.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096465.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096427.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u9c81\u6297\u533b\u836f\u505c\u724c\u7b79\u5212\u975e\u516c\u5f00\u53d1\u884c\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096427.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096429.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096430.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u7535\u5e7f\u901a\u62df\u5265\u79bb\u4f20\u7edf\u4e1a\u52a1 \u7f6e\u5165\u519b\u5de5\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096430.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096434.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096423.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u8fbd\u5b81\u6210\u5927\u62df4.2\u4ebf\u5143\u51fa\u552e\u5bb6\u4e50\u798f\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096423.html'}
2016-11-21 14:42:17 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096428.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:17 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096424.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u7eff\u53f6\u5236\u836f\u6f84\u6e05 \u5e76\u65e0\u4e0e\u4e50\u89c6\u8ba2\u7acb\u4efb\u4f55\u6295\u8d44\u5b89\u6392',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096424.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096446.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096425.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u897f\u85cf\u836f\u4e1a\u5b9a\u589e\u7533\u8bf7\u83b7\u8bc1\u76d1\u4f1a\u5ba1\u6838\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096425.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096464.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096465.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:01',
 'title': u'\u5929\u80fd\u91cd\u5de5\u4e2d\u7b7e\u73870.02613%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096465.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099113.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096487.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096538.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096497.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099114.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096429.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u84dd\u5149\u53d1\u5c55\u906d\u80a1\u4e1c\u51cf\u63012300\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096429.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096434.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:47',
 'title': u'\u6842\u53d1\u7965\u3001\u51ef\u83b1\u82f118\u65e5\u4e2d\u5c0f\u677f\u4e0a\u5e02',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096434.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096428.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u4e2d\u6bc5\u8fbe\u56e0\u6d89\u5acc\u4fe1\u62ab\u8fdd\u6cd5\u8fdd\u89c4\u906d\u7acb\u6848\u8c03\u67e5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096428.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096446.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:28',
 'title': u'\u79d1\u529b\u8fdc\uff1a\u62df\u51fa\u8d4414\u4ebf\u5143\u5171\u540c\u8bbe\u7acb\u6df7\u5408\u52a8\u529b\u6280\u672f\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096446.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096464.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:01',
 'title': u'\u534e\u9e4f\u98de\u80a1\u4e1c\u51cf\u63011100\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096464.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096484.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096500.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099121.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099123.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099115.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099124.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099116.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099125.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099122.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099113.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u534e\u95fb\u4f20\u5a92\u7b4910\u5bb6\u516c\u53f8\u6d89\u80a1\u6743\u8f6c\u8ba9 3\u4ebf\u6e38\u8d44\u8ffd\u63676\u53ea\u6982\u5ff5\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099113.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096487.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:45',
 'title': u'\u8fbd\u5b81\u6210\u5927\uff1a\u62df4.2\u4ebf\u5143\u51fa\u552e\u5bb6\u4e50\u798f\u5168\u90e8\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096487.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096538.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 21:37',
 'title': u'\u5149\u660e\u5730\u4ea7\uff1a\u62df10\u4ebf\u5143\u8f6c\u8ba9\u6240\u6301\u90e8\u5206\u7269\u4e1a\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096538.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096497.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 21:00',
 'title': u'\u683c\u529b\u7535\u5668\uff1a\u7ec8\u6b62\u7b79\u5212\u53d1\u884c\u80a1\u4efd\u8d2d\u4e70\u8d44\u4ea7\u4e8b\u5b9c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096497.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099114.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:54',
 'title': u'\u738b\u77f36\u5e74\u6765\u9996\u6b21\u53c2\u52a0\u5a92\u4f53\u4f1a \u5173\u4e8e\u5b9d\u4e07\u4e4b\u4e89\u8bf4\u4e86\u4e94\u4ef6\u91cd\u8981\u7684\u4e8b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099114.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096484.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 20:47',
 'title': u'\u4eba\u4e8b\u53d8\u52a8\u7ee7\u7eed \u5357\u73bbA\u8463\u79d8\u53ca\u4e24\u72ec\u7acb\u8463\u4e8b\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096484.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096500.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 21:08',
 'title': u'\u5eb7\u5f97\u65b0\uff1a\u62df\u63a8\u603b\u89c4\u6a216\u4ebf\u5143\u5458\u5de5\u6301\u80a1\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096500.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099121.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u534e\u5851\u63a7\u80a1\u7529\u591a\u5e74\u201c\u5305\u88b1\u201d\uff1a\u63a7\u80a1\u5b50\u516c\u53f8\u7533\u8bf7\u7834\u4ea7\u6e05\u7b97',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099121.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099148.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099154.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099155.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099126.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099156.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099157.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099146.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099123.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u4e50\u89c6\u6f6e\u9000\u516c\u52df\u4e50\u7c89\u4f55\u53bb\u4f55\u4ece\uff1a\u91cd\u4ed3\u673a\u6784\u6295\u8d44\u8005\u6216\u906d\u91cd\u632b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099123.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099115.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:55',
 'title': u'\u5168\u90e8\u505c\u4ea7\uff01\u77f3\u836f\u96c6\u56e2\u534e\u5317\u5236\u836f\u7b49\u591a\u5bb6\u4e0a\u5e02\u836f\u4f01\u8eba\u67aa\u73af\u4fdd\u4ee4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099115.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099124.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u76d8\u70b95\u5927\u795e\u5947\u58f3\u516c\u53f8\uff1a\u62ff\u5230\u4e00\u4e2a\u5341\u591a\u5929\u5c31\u80fd\u8d5a\u51e0\u5341\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099124.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099116.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 09:19',
 'title': u'\u300a\u6f58\u91d1\u83b2\u300b\u7275\u51fa\u5bf9\u8d4c\u534f\u8bae\uff1a\u51af\u5bfc\u4e3a6000\u4e07\u4e1a\u7ee9\u627f\u8bfa\u4e0d\u60dc\u6495\u7834\u8138',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099116.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099125.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u4e50\u89c6\u4e24\u9879\u76ee\u672a\u73b0\u65bd\u5de5\u8ff9\u8c61 \u6d89\u6295\u8d44\u989d600\u4ebf',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099125.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099122.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:52',
 'title': u'\u4e50\u89c6\u6c7d\u8f66200\u4ebf\u83ab\u5e72\u5c71\u5de5\u5382\u4e0b\u6708\u5960\u57fa\uff1a\u5b98\u5458\u79f0\u4e50\u89c6\u80af\u5b9a\u62ff\u5730',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099122.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099148.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u6d77\u80fd\u8fbe\u62df\u5b9a\u589e\u52df\u8d4410\u4ebf \u672c\u6b21\u5b9a\u589e\u5168\u90e8\u7531\u81ea\u5bb6\u4eba\u5305\u63fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099148.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099158.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099163.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099168.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099169.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099170.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099171.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099172.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099154.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u4e2d\u5b89\u6d88\u83b7\u65e5\u672c3.13\u4ebf\u5143\u5927\u5355 \u5c06\u6709\u5229\u4e8e\u8fdb\u4e00\u6b65\u62d3\u5bbd\u5883\u5916\u5e02\u573a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099154.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099155.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u80a1\u4ef7\u8fde\u521b\u65b0\u9ad8\u80cc\u540e \u91d1\u83b1\u7279\u62ff\u4ec0\u4e48\u6491\u8d77\u9ad8\u4f30\u503c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099155.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099126.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:44',
 'title': u'\u4e07\u8fbe\u9662\u7ebf\u6b32\u6253\u901a\u5168\u4ea7\u4e1a\u94fe \u767e\u4f59\u673a\u6784\u8c03\u7814',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099126.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099156.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:05',
 'title': u'\u6807\u7684\u8d44\u4ea7\u4e1a\u7ee9\u672a\u8fbe\u9884\u671f \u76db\u6d0b\u79d1\u6280\u7ec8\u6b62\u91cd\u7ec4\u906d\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099156.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099157.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:09',
 'title': u'\u56de\u590d\u6df1\u4ea4\u6240\u91cd\u7ec4\u95ee\u8be2\u51fd \u4e1c\u65b9\u7f51\u7edc\u610f\u5728\u589e\u5f3a\u5185\u5bb9\u63d0\u4f9b\u80fd\u529b',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099157.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099146.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:00',
 'title': u'11\u670821\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099146.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099232.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099352.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099358.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099360.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099365.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099368.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099158.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:09',
 'title': u'\u4e0a\u6d77\u5929\u73ae100%\u80a1\u67433.42\u4ebf\u5143\u6302\u724c\u8f6c\u8ba9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099158.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099163.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 09:58',
 'title': u'\u745e\u4e30\u9ad8\u6750\u62df\u6536\u8d2d\u62df\u4e0a\u5e02\u516c\u53f8\u6c5f\u82cf\u548c\u65f6\u5229',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099163.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099168.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:21',
 'title': u'\u745e\u548c\u80a1\u4efd\u6da8\u505c \u62df10\u8f6c25\u6d3e2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099168.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099169.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:21',
 'title': u'\u897f\u90e8\u8d44\u6e90\u7b499\u516c\u53f8\u56e0\u91cd\u8981\u4e8b\u987921\u65e5\u8d77\u505c\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099169.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099170.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:21',
 'title': u'8\u59294\u6b21 \u96f7\u67cf\u79d1\u6280\u63a7\u80a1\u80a1\u4e1c\u51cf\u6301\u4e0a\u763e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099170.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099171.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:22',
 'title': u'\u65b9\u6848\u4e24\u6b21\u88ab\u5426 \u5965\u7ef4\u901a\u4fe1\u7ec8\u6b62\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099171.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099172.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:22',
 'title': u'11\u6708\u795e\u534e5500\u52a8\u529b\u7164\u518d\u4e0b\u8c035\u5143/\u5428',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099172.html'}
2016-11-21 14:42:18 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:18 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099232.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 10:50',
 'title': u'\u91d1\u5c71\u8f6f\u4ef6\u7b2c\u4e09\u5b63\u5ea6\u8425\u6536\u540c\u6bd4\u589e\u957f\u8fd1\u4e94\u6210',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099232.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099352.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 12:13',
 'title': u'\u901a\u5bcc\u5fae\u7535\u83b7\u5f97\u653f\u5e9c\u8865\u52a93080\u4e07\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099352.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099358.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 12:33',
 'title': u'\u91d1\u57ce\u80a1\u4efd\u62df\u66f4\u540d\u795e\u96fe\u8282\u80fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099358.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099360.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 12:39',
 'title': u'\u4e09\u836f\u4f01\u62ab\u9732\u505c\u724c\u539f\u7531 \u5609\u5e94\u5236\u836f\u63a7\u80a1\u6743\u6216\u8f6c\u8ba9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099360.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098999.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099365.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 13:03',
 'title': u'\u5929\u745e\u4eea\u5668\u62df3.6\u4ebf\u6536\u8d2d\u4f53\u5916\u8bca\u65ad\u4ea7\u54c1\u4f01\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099365.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098986.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098996.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097700.html> (referer: http://www.cs.com.cn/ssgs/gsxw/)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097884.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097475.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099368.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 13:04',
 'title': u'11\u670821\u65e5\u5348\u95f4\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5099368.html'}
2016-11-21 14:42:19 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 34, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098999.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:09',
 'title': u'11\u670821\u65e5\u91cd\u5927\u505c\u590d\u724c\uff1a*ST\u5357\u7535\u7ec8\u6b62\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4 21\u65e5\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098999.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097886.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_3.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097480.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097485.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098986.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 07:58',
 'title': u'11\u670821\u65e5\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098986.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098996.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-21 08:05',
 'title': u'11\u670821\u65e5\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161121_5098996.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097700.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:11',
 'title': u'\u539f\u9ad8\u7ba1\u7ec6\u8ff01114\u8463\u4e8b\u4f1a\u5185\u60c5 \u5357\u73bbA\u4e71\u5c40\u7f18\u8d77\u65e9\u751f\u5acc\u9699\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097700.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097884.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:49',
 'title': u'\u534e\u661f\u521b\u4e1a\u7ec8\u6b62\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097884.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097475.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u534e\u5cf0\u8d85\u7ea4\u5468\u4e94\u590d\u724c \u62df18\u4ebf\u5143\u6536\u8d2d\u79fb\u52a8\u652f\u4ed8\u670d\u52a1\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097475.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097497.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097512.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096431.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_7.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097476.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097886.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:51',
 'title': u'11\u670818\u65e5\u6da8\u505c\u80a1\u63ed\u79d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097886.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097480.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 17:19',
 'title': u'\u89e3\u8bfb\u4e50\u89c6\u7f51\u8d22\u62a5 \u4e50\u89c6\u6a21\u5f0f\u9700\u7834\u89e3\u201c\u4f9b\u8840\u4e0d\u8db3\u201d\u96be\u9898',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097480.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097518.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097493.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u5929\u836f\u80a1\u4efd\u62df11.59\u4ebf\u5143\u6536\u8d2d\u91d1\u8000\u836f\u4e1a62%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097481.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097485.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 17:18',
 'title': u'\u201c\u5bfc\u706b\u7d22\u201d\u5357\u73bbA\u80a1\u6743\u8ba1\u5212\u7ec6\u8282\u62ab\u9732 6.2\u5143\u6fc0\u52b1\u4ef7\u4ec5\u4e3a\u5f53\u65f6\u5e02\u4ef7\u4e00\u534a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097485.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097479.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097497.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:25',
 'title': u'\u5357\u73bbA\u9ad8\u7ba1\u96c6\u4f53\u79bb\u804c\u5185\u5e55\uff1a\u59da\u632f\u534e\u6ca1\u63a5\u524d\u8463\u4e8b\u957f\u66fe\u5357\u7535\u8bdd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097497.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097511.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097512.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:24',
 'title': u'\u4e50\u89c6\u9ad8\u5c42\u56de\u5e94\u201c\u5e9e\u6c0f\u9a97\u5c40\u8bf4\u201d \uff1a\u6b63\u5168\u529b\u4ee5\u8d74\u628a\u94b1\u8f6c\u5230\u7f8e\u56fd\u6c7d\u8f66\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097512.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096431.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-16 19:41',
 'title': u'\u5e7f\u7530\u96c6\u56e2\u505c\u724c\u7b79\u5212\u6536\u8d2d\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161116_5096431.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097476.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u534e\u661f\u521b\u4e1a\u7ec8\u6b62\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097476.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097519.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097518.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:56',
 'title': u'\u5929\u9f99\u96c6\u56e2\uff1a2016\u5e74\u5ea6\u62df10\u8f6c15',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097518.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097528.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097493.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:24',
 'title': u'\u5357\u73bbA17\u65e5\u518d\u906d\u6df1\u4ea4\u6240\u95ee\u8be2 \u8981\u6c42\u8bf4\u660e\u524d\u6d77\u4eba\u5bff\u662f\u5426\u5e72\u9884\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097493.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097530.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097532.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097479.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 17:19',
 'title': u'\u77f3\u69b4\u96c6\u56e2\u6536\u5173\u6ce8\u51fd\uff1a\u56e0\u5728\u975e\u6307\u5b9a\u5a92\u4f53\u4e0a\u53d1\u58f0',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097479.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097525.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097558.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097511.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:24',
 'title': u'\u5929\u9f99\u96c6\u56e2\uff1a2016\u5e74\u5ea6\u62df10\u8f6c15\u6d3e0.5 \u591a\u4f4d\u80a1\u4e1c\u62df\u5de8\u91cf\u51cf\u6301',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097511.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097675.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097560.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097519.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:57',
 'title': u'\u90d1\u7164\u673a\u56e0\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4e8b\u9879\u5c06\u4e0a\u4f1a17\u65e5\u5f00\u5e02\u8d77\u505c\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097519.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097528.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:50',
 'title': u'11\u5bb6\u4e0a\u5e02\u516c\u53f8\u62df\u53c2\u4e0e\u7b79\u529e\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097528.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097696.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097530.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:10',
 'title': u'\u5c71\u4e1c\u534e\u9e4f\u516c\u544a\u9ad8\u9001\u8f6c\u7cfb\u8bef\u4f20',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097530.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097746.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097532.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:06',
 'title': u'\u4e2d\u901a\u56fd\u810911\u670818\u65e5\u7f51\u4e0a\u7533\u8d2d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097532.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097525.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:58',
 'title': u'\u82cf\u5b81\u6613\u8d2d\u201c\u7b11\u503e\u57ce\u201d\u63ed\u5e55',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097525.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097558.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:35',
 'title': u'\u65d7\u6ee8\u96c6\u56e2\u56e0\u5357\u73bbA\u4eba\u4e8b\u53d8\u52a8\u906d\u4e0a\u4ea4\u6240\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097558.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097733.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097565.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097678.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097675.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:03',
 'title': u'\u6c42\u89e3\u5357\u73bb\u4e71\u5c40\uff1a\u5171\u8d62\u987b\u5b88\u89c4\u5219\u5efa\u673a\u5236',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097675.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097689.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097560.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:38',
 'title': u'\u9686\u946b\u901a\u7528\uff1a\u62df4111\u4e07\u6b27\u5143\u83b7\u53d6\u610f\u5927\u5229\u516c\u53f8\u7ea667%\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097560.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097745.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097694.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097713.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097696.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:10',
 'title': u'\u5b9d\u80fd\u7cfb\u5168\u9762\u63a5\u7ba1\u5357\u73bb \u76d1\u7ba1\u90e8\u95e8\u8fde\u53d1\u5173\u6ce8\u51fd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097696.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097742.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097746.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:31',
 'title': u'\u76d1\u7ba1\u201c\u96f7\u9706\u51fa\u51fb\u201d\u623f\u5730\u4ea7\u4fe1\u6258\u4e1a\u52a1 \u4fe1\u6258\u516c\u53f8\u4e25\u9635\u4ee5\u5f85',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097746.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097774.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097733.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:30',
 'title': u'\u4e07\u79d1\u80a1\u6743\u4e89\u593a\u6218\u6108\u6f14\u6108\u70c8\uff1a\u6052\u5927\u7ee7\u7eed\u589e\u6301 \u4e2d\u7b56\u5bcc\u6c47\u201c\u62cd\u9a6c\u6740\u5165\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097733.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097565.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 21:39',
 'title': u'\u79cb\u6797\u96c6\u56e2\uff1a\u62df1\u4ebf\u5143\u5728\u6df1\u5733\u8bbe\u7acb\u73e0\u5b9d\u7ecf\u8425\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097565.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097783.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097796.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097678.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:04',
 'title': u'\u56fd\u4f01\u6539\u9769\u201c\u94c1\u5854\u6a21\u5f0f\u201d\uff1a\u201c\u91cd\u7ec4 \u4e0a\u5e02\u201d\u76d8\u6d3b\u56fd\u6709\u8d44\u672c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097678.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097689.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:07',
 'title': u'\u5357\u73bbA\u539f\u9ad8\u7ba1\u4e0e\u524d\u6d77\u4eba\u5bff\u7ea0\u7eb7\u518d\u8d77\u6ce2\u6f9c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097689.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097745.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:32',
 'title': u'\u5b89\u90a6\u51fa\u624b\uff01113\u4ebf\u5143\u4e3e\u724c\u4e2d\u56fd\u5efa\u7b51\u56fe\u4e2a\u5565\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097745.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097767.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097694.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:09',
 'title': u'\u524d\u6d77\u4eba\u5bff\u5357\u73bbA\u8f9e\u804c\u9ad8\u7ba1\u5404\u6267\u4e00\u8bcd \u5b9d\u80fd\u7cfb\u9762\u4e34\u7ba1\u7406\u6311\u6218',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097694.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097713.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:10',
 'title': u'\u5230\u5e95\u662f\u8c01"\u73bb\u7483\u5fc3"\uff1f\u5357\u73bbA\u98ce\u6ce2\u591a\u65b9\u5404\u6267\u4e00\u8bcd\u6ce2\u6f9c\u4e0d\u65ad',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097713.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097768.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097742.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:32',
 'title': u'\u4e0a\u5e02\u516c\u53f8\u5e76\u8d2d\u95ef\u5173\u5b58\u4e09\u5927\u6740\u5668 \u63a7\u5236\u6743\u6210\u5173\u6ce8\u65b0\u7126\u70b9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097742.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096992.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097765.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097775.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097774.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:45',
 'title': u'\u957f\u57ce\u52a8\u6f2b\u51fa\u552e\u5723\u8fbe\u7126\u5316 \u62d6\u6b20\u8d27\u6b3e\u5ba2\u6237\u5fb7\u80dc\u96c6\u56e28\u6298\u63a5\u76d8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097774.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097776.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097783.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:47',
 'title': u'A\u80a1\u201c\u58f3\u201d\u751f\u610f\u98ce\u751f\u6c34\u8d77 \u5404\u8def\u8d44\u672c\u7eb7\u5230\u201c\u7897\u91cc\u6765\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097783.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097796.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:56',
 'title': u'\u906d\u9047\u5f3a\u52bf\u5165\u4e3b\u201c\u540e\u9057\u75c7\u201d \u5916\u6765\u8d44\u672c\u5982\u4f55\u6597\u800c\u4e0d\u7834',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097796.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097051.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097797.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097767.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:43',
 'title': u'\u91cd\u6574\u8ba1\u5212\u83b7\u901a\u8fc7 *ST\u4e91\u7ef4\u4fdd\u58f3\u9700\u626d\u8f6c\u8fd110\u4ebf\u5de8\u4e8f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097767.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097798.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_4.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097768.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:43',
 'title': u'\u6b4c\u534e\u6709\u7ebf\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u8868\u73b0\u62a2\u773c \u65b0\u5a92\u4f53\u8f6c\u578b\u6548\u679c\u663e\u73b0',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097768.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097247.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096992.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 11:01',
 'title': u'\u5357\u73bbA\u79bb\u804c\u9ad8\u7ba1\u79f0\u96c6\u4f53\u8df3\u69fd\u81f3\u65d7\u6ee8\u96c6\u56e2\u662f\u8c23\u4f20',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5096992.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097765.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:42',
 'title': u'\u529b\u5e06\u80a1\u4efd\u62df1.7\u4ebf\u5143\u5265\u79bb\u5b89\u8bda\u4fdd\u9669\u80a1\u4efd \u6536\u7f29\u91d1\u878d\u201c\u8f93\u8840\u201d\u65b0\u80fd\u6e90',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097765.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097775.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:44',
 'title': u'28\u4ebf\u9a70\u63f4\u8d5b\u7ef4\u7834\u4ea7\u91cd\u6574 \u6613\u6210\u65b0\u80fd\u8bd5\u6c34\u53e6\u7c7b\u201c\u503a\u8f6c\u80a1\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097775.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097776.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:47',
 'title': u'\u201c\u95e8\u53e3\u7684\u91ce\u86ee\u4eba\u201d\u518d\u73b0 \u6da8\u505c\u7684\u5357\u73bbA\u80cc\u540e\u8fd8\u6709\u8fd9\u4e9b\u65e0\u4e3b\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097776.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097050.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097051.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:42',
 'title': u'\u5b9c\u660c\u4ea4\u8fd0\u5b50\u516c\u53f8\u4e24\u5904\u623f\u5c4b\u5c06\u88ab\u5f81\u6536',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097051.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097386.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097049.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097797.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:57',
 'title': u'\u6d77\u6da6\u5149\u4f0f\u4ea7\u4e1a\u57fa\u91d1\u8ba1\u5212\u88ab\u95ee\u8be2 \u671d\u4ee4\u5915\u6539\u4e14\u8bbe\u4e0d\u5e73\u7b49\u6761\u7ea6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097797.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097798.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 08:57',
 'title': u'\u9996\u6279\u5e74\u62a5\u201c\u9884\u9001\u8f6c\u201d\u65b9\u6848\u51fa\u7089',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097798.html'}
2016-11-21 14:42:19 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097060.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:19 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097247.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 16:26',
 'title': u'11\u670818\u65e5\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a\uff1a\u4e07\u79d1A\uff1a\u6536\u8d2d\u524d\u6d77\u56fd\u9645\u65b9\u6848\u5c1a\u672a\u8fbe\u6210\u5171\u8bc6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097247.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097059.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097376.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097381.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097050.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:42',
 'title': u'\u6d59\u5bcc\u63a7\u80a1\u4e2d\u68071.3\u4ebf\u5143\u8001\u631d\u6c34\u7535\u7ad9\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097050.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097382.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097386.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:51',
 'title': u'\u795e\u601d\u7535\u5b50\u80a1\u4e1c\u51cf\u6301330\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097386.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097049.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:42',
 'title': u'\u5317\u5df4\u4f20\u5a92\u3001\u4f17\u4e1a\u8fbe\u7ec8\u6b62\u53c2\u4e0e\u683c\u529b\u7535\u5668\u5b9a\u589e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097049.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097387.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097060.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:41',
 'title': u'11\u670817\u65e5\u5348\u95f4\u516c\u544a:\u5317\u5df4\u4f20\u5a92\u3001\u4f17\u4e1a\u8fbe\u7ec8\u6b62\u53c2\u4e0e\u683c\u529b\u7535\u5668\u5b9a\u589e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097060.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097059.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 12:45',
 'title': u'\u6b65\u68ee\u80a1\u4efd\u7ec8\u6b62\u670d\u88c5\u52df\u6295\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097059.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097397.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097376.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:43',
 'title': u'\u6d77\u8fbe\u80a1\u4efd\u80a1\u4e1c\u51cf\u6301390\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097376.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097381.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:48',
 'title': u'\u534e\u8679\u8ba1\u901a\u80a1\u4e1c\u8ba1\u5212\u51cf\u6301\u4e0d\u8d85\u8fc7168\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097381.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097390.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097389.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097395.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097392.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097388.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097394.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097403.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097382.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:48',
 'title': u'\u534e\u529b\u521b\u901a\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301590\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097382.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097406.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097387.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:54',
 'title': u'\u529b\u6e90\u4fe1\u606f\u83b7\u5f97\u653f\u5e9c\u8865\u52a9900\u4e07\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097387.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097397.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:01',
 'title': u'\u7279\u9510\u5fb7\u5168\u8d44\u5b50\u516c\u53f8\u7b7e\u8ba23.52\u4ebf\u5143EPC\u603b\u627f\u5305\u5408\u540c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097397.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097390.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:56',
 'title': u'\u6052\u6cf0\u827e\u666e\u62df\u6295\u8d448000\u4e07\u5143\u8bbe\u7acb\u5317\u4eac\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097390.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097413.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097389.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:55',
 'title': u'\u96f7\u66fc\u80a1\u4efd\u5b9e\u9645\u63a7\u5236\u4eba\u51cf\u6301600\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097389.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097407.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097395.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:00',
 'title': u'\u56db\u65b9\u7cbe\u521b\u6301\u80a15%\u4ee5\u4e0a\u80a1\u4e1c\u51cf\u6301150\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097395.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097392.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:56',
 'title': u'\u6d77\u8054\u8baf\u7b2c\u4e8c\u5927\u80a1\u4e1c\u51cf\u6301500\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097392.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097388.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:54',
 'title': u'\u56fd\u796f\u73af\u4fdd\u4e2d\u68072.6\u4ebf\u5143\u8499\u57ce\u6c61\u6c34\u5382\u7f51\u4e00\u4f53\u5316PPP\u9879\u76ee',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097388.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097394.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 18:39',
 'title': u'\u4e1c\u963f\u963f\u80f6\u4e09\u5927\u4e3b\u5bfc\u4ea7\u54c1\u5168\u7ebf\u63d0\u4ef7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097394.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097403.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:04',
 'title': u'11\u670818\u65e5\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1\uff1a\u6c49\u9f0e\u5b87\u4f51\u62df13\u4ebf\u5143\u5e76\u8d2d\u6e38\u620f\u516c\u53f8 \u5e03\u5c40\u5a31\u4e50\u4ea7\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097403.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097452.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097406.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:10',
 'title': u'\u6a2a\u6cb3\u6a21\u5177\u6536\u5230796\u4e07\u5143\u653f\u5e9c\u8865\u8d34',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097406.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097457.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097412.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097411.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097454.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097413.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:15',
 'title': u'11\u670818\u65e5\u91cd\u8981\u589e\u51cf\u6301',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097413.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097459.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097461.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097407.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:10',
 'title': u'\u5bcc\u745e\u7279\u88c5\u7b7e\u7f72\u5408\u4f5c\u5f00\u53d1\u6846\u67b6\u534f\u8bae',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097407.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097455.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097446.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097452.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:05',
 'title': u'\u4e09\u529b\u58eb\u667a\u80fd\u88c5\u5907\u5c55\u4f1a\u60ca\u8273\u4eae\u76f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097452.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097473.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097457.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:03',
 'title': u'\u65b0\u6e56\u4e2d\u5b9d\uff1a\u62df7.1\u4ebf\u5143\u8f6c\u8ba9\u5b50\u516c\u53f8\u65b0\u6e56\u5b9d\u534e65%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097457.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097412.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:13',
 'title': u'11\u670818\u65e5\u9ad8\u9001\u8f6c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097412.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097411.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:13',
 'title': u'11\u670818\u65e5\u91cd\u5927\u505c\u590d\u724c\uff1a\u534e\u5cf0\u8d85\u7ea4\u5468\u4e94\u590d\u724c \u62df18\u4ebf\u5143\u6536\u8d2d\u79fb\u52a8\u652f\u4ed8\u670d\u52a1\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097411.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097454.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:00',
 'title': u'\u5168\u7b51\u80a1\u4efd\uff1a\u7b7e\u8ba2\u5408\u4f5c\u6846\u67b6\u534f\u8bae \u6709\u671b\u83b7\u5f97\u5927\u91cf\u8ba2\u5355',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097454.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097459.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:09',
 'title': u'\u4e2d\u79d1\u66d9\u5149\u80a1\u4e1c\u5929\u5bcc\u521b\u6295\u51cf\u63013.11%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097459.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097461.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:09',
 'title': u'\u6885\u6cf0\u8bfa\u62df3000\u4e07\u5143\u6536\u8d2d\u9f0e\u5143\u4fe1\u5e7f49%\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097461.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097455.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:51',
 'title': u'\u6b65\u68ee\u80a1\u4efd\uff1a\u8fdb\u519b\u91d1\u878d\u79d1\u6280  \u6398\u91d1\u4e07\u4ebf\u5e02\u573a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097455.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097446.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 19:45',
 'title': u'\u4e2d\u56fd\u8fdc\u6d0b\uff1a\u62df7234\u4e07\u5143\u6536\u8d2d\u4e2d\u8fdc\u5e0c\u814a\u7b49\u5883\u5916\u516c\u53f8\u90e8\u5206\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097446.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097464.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097471.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097473.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u7ef4\u5c14\u522918\u65e5\u590d\u724c \u62df\u6536\u8d2d\u4e24\u5bb6\u73af\u4fdd\u4f01\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097473.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097474.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097470.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097463.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097943.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097472.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_5.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097937.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097948.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097464.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:10',
 'title': u'\u5927\u5bcc\u79d1\u62802016\u5e74\u5ea6\u4e1a\u7ee9\u9884\u589e108%-137%',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097464.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097471.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u7528\u53cb\u7f51\u7edc\u62df\u53d1\u8d77\u8bbe\u7acb\u5317\u4eac\u4e2d\u5173\u6751\u94f6\u884c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097471.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097474.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u4e07\u79d1A\uff1a\u6536\u8d2d\u524d\u6d77\u56fd\u9645\u65b9\u6848\u5c1a\u672a\u8fbe\u6210\u5171\u8bc6',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097474.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097988.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097470.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u6613\u6210\u65b0\u80fd\u62df\u903e28\u4ebf\u5143\u6536\u8d2d\u6c5f\u897f\u8d5b\u7ef4\u53ca\u65b0\u4f59\u8d5b\u7ef4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097470.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098023.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097947.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097463.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:10',
 'title': u'\u65b0\u6e56\u4e2d\u5b9d\u5168\u8d44\u5b50\u516c\u53f8\u65a5\u903e14.69\u4ebf\u5143\u62ff\u5730',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097463.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097943.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5b87\u901a\u5ba2\u8f66\u56de\u5e94\u4e0b\u8dcc\u539f\u56e0\uff1a\u6216\u56e0\u65b0\u80fd\u6e90\u6c7d\u8f66\u8865\u8d34\u53d6\u6d88\u4f20\u95fb',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097943.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097472.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-17 20:14',
 'title': u'\u70bc\u77f3\u6709\u8272\u505c\u724c\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161117_5097472.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097937.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:26',
 'title': u'\u4e0a\u6d77\u94f6\u884c\u4e0a\u5e02\u7b2c\u4e09\u5929\u5373\u6253\u5f00\u6da8\u505c\u677f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097937.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097948.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5eb7\u5f97\u65b0\uff1a\u4e0e\u534e\u4e3a\u7ec8\u6b62\u88f8\u773c3D\u4e1a\u52a1\u5408\u4f5c\u4f20\u95fb\u4e0d\u5b9e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097948.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098066.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098067.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097964.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098025.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097988.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:57',
 'title': u'\u4e0d\u6b62\u5357\u73bbA \u8fd9\u4e9b\u516c\u53f8\u540c\u6837\u7206\u53d1\u4eba\u4e8b\u5730\u9707\uff01(\u9644\u540d\u5355)',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097988.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098023.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:05',
 'title': u'\u6c49\u738b\u79d1\u6280\u62df\u63a8\u80a1\u6743\u6fc0\u52b1\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098023.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097947.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u4e07\u79d1A\u5927\u6da86% \u518d\u521b\u5386\u53f2\u65b0\u9ad8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097947.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098024.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097966.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098022.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098101.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098211.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098342.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097968.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098066.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:23',
 'title': u'\u817e\u90a6\u65c5\u6e38\u96c6\u56e2\u4e1a\u52a1\u5c06\u5411\u76ee\u7684\u5730\u5ef6\u4f38',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098066.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098346.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098067.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:22',
 'title': u'\u6842\u53d1\u7965\u4eca\u65e5\u4e0a\u5e02',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098067.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097964.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5fb7\u8d5b\u7535\u6c60\u900f\u9732\u516c\u53f8\u4e3a\u534e\u4e3aMate9\u63d0\u4f9b\u7535\u6c60\u4ea7\u54c1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097964.html'}
2016-11-21 14:42:20 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098025.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 09:23',
 'title': u'11\u670818\u65e5\u5348\u95f4\u516c\u544a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098025.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098358.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098348.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098347.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098024.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:05',
 'title': u'\u5409\u827e\u79d1\u6280\u7ec8\u6b62\u6536\u8d2d\u54c8\u8428\u514b\u65af\u5766\u70bc\u5316\u4f01\u4e1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098024.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097966.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u5c71\u4e1c\u534e\u9e4f\u91cd\u5927\u4e8b\u9879\u4e34\u505c \u9ad8\u9001\u8f6c\u662f\u8bef\u4f20',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097966.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098022.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:05',
 'title': u'\u666e\u90a6\u80a1\u4efd\u4e2d\u6807\u90d1\u5ddePPP\u9879\u76ee \u6709\u671b\u63d0\u632f\u5341\u5e74\u4e1a\u7ee9',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098022.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098101.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 14:19',
 'title': u'\u4e09\u5927\u80fd\u6e90\u96c6\u56e2\u5171\u8bbe\u6295\u8d44\u5e73\u53f0 \u52a9\u63a8\u80fd\u6e90\u8f6c\u578b\u5347\u7ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098101.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098211.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 16:16',
 'title': u'\u4e0b\u5468\u53ef\u80fd\u5f71\u54cd\u80a1\u4ef7\u91cd\u8981\u516c\u544a\uff1a\u5339\u51f8\u5339\u8463\u4e8b\u957f\u56e0\u5de5\u4f5c\u539f\u56e0\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098211.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098068.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098365.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098342.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 17:50',
 'title': u'\u51af\u5c0f\u521a\u624b\u6495\u738b\u5065\u6797\u80cc\u540e\uff1a\u5929\u4ef7\u7968\u8865\u4e0e\u4e07\u8fbe\u5784\u65ad',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098342.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098345.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097968.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 10:27',
 'title': u'\u8fce\u5b89\u90a6\u4e3e\u724c \u4e2d\u56fd\u5efa\u7b51\u4eca\u65e5\u9ad8\u5f00\u4f4e\u8d70',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5097968.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098346.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:00',
 'title': u'\u4e1c\u963f\u963f\u80f6\u9a74\u813e\u6c14\u96be\u6539 \u65d7\u4e0b\u4ea7\u54c16\u5e74\u6da8\u4ef712\u6b21',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098346.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098367.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098358.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 17:59',
 'title': u'\u4e0b\u5468\u5229\u597d\u516c\u544a\u8fce\u7206\u53d1\uff1a\u4e1c\u65b9\u7f51\u7edc\u62df35\u4ebf\u6536\u8d2d\u4e09\u5f71\u89c6\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098358.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098349.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098348.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:14',
 'title': u'\u4e0b\u5468\u91cd\u5927\u505c\u590d\u724c\uff1a\u8363\u4e4b\u8054\u7ec8\u6b62\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4 \u80a1\u7968\u590d\u724c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098348.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098347.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:00',
 'title': u'\u9664\u683c\u529b\u5916132\u5bb6\u4e0a\u5e02\u516c\u53f8\u91cd\u7ec4\u5931\u8d25\uff1a\u9ad8\u6ea2\u4ef7\u548c\u9ad8\u4e1a\u7ee9\u627f\u8bfa\u662f\u96f7\u533a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098347.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098368.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098369.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098068.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 13:37',
 'title': u'\u56db\u7ef4\u56fe\u65b0:\u4e0e\u5b9d\u9a6c\u5728\u5bfc\u822a\u9886\u57df\u5408\u4f5c\u5bc6\u5207',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098068.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098364.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098365.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:04',
 'title': u'\u4e2d\u822a\u5149\u7535\u80a1\u4e1c\u4e2d\u56fd\u7a7a\u7a7a\u5bfc\u5f39\u7814\u7a76\u9662\u62df\u51cf\u6301\u4e0d\u903e300\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098365.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098345.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 17:59',
 'title': u'\u6052\u5927\u501f\u58f3\u6df1\u6df1\u623f\u8fdb\u5165\u5b9e\u65bd\u9636\u6bb5 \u91cd\u7ec4\u4e2d\u4ecb\u673a\u6784\u5df2\u9009\u5b9a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098345.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098367.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:53',
 'title': u'\u4e2d\u5929\u79d1\u6280\u201c\u6c34\u4e0b\u4e92\u8054\u7f51\u201d\u4eae\u76f8\u4e16\u754c\u4e92\u8054\u7f51\u5927\u4f1a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098367.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098349.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:14',
 'title': u'11\u670818\u65e5\u665a\u95f4\u91cd\u8981\u589e\u51cf\u6301',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098349.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098368.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:47',
 'title': u'\u5e7f\u6c7d\u96c6\u56e2\u4eae\u76f82016\u7b2c14\u5c4a\u4e2d\u56fd\uff08\u5e7f\u5dde\uff09\u56fd\u9645\u6c7d\u8f66\u5c55',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098368.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098371.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098369.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:06',
 'title': u'\u5411\u65e5\u84755.2\u4ebf\u5143\u6536\u8d2d\u5965\u80fd\u7535\u6e90',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098369.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098373.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098364.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:00',
 'title': u'\u4eca\u4e16\u7f18\u526f\u603b\u7ecf\u7406\u8fdd\u89c4\u51cf\u6301\u906d\u5904\u7f5a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098364.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098375.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098372.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098374.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098376.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098371.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u5929\u76ee\u836f\u4e1a\u906d\u80a1\u4e1c\u51cf\u6301348\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098371.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098373.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u542f\u8fea\u53e4\u6c49\u5b9a\u589e\u7533\u8bf7\u83b7\u8bc1\u76d1\u4f1a\u5ba1\u6838\u901a\u8fc7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098373.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098420.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098366.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098377.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098375.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u5b9d\u94a2\u80a1\u4efd\u63a7\u80a1\u80a1\u4e1c\u66f4\u540d\u201c\u5b9d\u6b66\u94a2\u94c1\u96c6\u56e2\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098375.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098372.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u4e1c\u65b9\u7f51\u7edc\u62df35\u4ebf\u5143\u6536\u8d2d\u5f71\u89c6\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098372.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098374.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u4e1c\u5317\u5236\u836f\u906d\u80a1\u4e1c\u7d2f\u8ba1\u51cf\u6301470\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098374.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098376.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u4e00\u6c7d\u8f7f\u8f66\u62df4.28\u4ebf\u5143\u8f6c\u8ba9\u7ea2\u65d7\u54c1\u724c\u8d44\u4ea7',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098376.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098378.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098426.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098420.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:50',
 'title': u'\u5feb\u4e50\u8d2d\u4e24\u80a1\u4e1c\u8ba1\u5212\u51cf\u6301\u4e0d\u8d85\u8fc74530\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098420.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098366.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:05',
 'title': u'\u83ab\u9ad8\u80a1\u4efd\uff1a\u5b81\u6ce2\u5b8f\u521b\u53ca\u6c38\u65b0\u534e\u97f5\u6d89\u5acc\u8d85\u6bd4\u4f8b\u6301\u6709\u516c\u53f8\u80a1\u4efd\u672a\u516c\u544a\u906d\u7acb\u6848\u8c03\u67e5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098366.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098377.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u9e3f\u8def\u94a2\u6784\u9ad8\u7ba1\u51cf\u6301\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098377.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098419.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098504.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098423.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098378.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u8363\u4e4b\u8054\u7ec8\u6b62\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098378.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098425.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098379.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098426.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u5b9d\u5149\u80a1\u4efd\u80a1\u4e1c\u589e\u6301223.9\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098426.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098424.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098427.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098419.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:49',
 'title': u'\u5929\u76ee\u836f\u4e1a\u80a1\u4e1c\u5e73\u5b89\u5927\u534e\u6c47\u901a\u4ee3\u8868\u521b\u76c8 4 \u53f7\u51cf\u6301347.91\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098419.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098504.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 21:28',
 'title': u'\u6881\u5149\u4f1f\u5bf9\u6df1\u5733\u534e\u5f3a\u53d1\u8d77\u8981\u7ea6\u6536\u8d2d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098504.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098423.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u96f7\u67cf\u79d1\u6280\u63a7\u80a1\u80a1\u4e1c\u51cf\u63012.6%\u516c\u53f8\u80a1\u4efd',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098423.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098425.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u5929\u539f\u96c6\u56e2\u505c\u724c\u7b79\u5212\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u4e8b\u9879',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098425.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098379.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:09',
 'title': u'\u660e\u6cf0\u94dd\u4e1a\u906d\u80a1\u4e1c\u7d2f\u8ba1\u51cf\u6301200\u4e07\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098379.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098514.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098424.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u5339\u51f8\u5339\u8463\u4e8b\u957f\u56e0\u5de5\u4f5c\u539f\u56e0\u8f9e\u804c',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098424.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098594.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098595.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098427.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 19:54',
 'title': u'\u534e\u5f55\u767e\u7eb3\u80a1\u4e1c\u62ab\u9732\u51cf\u6301\u8ba1\u5212',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098427.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098644.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098645.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098649.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098514.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 21:31',
 'title': u'\u731b\u72ee\u79d1\u6280\uff1a\u62df1\u4ebf\u5143\u5728\u8944\u9633\u8bbe\u7acb\u65b0\u80fd\u6e90\u516c\u53f8',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098514.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098594.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:26',
 'title': u'\u8bc1\u76d1\u4f1a\u5bf9\u516d\u5b97\u6848\u4ef6\u4f5c\u51fa\u884c\u653f\u5904\u7f5a',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098594.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098647.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098595.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:28',
 'title': u'\u5b89\u90a6\u8d44\u4ea7\u62df\u589e\u6301\u4e2d\u56fd\u5efa\u7b511\u4ebf\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098595.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098644.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:48',
 'title': u'\u662f\u8d2a\u5a6a\u8fd8\u662f\u65e0\u77e5\uff1f\u4eca\u4e16\u7f18\u9ad8\u7ba1\u8fdd\u89c4\u51cf\u6301\u906d\u901a\u62a5',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098644.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098696.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098645.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:49',
 'title': u'\u5bb6\u4e50\u798f\u4e1a\u7ee9\u8fde\u4e8f\u80a1\u6743\u518d\u906d\u629b\u552e \u8fbd\u5b81\u6210\u59274.2\u4ebf\u51fa\u552e\u5176\u5168\u90e8\u80a1\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098645.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098649.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:51',
 'title': u'\u5b89\u90a6\u6301A\u80a1\u5df2\u8d851700\u4ebf\uff01\u4e3e\u724c\u4e2d\u56fd\u5efa\u7b51\u6d6e\u76c814.49\u4ebf \u8fd8\u5c06\u589e\u63011\u4ebf\u80a1',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098649.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098656.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098685.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098657.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098706.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098707.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098647.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:51',
 'title': u'\u91cd\u8981\u4ea4\u6613\u4fe1\u62ab\u4e0d\u5230\u4f4d \u5168\u7b51\u80a1\u4efd\u9686\u946b\u901a\u7528\u906d\u95ee\u8be2',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098647.html'}
2016-11-21 14:42:21 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098696.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:13',
 'title': u'\u5357\u73bb\u4e1a\u7ee9\u5982\u4f55\u4fdd\u969c\uff1f\u804c\u4e1a\u7ecf\u7406\u4eba\u7d20\u8d28\u4f55\u5728\uff1f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098696.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098672.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098656.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 08:59',
 'title': u'\u795e\u5f00\u80a1\u4efd\u80a1\u6743\u4e4b\u4e89\u672a\u6b47 \u80a1\u4e1c\u4f1a\u73b0\u573a\u8463\u4e8b\u201c\u53d1\u96be\u201d\u8d28\u7591\u8bae\u6848\u5408\u89c4\u6027',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098656.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098685.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:08',
 'title': u'\u5357\u73bbA\u9a7b\u4eac\u201c\u5e73\u6c11\u201d\uff1a\u6ce2\u53ca\u4e0e\u5426\u9700\u89c2\u671b\u5929\u6d25\u5de5\u5382',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098685.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098657.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:00',
 'title': u'\u6b65\u68ee\u53eb\u505c\u670d\u88c5\u52df\u6295\u73a9\u91d1\u670d \u4e1a\u7ee9\u4e00\u8def\u4e0b\u6ed1\u4e09\u6b21\u91cd\u7ec4\u5931\u8d25',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098657.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098706.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:16',
 'title': u'\u4e4c\u9547\u996d\u5c40\u201c\u5403\u51fa\u754c\u201d',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098706.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098707.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:17',
 'title': u'\u5ef6\u534e\u667a\u80fd\u5927\u80a1\u4e1c\u62df\u8f6c\u8ba9\u6295\u7968\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098707.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098740.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098741.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098742.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098672.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:03',
 'title': u'\u51af\u5c0f\u521a\u53eb\u677f\u4e07\u8fbe\uff1a\u738b\u601d\u806a\u9694\u7a7a\u5e94\u6218 \u534e\u8c0a\u8eba\u67aa\u7684\u80cc\u540e',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098672.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098686.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_1.html)
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098740.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:41',
 'title': u'\u963f\u91cc\u5df4\u5df4\u7a7a\u964d\u4e09\u6c5f\u8d2d\u7269 \u4e0a\u4ea4\u6240\u95ee\u5176\u662f\u5426\u610f\u5728\u63a7\u5236\u6743',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098740.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Crawled (200) <GET http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098363.html> (referer: http://www.cs.com.cn/ssgs/gsxw/index_2.html)
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098741.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:41',
 'title': u'\u946b\u79d1\u6750\u659923\u4ebf\u542f\u52a8\u53cc\u8de8\u5e76\u8d2d \u8de8\u56fd\u8de8\u754c\u201c\u8c6a\u8d4c\u201d\u8f6c\u578b\u9762\u4e34\u6311\u6218',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098741.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098742.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:41',
 'title': u'A\u80a1118\u5bb6\u516c\u53f8\u624e\u5806\u7535\u52a8\u8f66 \u52a8\u529b\u7535\u6c60\u884c\u4e1a\u5c06\u73b0\u4e95\u55b7\u5f0f\u589e\u957f',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098742.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098686.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-19 09:07',
 'title': u'\u63a2\u8bbf\u5357\u73bbA\u6210\u90fd\u5206\u516c\u53f8\uff1a\u8463\u4e8b\u957f\u6302\u9774\u603b\u7ecf\u7406\u4ecd\u5728\u5c97',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161119_5098686.html'}
2016-11-21 14:42:22 [scrapy] DEBUG: Scraped from <200 http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098363.html>
{'content': u'<div class="Dte',
 'time': u'2016-11-18 18:59',
 'title': u'\u7231\u5c14\u773c\u79d1\u62df\u5bf9\u5e7f\u5dde\u7231\u5c14\u589e\u8d443800\u4e07\u5143',
 'url': 'http://www.cs.com.cn/ssgs/gsxw/201611/t20161118_5098363.html'}
2016-11-21 14:42:22 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:42:22 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 109133,
 'downloader/request_count': 363,
 'downloader/request_method_count/GET': 363,
 'downloader/response_bytes': 3282849,
 'downloader/response_count': 363,
 'downloader/response_status_count/200': 363,
 'dupefilter/filtered': 37,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 42, 22, 324490),
 'item_scraped_count': 352,
 'log_count/DEBUG': 717,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 363,
 'scheduler/dequeued': 363,
 'scheduler/dequeued/memory': 363,
 'scheduler/enqueued': 363,
 'scheduler/enqueued/memory': 363,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2016, 11, 21, 6, 42, 14, 264851)}
2016-11-21 14:42:22 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:50:01 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:50:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:50:01 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:50:01 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:50:01 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:50:01 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:50:01 [scrapy] INFO: Spider opened
2016-11-21 14:50:01 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:50:10 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61642/> (referer: http://www.cs.com.cn/ssgs/hyzx/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 46, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:50:11 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:50:11 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 117982,
 'downloader/request_count': 392,
 'downloader/request_method_count/GET': 392,
 'downloader/response_bytes': 3689843,
 'downloader/response_count': 392,
 'downloader/response_status_count/200': 392,
 'dupefilter/filtered': 8,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 50, 11, 470547),
 'item_scraped_count': 381,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 392,
 'scheduler/dequeued': 392,
 'scheduler/dequeued/memory': 392,
 'scheduler/enqueued': 392,
 'scheduler/enqueued/memory': 392,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2016, 11, 21, 6, 50, 1, 375334)}
2016-11-21 14:50:11 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:54:48 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:54:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:54:48 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:54:48 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:54:48 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:54:48 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:54:48 [scrapy] INFO: Spider opened
2016-11-21 14:54:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:54:57 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:54:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 99134,
 'downloader/request_count': 330,
 'downloader/request_method_count/GET': 330,
 'downloader/response_bytes': 2969745,
 'downloader/response_count': 330,
 'downloader/response_status_count/200': 330,
 'dupefilter/filtered': 70,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 54, 57, 93600),
 'item_scraped_count': 320,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 330,
 'scheduler/dequeued': 330,
 'scheduler/dequeued/memory': 330,
 'scheduler/enqueued': 330,
 'scheduler/enqueued/memory': 330,
 'start_time': datetime.datetime(2016, 11, 21, 6, 54, 48, 877041)}
2016-11-21 14:54:57 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:56:48 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:56:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:56:48 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:56:48 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:56:48 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:56:48 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:56:48 [scrapy] INFO: Spider opened
2016-11-21 14:56:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098844.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098845.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098846.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099007.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098847.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099013.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099006.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099093.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099098.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099095.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099099.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099133.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099137.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099200.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099130.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:48 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099132.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090734.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090602.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090731.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090686.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090663.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090618.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090779.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090730.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090406.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090503.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090516.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090515.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090577.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090526.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090510.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090584.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090504.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090519.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091008.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090553.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090927.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091009.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090912.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091012.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5090833.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091007.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091015.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091064.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091264.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091023.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091078.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091187.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091355.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091360.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091283.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091583.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091426.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091642.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091363.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091705.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091431.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091579.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091609.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091704.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091710.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091890.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091707.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091904.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091708.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091747.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091757.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:49 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091907.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092043.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091908.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091981.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092034.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091914.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092050.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091968.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091365.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092285.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092046.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092336.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092457.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092060.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092220.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092325.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092070.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092080.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092396.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092310.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092531.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092401.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092522.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092405.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092570.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092518.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092574.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092512.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092513.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5096981.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092532.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092534.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097008.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092536.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097010.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092547.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5096980.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097011.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097089.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097009.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097007.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097180.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097186.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097185.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097189.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097194.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097193.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097207.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094273.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097192.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097181.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097188.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094340.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094293.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094378.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097210.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094296.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094391.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094402.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094393.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094299.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094434.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094342.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094351.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094392.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094555.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094554.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094394.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:50 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094608.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094430.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094644.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094741.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094911.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094472.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094615.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094736.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094616.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095148.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094905.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094908.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095135.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095136.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094982.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095152.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095124.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095013.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095183.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095134.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095012.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095147.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094975.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092937.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092939.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092995.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092960.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092941.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092963.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092996.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093108.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093111.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093159.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093105.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093155.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093101.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5093022.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093339.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5093032.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093154.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092961.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093453.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093309.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093352.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093278.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093427.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093451.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093509.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093510.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093507.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093454.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093457.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093512.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093511.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093517.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093508.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093518.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093520.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093514.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093513.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:51 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093516.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093515.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095347.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095330.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095244.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095389.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095352.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095195.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095294.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095316.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095374.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095354.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095356.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095455.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095431.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095355.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095357.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095621.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095363.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095436.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095605.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095862.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095622.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095625.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096039.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095929.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095856.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095863.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095613.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095936.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095958.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096233.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096280.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096192.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096092.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093521.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092575.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096286.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092609.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096142.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096287.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093519.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092576.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092631.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092524.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092615.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092530.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092537.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092684.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092249.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092533.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092670.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092535.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092568.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092786.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092726.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092915.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092727.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092728.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092801.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092914.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:52 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092908.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092917.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092926.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092741.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092930.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097639.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098836.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098835.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098838.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098837.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092925.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098839.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092931.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092935.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098840.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098841.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098843.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098842.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093522.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093525.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093523.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093524.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093580.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093569.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093649.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092916.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093526.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093527.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093728.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093867.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093598.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093650.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093615.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093869.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093870.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093623.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093871.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093872.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093616.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093873.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093885.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093733.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093986.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093874.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093987.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094073.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093921.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094121.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093939.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094114.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094188.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094141.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097337.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097320.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094116.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097409.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099202.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094139.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099195.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097352.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099248.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099289.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094184.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099290.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097401.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/cj/201611/t20161117_5097400.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099307.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099308.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099351.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099370.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099382.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099387.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099440.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099413.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099075.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097425.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097424.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097561.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097635.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097638.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097722.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097815.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097885.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097559.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097987.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097456.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097582.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097627.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097994.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098000.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097996.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098085.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:53 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098108.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097729.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097991.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098111.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098139.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098112.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098115.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097997.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098110.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098114.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098169.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098212.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098117.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098159.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:54 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098152.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:55 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093868.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:56:55 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:56:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 111348,
 'downloader/request_count': 375,
 'downloader/request_method_count/GET': 375,
 'downloader/response_bytes': 3357685,
 'downloader/response_count': 375,
 'downloader/response_status_count/200': 375,
 'dupefilter/filtered': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 56, 55, 461563),
 'item_scraped_count': 1,
 'log_count/ERROR': 364,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 375,
 'scheduler/dequeued': 375,
 'scheduler/dequeued/memory': 375,
 'scheduler/enqueued': 375,
 'scheduler/enqueued/memory': 375,
 'spider_exceptions/TypeError': 364,
 'start_time': datetime.datetime(2016, 11, 21, 6, 56, 48, 445407)}
2016-11-21 14:56:55 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:57:38 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:57:38 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:57:38 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:57:38 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:57:38 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:57:38 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:57:38 [scrapy] INFO: Spider opened
2016-11-21 14:57:38 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095352.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095347.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095294.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095389.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095316.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095354.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095330.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095356.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:38 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095363.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095436.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095455.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095355.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095357.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095374.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095431.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098845.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093526.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098846.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097185.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092728.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092727.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092741.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097089.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097181.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097189.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097425.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097011.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097180.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097188.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092786.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097193.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097192.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097210.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097186.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097194.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097207.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097320.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097337.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097352.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098837.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098835.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098838.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098836.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/cj/201611/t20161117_5097400.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097401.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098839.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098840.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097409.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097639.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098841.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097424.html> (referer: http://www.cs.com.cn/xwzx/hg/index_2.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098842.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098843.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091008.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098844.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091023.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091187.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091015.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091012.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091078.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091009.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161109_5091064.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091264.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091355.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091283.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091360.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098847.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092070.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091426.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091431.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091365.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099007.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099006.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091363.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099013.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099093.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099095.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099098.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099130.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099099.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099132.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:39 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099133.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092080.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099137.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099200.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099195.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099307.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099248.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099289.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099290.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099202.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099308.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099351.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099075.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099413.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099382.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099387.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099440.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099370.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091609.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091704.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091642.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091579.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091708.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091583.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091747.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091705.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091707.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091710.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091757.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091908.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091890.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091907.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091904.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091968.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091914.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092060.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5091981.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092043.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092046.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092034.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092285.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161110_5092050.html> (referer: http://www.cs.com.cn/xwzx/hg/index_9.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092457.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092220.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092310.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092531.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092512.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092325.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092401.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092336.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092396.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092405.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092513.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092518.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092574.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092522.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092532.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092534.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092575.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092570.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092536.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092547.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092576.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092530.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092609.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092631.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:40 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092615.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092684.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092524.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092537.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092670.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092535.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092726.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097559.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097561.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092249.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097456.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097627.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161117_5097582.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097635.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092908.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092801.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097638.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097722.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092914.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092916.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092917.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092915.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092925.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092926.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092931.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092930.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092937.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092935.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092939.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092941.html> (referer: http://www.cs.com.cn/xwzx/hg/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093525.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093519.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093523.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093521.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093522.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093524.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092961.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092960.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092963.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093105.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093108.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092995.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093159.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5093032.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092996.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5093022.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093155.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093339.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093154.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093111.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093101.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093352.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093309.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161112_5093278.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093454.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093427.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093453.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093451.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093457.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093508.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093507.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093510.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093509.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093513.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093514.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093515.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093511.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093517.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093512.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097729.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093516.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097885.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093520.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092533.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093518.html> (referer: http://www.cs.com.cn/xwzx/hg/index_6.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094608.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098000.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097815.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097987.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098085.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098108.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097994.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097991.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097997.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5097996.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161111_5092568.html> (referer: http://www.cs.com.cn/xwzx/hg/index_8.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098114.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098159.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098139.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098152.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098354.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098110.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098111.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098397.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098112.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/sylm/jsbd/201611/t20161118_5098393.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098115.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098400.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098402.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098169.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098404.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098117.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161119_5098667.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161119_5098653.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093580.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093569.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161118_5098212.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161113_5093527.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093615.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093598.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093650.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093616.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093869.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093871.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093728.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093623.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093872.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093733.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093885.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093867.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093870.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:42 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093649.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093874.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093921.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093873.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094073.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093939.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094114.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093868.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093986.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5093987.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094121.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094139.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094184.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094116.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094141.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094741.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094736.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094644.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094616.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094615.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161114_5094188.html> (referer: http://www.cs.com.cn/xwzx/hg/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094908.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095013.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095124.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094905.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095135.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095148.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094911.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095136.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094975.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5094982.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095012.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095183.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095244.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095134.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095147.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095152.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095621.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095613.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095862.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095605.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161115_5095195.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095929.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095856.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095622.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095625.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096039.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095863.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096286.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096192.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096092.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095936.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096280.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096142.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096233.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5095958.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161116_5096287.html> (referer: http://www.cs.com.cn/xwzx/hg/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 65, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:57:43 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:57:43 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 99650,
 'downloader/request_count': 336,
 'downloader/request_method_count/GET': 336,
 'downloader/response_bytes': 3053676,
 'downloader/response_count': 336,
 'downloader/response_status_count/200': 336,
 'dupefilter/filtered': 64,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 57, 43, 849075),
 'item_scraped_count': 1,
 'log_count/ERROR': 325,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 336,
 'scheduler/dequeued': 336,
 'scheduler/dequeued/memory': 336,
 'scheduler/enqueued': 336,
 'scheduler/enqueued/memory': 336,
 'spider_exceptions/TypeError': 325,
 'start_time': datetime.datetime(2016, 11, 21, 6, 57, 38, 537626)}
2016-11-21 14:57:43 [scrapy] INFO: Spider closed (finished)
2016-11-21 14:59:29 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 14:59:29 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 14:59:29 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 14:59:29 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 14:59:29 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 14:59:29 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 14:59:29 [scrapy] INFO: Spider opened
2016-11-21 14:59:29 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099007.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098842.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098847.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099006.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098844.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098846.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098845.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098843.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099013.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099093.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098835.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099099.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099130.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099132.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099133.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099098.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099095.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098836.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098837.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099137.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098839.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098841.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099200.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098838.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161120_5098840.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099202.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099195.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099248.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099289.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099290.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099307.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099308.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099351.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099370.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099382.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099387.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099413.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099440.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/hg/201611/t20161121_5099075.html> (referer: http://www.cs.com.cn/xwzx/hg/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 66, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 14:59:33 [scrapy] INFO: Closing spider (finished)
2016-11-21 14:59:33 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11451,
 'downloader/request_count': 40,
 'downloader/request_method_count/GET': 40,
 'downloader/response_bytes': 397265,
 'downloader/response_count': 40,
 'downloader/response_status_count/200': 40,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 6, 59, 33, 135931),
 'log_count/ERROR': 39,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 40,
 'scheduler/dequeued': 40,
 'scheduler/dequeued/memory': 40,
 'scheduler/enqueued': 40,
 'scheduler/enqueued/memory': 40,
 'spider_exceptions/TypeError': 39,
 'start_time': datetime.datetime(2016, 11, 21, 6, 59, 29, 410827)}
2016-11-21 14:59:33 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:07:40 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:07:40 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:07:40 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:07:41 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:07:41 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:07:41 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:07:41 [scrapy] INFO: Spider opened
2016-11-21 15:07:41 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:07:49 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:07:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 111348,
 'downloader/request_count': 375,
 'downloader/request_method_count/GET': 375,
 'downloader/response_bytes': 3278690,
 'downloader/response_count': 375,
 'downloader/response_status_count/200': 375,
 'dupefilter/filtered': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 7, 49, 692374),
 'item_scraped_count': 365,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 375,
 'scheduler/dequeued': 375,
 'scheduler/dequeued/memory': 375,
 'scheduler/enqueued': 375,
 'scheduler/enqueued/memory': 375,
 'start_time': datetime.datetime(2016, 11, 21, 7, 7, 41, 32587)}
2016-11-21 15:07:49 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:10:12 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:10:12 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:10:12 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:10:12 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:10:12 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:10:12 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:10:12 [scrapy] INFO: Spider opened
2016-11-21 15:10:12 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:10:29 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:10:29 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 119450,
 'downloader/request_count': 397,
 'downloader/request_method_count/GET': 397,
 'downloader/response_bytes': 3230831,
 'downloader/response_count': 397,
 'downloader/response_status_count/200': 397,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 10, 29, 874537),
 'item_scraped_count': 387,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 397,
 'scheduler/dequeued': 397,
 'scheduler/dequeued/memory': 397,
 'scheduler/enqueued': 397,
 'scheduler/enqueued/memory': 397,
 'start_time': datetime.datetime(2016, 11, 21, 7, 10, 12, 962586)}
2016-11-21 15:10:29 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:15:03 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:15:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:15:03 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:15:03 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:15:03 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:15:03 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:15:03 [scrapy] INFO: Spider opened
2016-11-21 15:15:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:15:13 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61642/> (referer: http://www.cs.com.cn/ssgs/hyzx/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 60, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:15:20 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 60, in parse_item
    item['content'] = response.xpath('//div[@class="Dtext z_content"]').extract_first()[:15]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:15:22 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:15:22 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 322297,
 'downloader/request_count': 1072,
 'downloader/request_method_count/GET': 1072,
 'downloader/response_bytes': 9704106,
 'downloader/response_count': 1072,
 'downloader/response_status_count/200': 1072,
 'dupefilter/filtered': 128,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 15, 22, 445991),
 'item_scraped_count': 1040,
 'log_count/ERROR': 2,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1072,
 'scheduler/dequeued': 1072,
 'scheduler/dequeued/memory': 1072,
 'scheduler/enqueued': 1072,
 'scheduler/enqueued/memory': 1072,
 'spider_exceptions/TypeError': 2,
 'start_time': datetime.datetime(2016, 11, 21, 7, 15, 3, 590950)}
2016-11-21 15:15:22 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:15:23 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:15:23 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:15:23 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:15:23 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:15:23 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:15:23 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:15:23 [scrapy] INFO: Spider opened
2016-11-21 15:15:23 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:15:35 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:15:35 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 210316,
 'downloader/request_count': 704,
 'downloader/request_method_count/GET': 704,
 'downloader/response_bytes': 5945417,
 'downloader/response_count': 704,
 'downloader/response_status_count/200': 704,
 'dupefilter/filtered': 96,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 15, 35, 194409),
 'item_scraped_count': 684,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 704,
 'scheduler/dequeued': 704,
 'scheduler/dequeued/memory': 704,
 'scheduler/enqueued': 704,
 'scheduler/enqueued/memory': 704,
 'start_time': datetime.datetime(2016, 11, 21, 7, 15, 23, 577881)}
2016-11-21 15:15:35 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:19:35 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:19:35 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:19:35 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:19:35 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:19:35 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:19:35 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:19:35 [scrapy] INFO: Spider opened
2016-11-21 15:19:35 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:20:35 [scrapy] INFO: Crawled 2564 pages (at 2564 pages/min), scraped 2430 items (at 2430 items/min)
2016-11-21 15:21:35 [scrapy] INFO: Crawled 5143 pages (at 2579 pages/min), scraped 4899 items (at 2469 items/min)
2016-11-21 15:22:35 [scrapy] INFO: Crawled 7912 pages (at 2769 pages/min), scraped 7602 items (at 2703 items/min)
2016-11-21 15:23:35 [scrapy] INFO: Crawled 10194 pages (at 2282 pages/min), scraped 9786 items (at 2184 items/min)
2016-11-21 15:24:02 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:24:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3620421,
 'downloader/request_count': 11402,
 'downloader/request_method_count/GET': 11402,
 'downloader/response_bytes': 103095965,
 'downloader/response_count': 11402,
 'downloader/response_status_count/200': 11388,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/404': 13,
 'dupefilter/filtered': 911,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 24, 2, 565757),
 'item_scraped_count': 10990,
 'log_count/INFO': 11,
 'request_depth_max': 203,
 'response_received_count': 11399,
 'scheduler/dequeued': 11402,
 'scheduler/dequeued/memory': 11402,
 'scheduler/enqueued': 11402,
 'scheduler/enqueued/memory': 11402,
 'start_time': datetime.datetime(2016, 11, 21, 7, 19, 35, 494930)}
2016-11-21 15:24:02 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:48:51 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:48:51 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:48:51 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:48:51 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:48:51 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:48:51 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:48:51 [scrapy] INFO: Spider opened
2016-11-21 15:48:51 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:49:22 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:49:22 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 233874,
 'downloader/request_count': 820,
 'downloader/request_method_count/GET': 820,
 'downloader/response_bytes': 11835371,
 'downloader/response_count': 820,
 'downloader/response_status_count/200': 820,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 49, 22, 580942),
 'item_scraped_count': 800,
 'log_count/INFO': 7,
 'request_depth_max': 20,
 'response_received_count': 820,
 'scheduler/dequeued': 820,
 'scheduler/dequeued/memory': 820,
 'scheduler/enqueued': 820,
 'scheduler/enqueued/memory': 820,
 'start_time': datetime.datetime(2016, 11, 21, 7, 48, 51, 946011)}
2016-11-21 15:49:22 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:55:07 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:55:07 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:55:07 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:55:07 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:55:07 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:55:07 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:55:07 [scrapy] INFO: Spider opened
2016-11-21 15:55:07 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:55:17 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61642/04/201611/t20161111_5092519.html> (referer: http://www.cs.com.cn/ssgs/hyzx/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 60, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:55:17 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61642/> (referer: http://www.cs.com.cn/ssgs/hyzx/index_3.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 60, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:55:18 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/404error/index.html> (referer: http://www.cs.com.cn/ssgs/hyzx/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 60, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:55:23 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 61, in parse_item
    item['time'] = datetime.datetime.strptime(item['time'], '%Y-%m-%d')
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '(11-21 09:' does not match format '%Y-%m-%d'
2016-11-21 15:55:34 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:55:34 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 326823,
 'downloader/request_count': 1087,
 'downloader/request_method_count/GET': 1087,
 'downloader/response_bytes': 9729499,
 'downloader/response_count': 1087,
 'downloader/response_status_count/200': 1085,
 'downloader/response_status_count/302': 2,
 'dupefilter/filtered': 115,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 55, 34, 523021),
 'item_scraped_count': 1051,
 'log_count/ERROR': 4,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1085,
 'scheduler/dequeued': 1087,
 'scheduler/dequeued/memory': 1087,
 'scheduler/enqueued': 1087,
 'scheduler/enqueued/memory': 1087,
 'spider_exceptions/TypeError': 3,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2016, 11, 21, 7, 55, 7, 153371)}
2016-11-21 15:55:34 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:56:26 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:56:26 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:56:26 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:56:26 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:56:26 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:56:26 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:56:26 [scrapy] INFO: Spider opened
2016-11-21 15:56:26 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:56:32 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/tzjj/00/201611/t20161109_5090199.html> (referer: http://www.cs.com.cn/xwzx/hwxx/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 106, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:56:41 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/xwzt/151215_61693/01/201611/t20161117_5097402.html> (referer: http://www.cs.com.cn/xwzx/hg/index_1.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/news/news/spiders/cs.py", line 106, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:56:47 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:56:47 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 225318,
 'downloader/request_count': 754,
 'downloader/request_method_count/GET': 754,
 'downloader/response_bytes': 6484418,
 'downloader/response_count': 754,
 'downloader/response_status_count/200': 754,
 'dupefilter/filtered': 46,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 56, 47, 333302),
 'item_scraped_count': 732,
 'log_count/ERROR': 2,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 754,
 'scheduler/dequeued': 754,
 'scheduler/dequeued/memory': 754,
 'scheduler/enqueued': 754,
 'scheduler/enqueued/memory': 754,
 'spider_exceptions/TypeError': 2,
 'start_time': datetime.datetime(2016, 11, 21, 7, 56, 26, 725685)}
2016-11-21 15:56:47 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:57:47 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:57:47 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:57:47 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:57:47 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:57:47 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:57:47 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:57:47 [scrapy] INFO: Spider opened
2016-11-21 15:57:47 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:58:22 [scrapy] INFO: Closing spider (finished)
2016-11-21 15:58:22 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 233874,
 'downloader/request_count': 820,
 'downloader/request_method_count/GET': 820,
 'downloader/response_bytes': 11835371,
 'downloader/response_count': 820,
 'downloader/response_status_count/200': 820,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 7, 58, 22, 71747),
 'item_scraped_count': 800,
 'log_count/INFO': 7,
 'request_depth_max': 20,
 'response_received_count': 820,
 'scheduler/dequeued': 820,
 'scheduler/dequeued/memory': 820,
 'scheduler/enqueued': 820,
 'scheduler/enqueued/memory': 820,
 'start_time': datetime.datetime(2016, 11, 21, 7, 57, 47, 579749)}
2016-11-21 15:58:22 [scrapy] INFO: Spider closed (finished)
2016-11-21 15:59:28 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 15:59:28 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 15:59:28 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 15:59:28 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 15:59:28 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 15:59:28 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 15:59:28 [scrapy] INFO: Spider opened
2016-11-21 15:59:28 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 15:59:47 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/company/scp_ggjd/gszhuanti/2015bnb/> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/25)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 15:59:49 [scrapy] ERROR: Spider error processing <GET http://yjbg.cnstock.com/dyjm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/24)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:13 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3283082.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/75)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:13 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278178.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:13 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3280014.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:13 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3280033.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:13 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3281519.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3276450.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3276453.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3273173.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3274832.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:16 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201411/3258128.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/83)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:21 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201411/3246942.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/87)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:22 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3274684.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:22 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278159.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:22 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278232.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:00:28 [scrapy] INFO: Crawled 2187 pages (at 2187 pages/min), scraped 2063 items (at 2063 items/min)
2016-11-21 16:00:28 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3281562.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:01:02 [scrapy] ERROR: Spider error processing <GET http://yjbg.cnstock.com/> (referer: http://company.cnstock.com/company/scp_gsxw/58)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:01:14 [scrapy] ERROR: Spider error processing <GET http://www.cnstock.com> (referer: http://company.cnstock.com/company/scp_gsxw/65)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:01:28 [scrapy] INFO: Crawled 4407 pages (at 2220 pages/min), scraped 4199 items (at 2136 items/min)
2016-11-21 16:02:21 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/topics/xzqmsdwk15> (referer: http://company.cnstock.com/company/scp_gsxw/176)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:02:23 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/topics/xzqmsdwk15/201512/3663412.htm> (referer: http://company.cnstock.com/company/scp_gsxw/179)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:02:28 [scrapy] INFO: Crawled 6828 pages (at 2421 pages/min), scraped 6514 items (at 2315 items/min)
2016-11-21 16:02:37 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/company/scp_ggjd/gszhuanti/20153jb> (referer: http://company.cnstock.com/company/scp_gsxw/192)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:03:28 [scrapy] INFO: Crawled 9512 pages (at 2684 pages/min), scraped 9122 items (at 2608 items/min)
2016-11-21 16:03:42 [scrapy] INFO: Closing spider (finished)
2016-11-21 16:03:42 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3198741,
 'downloader/request_count': 10070,
 'downloader/request_method_count/GET': 10070,
 'downloader/response_bytes': 92432604,
 'downloader/response_count': 10070,
 'downloader/response_status_count/200': 10056,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/404': 13,
 'dupefilter/filtered': 911,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 8, 3, 42, 911948),
 'item_scraped_count': 9678,
 'log_count/ERROR': 23,
 'log_count/INFO': 11,
 'request_depth_max': 203,
 'response_received_count': 10067,
 'scheduler/dequeued': 10070,
 'scheduler/dequeued/memory': 10070,
 'scheduler/enqueued': 10070,
 'scheduler/enqueued/memory': 10070,
 'spider_exceptions/IndexError': 1,
 'spider_exceptions/TypeError': 22,
 'start_time': datetime.datetime(2016, 11, 21, 7, 59, 28, 327326)}
2016-11-21 16:03:42 [scrapy] INFO: Spider closed (finished)
2016-11-21 16:05:42 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 16:05:42 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 16:05:42 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 16:05:42 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 16:05:42 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 16:05:42 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 16:05:42 [scrapy] INFO: Spider opened
2016-11-21 16:05:42 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 16:05:42 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/gglist/search/qmtbbdj/> (referer: None)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 27, in parse
    if words[-2] == u'下一页':
IndexError: list index out of range
2016-11-21 16:05:55 [scrapy] ERROR: Spider error processing <GET http://yjbg.cnstock.com/dyjm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/24)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:05:56 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/company/scp_ggjd/gszhuanti/2015bnb/> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/25)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3283082.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/75)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278178.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3280014.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3281519.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3280033.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3276450.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:25 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3276453.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:25 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3273173.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:25 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3274832.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:28 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201411/3258128.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/83)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:32 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201411/3246942.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/87)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:33 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3274684.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:34 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278159.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:34 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278232.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:34 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3281562.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:42 [scrapy] INFO: Crawled 2695 pages (at 2695 pages/min), scraped 2566 items (at 2566 items/min)
2016-11-21 16:06:46 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000622898> (referer: http://company.cnstock.com/company/scp_gsxw/15)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:06:56 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000604000> (referer: http://company.cnstock.com/company/scp_gsxw/37)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:07:08 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000590883> (referer: http://company.cnstock.com/company/scp_gsxw/57)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:07:08 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000591138> (referer: http://company.cnstock.com/company/scp_gsxw/57)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:07:08 [scrapy] ERROR: Spider error processing <GET http://yjbg.cnstock.com/> (referer: http://company.cnstock.com/company/scp_gsxw/58)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:07:08 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000589597> (referer: http://company.cnstock.com/company/scp_gsxw/59)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:07:11 [scrapy] ERROR: Spider error processing <GET http://www.cnstock.com> (referer: http://company.cnstock.com/company/scp_gsxw/65)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:07:42 [scrapy] INFO: Crawled 5271 pages (at 2576 pages/min), scraped 5037 items (at 2471 items/min)
2016-11-21 16:08:20 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/topics/xzqmsdwk15> (referer: http://company.cnstock.com/company/scp_gsxw/176)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:08:21 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/topics/xzqmsdwk15/201512/3663412.htm> (referer: http://company.cnstock.com/company/scp_gsxw/179)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:08:40 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/company/scp_ggjd/gszhuanti/20153jb> (referer: http://company.cnstock.com/company/scp_gsxw/192)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:08:42 [scrapy] INFO: Crawled 7522 pages (at 2251 pages/min), scraped 7192 items (at 2155 items/min)
2016-11-21 16:08:54 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000625404> (referer: http://company.cnstock.com/company/scp_gsxw/11)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/cnstock.py", line 34, in parse_item
    item = NewsItem()
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:08:56 [scrapy] INFO: Closing spider (finished)
2016-11-21 16:08:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2610660,
 'downloader/request_count': 8210,
 'downloader/request_method_count/GET': 8210,
 'downloader/response_bytes': 77345540,
 'downloader/response_count': 8210,
 'downloader/response_status_count/200': 8196,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/404': 13,
 'dupefilter/filtered': 880,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 8, 8, 56, 583671),
 'item_scraped_count': 7873,
 'log_count/ERROR': 29,
 'log_count/INFO': 10,
 'request_depth_max': 203,
 'response_received_count': 8207,
 'scheduler/dequeued': 8210,
 'scheduler/dequeued/memory': 8210,
 'scheduler/enqueued': 8210,
 'scheduler/enqueued/memory': 8210,
 'spider_exceptions/IndexError': 1,
 'spider_exceptions/TypeError': 28,
 'start_time': datetime.datetime(2016, 11, 21, 8, 5, 42, 606376)}
2016-11-21 16:08:56 [scrapy] INFO: Spider closed (finished)
2016-11-21 16:10:24 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 16:10:24 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 16:10:24 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 16:10:25 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 16:10:25 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 16:10:25 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 16:10:25 [scrapy] INFO: Spider opened
2016-11-21 16:10:25 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 16:11:25 [scrapy] INFO: Crawled 817 pages (at 817 pages/min), scraped 797 items (at 797 items/min)
2016-11-21 16:11:40 [scrapy] INFO: Closing spider (finished)
2016-11-21 16:11:40 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 233121,
 'downloader/request_count': 820,
 'downloader/request_method_count/GET': 820,
 'downloader/response_bytes': 12391561,
 'downloader/response_count': 820,
 'downloader/response_status_count/200': 820,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 8, 11, 40, 612674),
 'item_scraped_count': 800,
 'log_count/INFO': 8,
 'request_depth_max': 20,
 'response_received_count': 820,
 'scheduler/dequeued': 820,
 'scheduler/dequeued/memory': 820,
 'scheduler/enqueued': 820,
 'scheduler/enqueued/memory': 820,
 'start_time': datetime.datetime(2016, 11, 21, 8, 10, 25, 65034)}
2016-11-21 16:11:40 [scrapy] INFO: Spider closed (finished)
2016-11-21 16:12:28 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 16:12:28 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 16:12:28 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 16:12:28 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 16:12:28 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 16:12:28 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 16:12:28 [scrapy] INFO: Spider opened
2016-11-21 16:12:28 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 16:12:40 [scrapy] INFO: Closing spider (finished)
2016-11-21 16:12:40 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 233121,
 'downloader/request_count': 820,
 'downloader/request_method_count/GET': 820,
 'downloader/response_bytes': 12391705,
 'downloader/response_count': 820,
 'downloader/response_status_count/200': 820,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 8, 12, 40, 566836),
 'item_scraped_count': 800,
 'log_count/INFO': 7,
 'request_depth_max': 20,
 'response_received_count': 820,
 'scheduler/dequeued': 820,
 'scheduler/dequeued/memory': 820,
 'scheduler/enqueued': 820,
 'scheduler/enqueued/memory': 820,
 'start_time': datetime.datetime(2016, 11, 21, 8, 12, 28, 393099)}
2016-11-21 16:12:40 [scrapy] INFO: Spider closed (finished)
2016-11-21 16:13:07 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-21 16:13:07 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-21 16:13:07 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-21 16:13:07 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-21 16:13:07 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-21 16:13:07 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-21 16:13:07 [scrapy] INFO: Spider opened
2016-11-21 16:13:07 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-21 16:13:18 [scrapy] ERROR: Spider error processing <GET http://www.stcn.com> (referer: http://company.stcn.com/cjnews/13.shtml)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/news/news/spiders/stcn.py", line 35, in parse_item
    item['time'] = response.xpath('//div[@class="intal_tit"]/div[@class="info"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-21 16:13:55 [scrapy] INFO: Closing spider (finished)
2016-11-21 16:13:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465188,
 'downloader/request_count': 1633,
 'downloader/request_method_count/GET': 1633,
 'downloader/response_bytes': 24054484,
 'downloader/response_count': 1633,
 'downloader/response_status_count/200': 1626,
 'downloader/response_status_count/302': 7,
 'dupefilter/filtered': 14,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 21, 8, 13, 55, 32257),
 'item_scraped_count': 1585,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 20,
 'response_received_count': 1626,
 'scheduler/dequeued': 1633,
 'scheduler/dequeued/memory': 1633,
 'scheduler/enqueued': 1633,
 'scheduler/enqueued/memory': 1633,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2016, 11, 21, 8, 13, 7, 332718)}
2016-11-21 16:13:55 [scrapy] INFO: Spider closed (finished)
2016-11-23 15:04:56 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-23 15:04:56 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-23 15:04:56 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-23 15:04:56 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-23 15:04:56 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-23 15:04:56 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-23 15:04:56 [scrapy] INFO: Spider opened
2016-11-23 15:04:56 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-23 15:05:07 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61642/04/201611/t20161111_5092519.html> (referer: http://www.cs.com.cn/ssgs/hyzx/index_5.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/spiders/cs.py", line 64, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:05:08 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61642/> (referer: http://www.cs.com.cn/ssgs/hyzx/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/spiders/cs.py", line 64, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:05:13 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/wysg/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/spiders/cs.py", line 65, in parse_item
    item['time'] = datetime.datetime.strptime(item['time'], '%Y-%m-%d')
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/_strptime.py", line 325, in _strptime
    (data_string, format))
ValueError: time data '(11-23 09:' does not match format '%Y-%m-%d'
2016-11-23 15:05:13 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/ssgs/gszt/20150325_61782/> (referer: http://www.cs.com.cn/ssgs/gsxw/)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/spiders/cs.py", line 64, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:05:19 [scrapy] INFO: Closing spider (finished)
2016-11-23 15:05:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317127,
 'downloader/request_count': 1055,
 'downloader/request_method_count/GET': 1055,
 'downloader/response_bytes': 9333361,
 'downloader/response_count': 1055,
 'downloader/response_status_count/200': 1055,
 'dupefilter/filtered': 145,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 23, 7, 5, 19, 832261),
 'item_scraped_count': 1021,
 'log_count/ERROR': 4,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1055,
 'scheduler/dequeued': 1055,
 'scheduler/dequeued/memory': 1055,
 'scheduler/enqueued': 1055,
 'scheduler/enqueued/memory': 1055,
 'spider_exceptions/TypeError': 3,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2016, 11, 23, 7, 4, 56, 806071)}
2016-11-23 15:05:19 [scrapy] INFO: Spider closed (finished)
2016-11-23 15:05:21 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-23 15:05:21 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-23 15:05:21 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-23 15:05:21 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-23 15:05:21 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-23 15:05:21 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-23 15:05:21 [scrapy] INFO: Spider opened
2016-11-23 15:05:21 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-23 15:05:22 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/tzjj/00/201611/t20161109_5090199.html> (referer: http://www.cs.com.cn/xwzx/hwxx/index_7.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/spiders/cs.py", line 110, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:05:30 [scrapy] ERROR: Spider error processing <GET http://www.cs.com.cn/xwzx/xwzt/151215_61693/01/201611/t20161117_5097402.html> (referer: http://www.cs.com.cn/xwzx/hg/index_4.html)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/spiders/cs.py", line 110, in parse_item
    item['time'] = response.xpath('//span[@class="ctime01"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:05:32 [scrapy] INFO: Closing spider (finished)
2016-11-23 15:05:32 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 236182,
 'downloader/request_count': 790,
 'downloader/request_method_count/GET': 790,
 'downloader/response_bytes': 6694487,
 'downloader/response_count': 790,
 'downloader/response_status_count/200': 790,
 'dupefilter/filtered': 10,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 23, 7, 5, 32, 223092),
 'item_scraped_count': 768,
 'log_count/ERROR': 2,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 790,
 'scheduler/dequeued': 790,
 'scheduler/dequeued/memory': 790,
 'scheduler/enqueued': 790,
 'scheduler/enqueued/memory': 790,
 'spider_exceptions/TypeError': 2,
 'start_time': datetime.datetime(2016, 11, 23, 7, 5, 21, 317582)}
2016-11-23 15:05:32 [scrapy] INFO: Spider closed (finished)
2016-11-23 15:05:33 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-23 15:05:33 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-23 15:05:33 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-23 15:05:33 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-23 15:05:33 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-23 15:05:33 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-23 15:05:33 [scrapy] INFO: Spider opened
2016-11-23 15:05:33 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-23 15:06:10 [scrapy] ERROR: Spider error processing <GET http://yjbg.cnstock.com/> (referer: http://company.cnstock.com/company/scp_gsxw/62)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:06:15 [scrapy] ERROR: Spider error processing <GET http://www.cnstock.com> (referer: http://company.cnstock.com/company/scp_gsxw/69)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:06:33 [scrapy] INFO: Crawled 2458 pages (at 2458 pages/min), scraped 2336 items (at 2336 items/min)
2016-11-23 15:07:18 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/topics/xzqmsdwk15> (referer: http://company.cnstock.com/company/scp_gsxw/180)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:07:19 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/topics/xzqmsdwk15/201512/3663412.htm> (referer: http://company.cnstock.com/company/scp_gsxw/183)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:07:28 [scrapy] ERROR: Spider error processing <GET http://yjbg.cnstock.com/dyjm> (referer: http://company.cnstock.com/company/scp_gsxw/201)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:07:33 [scrapy] INFO: Crawled 4793 pages (at 2335 pages/min), scraped 4556 items (at 2220 items/min)
2016-11-23 15:07:35 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/company/scp_ggjd/gszhuanti/20153jb> (referer: http://company.cnstock.com/company/scp_gsxw/196)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:07:54 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/ggdetail/index/2000589770> (referer: http://company.cnstock.com/company/scp_gsxw/63)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:08:15 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u738b\u5c79\uff09 \u529b\u5e06\u80a1\u4efd9\u670830\u665a\u95f4\u516c\u544a\uff0c\u516c\u53f8\u62df\u534f\u540c\u5168\u8d44\u5b50\u516c\u53f8\u91cd\u5e86\u529b\u5e06\u5b9e\u4e1a\uff08\u96c6\u56e2\uff09\u8fdb\u51fa\u53e3\u6709\u9650\u516c\u53f8\u5171\u540c\u6295\u8d44\u4e0d\u8d85\u8fc73\u4ebf\u7f8e\u5143\u5728\u4fc4\u7f57\u65af\u5229\u4f69\u8328\u514b\u5dde\u5883\u5185\u65b0\u8bbe\u4e3b\u4f53\u5efa\u5382\u751f\u4ea7\u8f66\u8f86\uff0c\u5176\u4e2d\uff0c\u529b\u5e06\u80a1\u4efd\u5360\u6bd45%\uff0c\u529b\u5e06\u8fdb\u51fa\u53e3\u5360\u6bd495%\u3002</p><p>\u3000\u3000\u529b\u5e06\u80a1\u4efd\u4eca\u5e748\u670819\u65e5\u8463\u4e8b\u4f1a\u66fe\u51b3\u5b9a\uff0c\u62df\u901a\u8fc7\u529b\u5e06\u56fd\u9645(\u63a7\u80a1)\u6709\u9650\u516c\u53f8\u5728\u65b0\u52a0\u5761\u8bbe\u7acb\u7684\u5168\u8d44\u5b50\u516c\u53f8\u2014\u2014\u529b\u5e06\u56fd\u9645\uff08\u8d38\u6613\uff09\u6709\u9650\u516c\u53f8\uff0c\u6295\u8d441.5\u4ebf\u5143\u7f8e\u91d1\u5728\u4fc4\u7f57\u65af\u5361\u5362\u52a0\u5dde\u6295\u8d44\u5efa\u5382\u53ca\u751f\u4ea7\u548c\u9500\u552e\u8f66\u8f86\uff0c\u5e76\u5c31\u4e0a\u8ff0\u6295\u8d44\u4e8b\u5b9c\u4e0e\u5f53\u5730\u653f\u5e9c\u4ee3\u8868\u7b7e\u7f72\u300a\u6295\u8d44\u610f\u5411\u534f\u8bae\u300b\u3002</p><p>\u3000\u3000\u5bf9\u4e8e\u6b64\u6b21\u53d8\u66f4\uff0c\u529b\u5e06\u80a1\u4efd\u8868\u793a\uff0c\u5728\u4fc4\u7f57\u65af\u5361\u5362\u52a0\u5dde\u6295\u8d44\u5efa\u5382\u53ca\u751f\u4ea7\u548c\u9500\u552e\u8f66\u8f86\u7684\u5177\u4f53\u5b89\u6392\u4e0e\u5f53\u5730\u653f\u5e9c\u4ee3\u8868\u672a\u80fd\u8fbe\u6210\u4e00\u81f4\uff0c\u4e5f\u6ca1\u6709\u6b63\u5f0f\u7b7e\u7f72\u6295\u8d44\u610f\u5411\u6587\u4ef6\u3002\u7ecf\u516c\u53f8\u7814\u7a76\u8ba8\u8bba\uff0c\u62df\u6539\u5728\u6295\u8d44\u53ca\u751f\u4ea7\u73af\u5883\u66f4\u4e3a\u9002\u5b9c\u7684\u4fc4\u7f57\u65af\u5229\u4f69\u8328\u514b\u5dde\u5883\u5185\u5efa\u5382\u3001\u5e76\u8c03\u6574\u6295\u8d44\u989d\u5ea6\u53ca\u6295\u8d44\u4e3b\u4f53\u3002</p><p>\u3000\u3000\u6839\u636e\u516c\u544a\uff0c\u4e0a\u8ff0\u9879\u76ee\u6267\u884c\u5730\u5728\u5229\u4f69\u8328\u514b\u5dde\u5229\u4f69\u8328\u514b\u8054\u90a6\u7ecf\u6d4e\u7279\u533a\uff0c\u571f\u5730\u7531\u5f53\u5730\u653f\u5e9c\u843d\u5b9e\uff0c\u5efa\u8bbe\u671f\u95f4\u79df\u8d41\u4e88\u529b\u5e06\u80a1\u4efd\u6216\u5176\u5b50\u516c\u53f8\u3002\u5de5\u5382\u8fd0\u8425\u540e\uff0c\u529b\u5e06\u65b9\u9762\u83b7\u5f97\u8d2d\u4e70\u8be5\u5730\u5757\u7684\u6743\u5229\uff0c\u5f53\u5730\u653f\u5e9c\u5219\u4fdd\u8bc1\u7ed9\u4e88\u5176\u989d\u59163\u516c\u9877\u571f\u5730\u7528\u4e8e\u5458\u5de5\u5bbf\u820d\u5efa\u8bbe\uff0c\u5e76\u8d1f\u8d23\u7ed9\u4e88\u5168\u9762\u534f\u52a9\u3002\u6b64\u5916\uff0c\u5f53\u5730\u653f\u5e9c\u53ca\u7ecf\u6d4e\u7279\u533a\u7ba1\u7406\u516c\u53f8\u8fd8\u5c06\u534f\u52a9\u529b\u5e06\u83b7\u53d6\u9002\u7528\u4fc4\u7f57\u65af\u8054\u90a6\u53ca\u8be5\u5dde\u6cd5\u5f8b\u7684\u5404\u9879\u7a0e\u6536\u4f18\u60e0\u653f\u7b56\uff0c\u8fdb\u53e3\u81f3\u8054\u90a6\u7ecf\u6d4e\u7279\u533a\u5185\u7684\u8d27\u7269\u514d\u9664\u5173\u7a0e\u3001\u589e\u503c\u7a0e\uff0c\u5e76\u5b9a\u671f\u4fdd\u6301\u53cc\u65b9\u7684\u4f1a\u89c1\u548c\u4f1a\u8bae\u4ee5\u89e3\u51b3\u9879\u76ee\u6295\u8d44\u7684\u5404\u79cd\u95ee\u9898\u3002</p><p>\u3000\u3000\u636e\u4e86\u89e3\uff0c\u5229\u4f69\u8328\u514b\u5dde\u4f4d\u4e8e\u4fc4\u7f57\u65af\u6b27\u6d32\u90e8\u5206\u7684\u4e2d\u5fc3\uff0c\u8ddd\u83ab\u65af\u79d1400\u516c\u91cc\uff0c\u5c06\u4fc4\u7f57\u65af\u9996\u90fd\u548c\u4fc4\u5357\u90e8\u3001\u5317\u9ad8\u52a0\u7d22\u3001\u4fc4\u897f\u90e8\u3001\u4f0f\u5c14\u52a0\u6cb3\u6d41\u57df\u8fde\u63a5\u5728\u4e00\u8d77\uff0c\u662f\u91cd\u8981\u7684\u4ea4\u901a\u67a2\u7ebd\u3002\u5dde\u9762\u79ef2.4\u4e07\u5e73\u65b9\u516c\u91cc\uff0c\u4eba\u53e3120\u4e07\u3002\u65e9\u5728\u524d\u82cf\u8054\u65f6\u671f\uff0c\u8be5\u5dde\u5c31\u5df2\u7ecf\u662f\u751f\u4ea7\u767d\u8272\u5bb6\u7535\u7684\u5de5\u4e1a\u57fa\u5730\uff0c\u4ea7\u54c1\u5305\u62ec\u51b0\u7bb1\u3001\u6d17\u8863\u673a\u3001\u7a7a\u8c03\u7b49\u3002\u5f53\u5730\u5de5\u4e1a\u57fa\u7840\u8f83\u96c4\u539a\uff0c\u6709\u94a2\u94c1\u5382\u3001\u5927\u578b\u953b\u9020\u4f01\u4e1a\u7b49\u7b49\uff0c\u5177\u6709\u8f83\u4e3a\u5b8c\u5584\u7684\u5de5\u4e1a\u7efc\u5408\u4f53\u7cfb\u548c\u914d\u5957\u4ea7\u4e1a\uff0c\u76f8\u8f83\u4e8e\u5361\u5362\u52a0\u5dde\u5177\u6709\u66f4\u4e3a\u5b8c\u5584\u7684\u751f\u4ea7\u914d\u5957\u73af\u5883\u548c\u66f4\u4f18\u7684\u6295\u8d44\u73af\u5883\u3002</p><p>\u3000\u3000\u529b\u5e06\u80a1\u4efd\u63d0\u793a\uff0c\u672c\u6b21\u7b7e\u7f72\u7684\u534f\u8bae\u5c5e\u4e8e\u610f\u5411\u6027\u534f\u8bae\uff0c\u5176\u4e2d\u5404\u65b9\u8868\u8fbe\u4e86\u76f8\u4e92\u5408\u4f5c\u610f\u613f\u5e76\u56fa\u5316\u4e86\u5177\u4f53\u5408\u4f5c\u6761\u4ef6\u53ca\u4f18\u60e0\u653f\u7b56\uff0c\u6700\u7ec8\u6295\u8d44\u65b9\u6848\u5728\u6295\u8d44\u5b9e\u65bd\u65f6\u6240\u6d89\u5185\u5bb9\u53ef\u80fd\u4f1a\u53d1\u751f\u53d8\u5316\u53ca\u8c03\u6574\uff0c\u6700\u7ec8\u4ee5\u83b7\u5f97\u56fd\u5185\u76f8\u5173\u5ba1\u6279\u90e8\u95e8\u6279\u51c6\u4e3a\u51c6\u3002</p><p>\u3000\u3000\u636e\u529b\u5e06\u80a1\u4efd\u6709\u5173\u8d1f\u8d23\u4eba\u4ecb\u7ecd\uff0c\u51fa\u53e3\u4e1a\u52a1\u5386\u6765\u662f\u516c\u53f8\u6210\u957f\u58ee\u5927\u7684\u201c\u6cd5\u5b9d\u4e4b\u4e00\u201d\uff0c\u8fd1\u5e74\u6765\u66f4\u52a0\u5927\u4e86\u5bf9\u6d77\u5916\u5e02\u573a\u7684\u62d3\u5c55\u529b\u5ea6\u30022013\u5e74\u516c\u53f8\u51fa\u53e3\u91d1\u989d\u8fbe53.52\u4ebf\u5143\uff0c\u4fdd\u6301\u91cd\u5e86\u6c11\u8425\u5236\u9020\u4f01\u4e1a\u7b2c\u4e00\uff0c\u5360\u516c\u53f8\u8425\u4e1a\u603b\u6536\u5165\u6bd4\u91cd\u5df2\u8d85\u8fc7\u4e00\u534a\u3002\u5176\u4e2d\uff0c\u529b\u5e06\u8f7f\u8f66\u51fa\u53e3\u4f4d\u5217\u4e2d\u56fd\u81ea\u4e3b\u54c1\u724c\u8f7f\u8f66\u51fa\u53e3\u7b2c\u4e09\u540d\uff0c\u8fde\u7eed\u4e09\u5e74\u4e3a\u4fc4\u7f57\u65af\u4e2d\u56fd\u8f66\u4f01\u9500\u91cf\u51a0\u519b\uff1b\u6469\u6258\u8f66\u51fa\u53e3\u9500\u91cf\u4ea6\u589e\u957f\u4e8614.11%\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3197648">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 30, 0, 0),
 'title': u'\u529b\u5e06\u80a1\u4efd\u8c03\u6574\u4fc4\u7f57\u65af\u5de5\u5382\u5730\u5740 \u6295\u8d44\u89c4\u6a21\u589e\u81f33\u4ebf\u7f8e\u5143',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3197648.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1298, in __create_index
    sock_info, cmd, read_preference=ReadPreference.PRIMARY)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 208, in _command
    read_concern=read_concern)
  File "/Library/Python/2.7/site-packages/pymongo/pool.py", line 244, in command
    self._raise_connection_failure(error)
  File "/Library/Python/2.7/site-packages/pymongo/pool.py", line 372, in _raise_connection_failure
    raise error
AutoReconnect: connection closed
2016-11-23 15:08:45 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\xa0\u8bb0\u8005\xa0\u4e25\u7fe0\uff09 \u56fd\u5185\u81b3\u98df\u8425\u517b\u8865\u5145\u5242\u9886\u5148\u4f01\u4e1a\u6c64\u81e3\u500d\u50659\u670830\u65e5\u665a\u95f4\u53d1\u5e03\u524d\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u9884\u544a\u663e\u793a\uff0c\u9884\u8ba1\u4eca\u5e74\u524d\u4e09\u5b63\u5ea6\u51c0\u5229\u6da6\u4e3a\xa04.4199\xa0\u4ebf\u5143-5.1271\u4ebf\u5143\uff0c\u53bb\u5e74\u540c\u671f\u4e3a3.535948\u4ebf\u5143\uff0c\u540c\u6bd4\u589e\u957f25%-45%\u3002</p><p>\u3000\u3000\u6c64\u81e3\u500d\u5065\u8868\u793a\uff0c2014\xa0\u5e74\u524d\u4e09\u5b63\u5ea6\uff0c\u516c\u53f8\u843d\u5b9e\xa02014\xa0\u5e74\u5ea6\u7ecf\u8425\u8ba1\u5212\u7684\u8981\u6c42\uff0c\u59cb\u7ec8\u575a\u6301\u201c\u53d6\u81ea\u5168\u7403\uff0c\u5065\u5eb7\u5168\u5bb6\u201d\u7684\u54c1\u724c\u7406\u5ff5\uff0c\u7740\u624b\u63d0\u5347\u670d\u52a1\u529b\uff0c\u542f\u52a8\u4e0e\u63a8\u5e7f\u201c\u8425\u517b\u5bb6\u4f53\u7cfb\u201d\uff0c\u5b9a\u5236\u5168\u65b0\u7ba1\u7406\u7cfb\u7edf\u4ee5\u6253\u9020\u6838\u5fc3\u7ade\u4e89\u529b\uff1b\u7ee7\u7eed\u5f00\u62d3\u5355\u54c1\u65b0\u6a21\u5f0f\u7b49\u65b0\u54c1\u724c\u3001\u65b0\u54c1\u7c7b\u3001\u65b0\u9879\u76ee\u7b49\u5229\u6da6\u589e\u957f\u70b9\uff0c\u63a8\u51fa\u4e0e\u79ef\u6781\u57f9\u80b2\u57fa\u4e8e\u79fb\u52a8\u4e92\u8054\u7f51\u601d\u7ef4\u7684\u5065\u5eb7\u7ba1\u7406\u54c1\u724c\u201c\u5341\u4e8c\u7bee\u201d\u3002\u57fa\u4e8e\u6b64\u516c\u53f8\u9884\u8ba1\xa02014\xa0\u5e74\u524d\u4e09\u5b63\u5ea6\u516c\u53f8\u9500\u552e\u6536\u5165\u8f83\u53bb\u5e74\u540c\u671f\u5c06\u6709\u4e00\u5b9a\u5e45\u5ea6\u589e\u957f\uff0c\u5bfc\u81f4\u516c\u53f8\xa02014\xa0\u5e74\u524d\u4e09\u5b63\u5ea6\u7684\u4e1a\u7ee9\u8f83\u53bb\u5e74\u540c\u671f\u6709\u4e00\u5b9a\u5e45\u5ea6\u589e\u52a0\u3002</p><p>\u3000\u3000\u56de\u67e5\u6c64\u81e3\u500d\u5065\u8d22\u52a1\u6570\u636e\u53d1\u73b0\uff0c\u51762013\u5e74\u5ea6\u3001\u4eca\u5e74\u4e00\u5b63\u5ea6\u3001\u4ee5\u53ca\u4eca\u5e74\u4e0a\u534a\u5e74\u51c0\u5229\u6da6\u5206\u522b\u540c\u6bd4\u589e\u957f50.41%\u300150.68%\u300151.6%\uff0c\u56e0\u6b64\u5bf9\u6bd4\u672c\u6b21\u51c0\u5229\u6da6\u9884\u589e\u60c5\u51b5\u770b\uff0c\u4eca\u5e74\u7b2c\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u6bd4\u6b64\u524d\u7684\u9ad8\u589e\u901f\u6216\u7a0d\u6709\u56de\u843d\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3197661">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 30, 0, 0),
 'title': u'\u6c64\u81e3\u500d\u5065\u524d\u4e09\u5b63\u5ea6\u51c0\u5229\u9884\u589e25%-45%',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3197661.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:08:45 [scrapy] INFO: Crawled 6414 pages (at 1621 pages/min), scraped 6145 items (at 1589 items/min)
2016-11-23 15:09:15 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p><p></p></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u738b\u5c79\uff09 \u897f\u5357\u8bc1\u52389\u670830\u65e5\u665a\u95f4\u516c\u544a,\u7ecf9\u670829\u65e5\u53ec\u5f00\u7684\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u53d1\u884c\u5ba1\u6838\u59d4\u5458\u4f1a\u5ba1\u6838\uff0c\u516c\u53f8\u53d1\u884c\u516c\u53f8\u503a\u5238\u7533\u8bf7\u83b7\u5f97\u901a\u8fc7\u3002\u6309\u7167\u89c4\u5b9a,\u516c\u53f8\u5c06\u5728\u6536\u5230\u8bc1\u76d1\u4f1a\u6b63\u5f0f\u6279\u6587\u540e\u65b9\u80fd\u542f\u52a8\u53d1\u884c\u4e8b\u5b9c\u3002</p><p>\u3000\u3000\u4eca\u5e745\u670812\u65e5\uff0c\u897f\u5357\u8bc1\u5238\u80a1\u4e1c\u5927\u4f1a\u5ba1\u8bae\u901a\u8fc7\u4e86\u300a\u5173\u4e8e\u516c\u53f8\u53d1\u884c\u516c\u53f8\u503a\u5238\u7684\u8bae\u6848\u300b\uff0c\u62df\u6309\u4e0d\u8d85\u8fc7\u53d1\u884c\u524d\u6700\u8fd1\u4e00\u671f\u672b\u51c0\u8d44\u4ea7\u989d\u768440%\u7684\u89c4\u5b9a\u4e0a\u9650\u7533\u8bf7\u53d1\u884c\u516c\u53f8\u503a\u5238\uff0c\u671f\u9650\u4e3a\u4e0d\u8d85\u8fc710\u5e74\uff0c\u53ef\u4ee5\u4e3a\u5355\u4e00\u671f\u9650\u54c1\u79cd\uff0c\u4e5f\u53ef\u4ee5\u4e3a\u591a\u79cd\u671f\u9650\u7684\u6df7\u5408\u54c1\u79cd\uff0c\u52df\u96c6\u8d44\u91d1\u5168\u90e8\u7528\u4e8e\u8865\u5145\u516c\u53f8\u8425\u8fd0\u8d44\u91d1\u3002</p><p>\u3000\u3000\u6839\u636e\u897f\u5357\u8bc1\u5238\u622a\u81f3\u4eca\u5e746\u670830\u65e5\u7684\u51c0\u8d44\u4ea7154\u4ebf\u5143\u8ba1\uff0c\u6700\u591a\u53ef\u53d1\u884c\u7ea660\u4ebf\u5143\u516c\u53f8\u503a\u5238\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3197647">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 30, 0, 0),
 'title': u'\u897f\u5357\u8bc1\u5238\u516c\u53f8\u503a\u53d1\u884c\u7533\u8bf7\u83b7\u5ba1\u6838\u901a\u8fc7',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3197647.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:09:45 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u4e25\u7fe0\uff09 \u79d1\u529b\u8fdc9\u670830\u65e5\u665a\u95f4\u516c\u544a\uff0c\u516c\u53f8\u5168\u8d44\u5b50\u516c\u53f8\u6e56\u5357\u79d1\u9738\u52a8\u529b\u7535\u6c60\u6709\u9650\u8d23\u4efb\u516c\u53f8\u8fd1\u65e5\u6536\u5230\u653f\u5e9c\u8865\u8d34\u5171\u8ba13548\u4e07\u5143\uff0c\u8d44\u91d1\u5df2\u4e8e2014\u5e749\u670829\u65e5\u5230\u8d26\u3002<br>\u3000\u3000\u4e0a\u8ff0\u653f\u5e9c\u8865\u8d34\u5747\u6765\u81ea\u65b0\u80fd\u6e90\u6c7d\u8f66\u76f8\u5173\u9879\u76ee\uff0c\u5305\u62ec\u4e24\u90e8\u5206\uff0c\u5176\u4e00\u662f\u6839\u636e\u957f\u6c99\u5e02\u8d22\u653f\u5c40\u300a\u5173\u4e8e\u4e0b\u8fbe2014\u5e74\u7a00\u571f\u4ea7\u4e1a\u8865\u52a9\u8d44\u91d1\u9884\u7b97\uff08\u62e8\u6b3e\uff09\u7684\u901a\u77e5\u300b\uff08\u957f\u8d22\u4f01\u6307[2014]74\u53f7\uff09\uff0c\u79d1\u9738\u516c\u53f8\u83b7\u5f972014\u5e74\u7a00\u571f\u4ea7\u4e1a\u8865\u52a9\u8d44\u91d11178\u4e07\u5143\uff0c\u7528\u4e8e\u201c\u5e74\u4ea74.8\u4e07\u53f0\u5957\u65b0\u80fd\u6e90\u6c7d\u8f66\u7528\u7a00\u571f\u50a8\u6c22\u5408\u91d1\u52a8\u529b\u7535\u6c60\u6a21\u5757\u4ea7\u4e1a\u5316\u201d\u9879\u76ee\u3002 <br>\u3000\u3000\u5176\u4e8c\uff0c\u662f\u6839\u636e\u957f\u6c99\u5e02\u8d22\u653f\u5c40\u3001\u957f\u6c99\u5e02\u5de5\u4e1a\u548c\u4fe1\u606f\u5316\u59d4\u5458\u4f1a\u300a\u5173\u4e8e\u4e0b\u8fbe2014\u5e74\u5de5\u4e1a\u8f6c\u578b\u5347\u7ea7\uff08\u5de5\u4e1a\u5f3a\u57fa\u5de5\u7a0b\uff09\u8d44\u91d1\u7684\u901a\u77e5\u300b\uff08\u957f\u8d22\u4f01\u6307[2014]75\u53f7\uff09\uff0c\u79d1\u9738\u516c\u53f8\u83b7\u5f972014\u5e74\u5de5\u4e1a\u8f6c\u578b\u5347\u7ea7\uff08\u5de5\u4e1a\u5f3a\u57fa\u5de5\u7a0b\uff09\u8d44\u91d12370\u4e07\u5143\uff0c\u7528\u4e8e\u201c\u6df7\u5408\u52a8\u529b\u6c7d\u8f66\u954d\u6c22\u7535\u6c60\u5b9e\u65bd\u65b9\u6848\u201d\u9879\u76ee\u3002<br>\u3000\u3000\u4eca\u5e74\u4ee5\u6765\uff0c\u79d1\u529b\u8fdc\u4e00\u76f4\u5728\u52a0\u5927\u5bf9\u65b0\u80fd\u6e90\u6c7d\u8f66\u4e1a\u52a1\u7684\u6295\u5165\u4e0e\u89c4\u5212\u529b\u5ea6\u3002\u5982\u4eca\u5e745\u670827\u65e5\u665a\uff0c\u79d1\u529b\u8fdc\u516c\u544a\u62df\u5411\u56db\u5bb6\u6218\u7565\u6295\u8d44\u673a\u6784\u975e\u516c\u5f00\u53d1\u884c2810\u4e07\u81f34680\u4e07\u80a1\u80a1\u7968\uff0c\u52df\u8d446\u4ebf-10\u4ebf\u7528\u4e8e\u8865\u5145\u6d41\u52a8\u8d44\u91d1\u65f6\uff0c\u79d1\u529b\u8fdc\u603b\u7ecf\u7406\u7f57\u97ec\u5c31\u66fe\u660e\u786e\u8868\u793a\uff0c\u201c\u672c\u6b21\u975e\u516c\u5f00\u52df\u8d44\uff0c\u6709\u5229\u4e8e\u5feb\u901f\u63a8\u8fdbHEV\uff08\u6df7\u5408\u52a8\u529b\u6c7d\u8f66\uff09\u7535\u6c60\u80fd\u91cf\u5305\u5efa\u8bbe\uff0c\u4e3a\u516c\u53f8HEV\u52a8\u529b\u7535\u6c60\u4e1a\u52a1\u7206\u53d1\u505a\u51c6\u5907\u201d\u3002<br>\u3000\u3000\u518d\u5982\uff0c9\u670819\u65e5\u665a\uff0c\u79d1\u529b\u8fdc\u518d\u5ea6\u516c\u544a\uff0c\u62df\u8054\u59fb\u201c\u5409\u5229\u201d\uff0c\u5171\u540c\u6210\u7acb\u5408\u8d44\u516c\u53f8\uff0c\u6df1\u8015\u6df7\u5408\u52a8\u529b\u6c7d\u8f66\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3197662">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 30, 0, 0),
 'title': u'\u79d1\u529b\u8fdc\u65b0\u80fd\u6e90\u6c7d\u8f66\u9879\u76ee\u83b73548\u4e07\u653f\u5e9c\u8865\u8d34',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3197662.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:10:15 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u674e\u7433\uff09 \u8f89\u4e30\u80a1\u4efd\u4e0e\u4e30\u4e1c\u80a1\u4efd10\u67087\u65e5\u665a\u95f4\u540c\u65f6\u53d1\u5e03\u516c\u544a\uff0c\u7531\u8f89\u4e30\u80a1\u4efd\u4f5c\u4e3a\u4e3b\u53d1\u8d77\u4eba\uff0c\u4e24\u516c\u53f8\u53c2\u80a1\u7533\u8bf7\u8bbe\u7acb\u7684\u519c\u6751\u5c0f\u8d37\u516c\u53f8\u83b7\u6c5f\u82cf\u7701\u91d1\u878d\u529e\u7b79\u5efa\u6279\u590d\u3002<br>\u3000\u3000\u6839\u636e\u516c\u544a\uff0c\u8f89\u4e30\u80a1\u4efd\u4e0e\u4e30\u4e1c\u80a1\u4efd\u5747\u4e8e\u8fd1\u65e5\u6536\u5230\u6c5f\u82cf\u7701\u4eba\u6c11\u653f\u5e9c\u91d1\u878d\u529e\u4e0b\u53d1\u7684\u300a\u5173\u4e8e\u540c\u610f\u7b79\u5efa\u5927\u4e30\u5e02\u6cbf\u6d77\u519c\u6751\u5c0f\u989d\u8d37\u6b3e\u6709\u9650\u516c\u53f8\u7684\u6279\u590d\u300b\uff0c\u540c\u610f\u4e24\u516c\u53f8\u53d1\u8d77\u8bbe\u7acb\u5927\u4e30\u5e02\u6cbf\u6d77\u519c\u6751\u5c0f\u989d\u8d37\u6b3e\u6709\u9650\u516c\u53f8\uff0c\u7b79\u5efa\u5730\u70b9\u4e3a\u5927\u4e30\u5e02\u897f\u56e2\u9547\uff0c\u7b79\u5907\u671f\u6700\u957f\u4e0d\u8d85\u8fc76 \u4e2a\u6708\u3002<br>\u3000\u3000\u540c\u5904\u5927\u4e30\u5e02\u7684\u8f89\u4e30\u80a1\u4efd\u548c\u4e30\u4e1c\u80a1\u4efd\u4ece2013\u5e7410\u6708\u4e2d\u65ec\u5f00\u59cb\u8054\u624b\u53d1\u8d77\u8bbe\u7acb\u5c0f\u989d\u8d37\u6b3e\u516c\u53f8\uff0c\u6ce8\u518c\u8d44\u672c\u4e3a2\u4ebf\u5143\uff0c\u5c0f\u8d37\u516c\u53f8\u7684\u6295\u8d44\u65b9\u5f53\u65f6\u62df\u5b9a\u4e3a5\u540d\uff0c\u5305\u62ec\u8f89\u4e30\u80a1\u4efd\u3001\u4e30\u4e1c\u80a1\u4efd\u548c3\u540d\u81ea\u7136\u4eba\u3002\u5176\u4e2d\uff0c\u8f89\u4e30\u80a1\u4efd\u51fa\u8d447000\u4e07\u5143\uff0c\u5360\u603b\u80a1\u672c\u768435%\uff0c\u4e3a\u4e3b\u53d1\u8d77\u4eba\uff1b\u4e30\u4e1c\u80a1\u4efd\u51fa\u8d444000\u4e07\u5143\uff0c\u5360\u5176\u6ce8\u518c\u8d44\u672c\u768420%\u3002<br>\u3000\u3000\u6b64\u6b21\u7b79\u5efa\u7684\u5927\u4e30\u5e02\u6cbf\u6d77\u519c\u6751\u5c0f\u989d\u8d37\u6b3e\u6709\u9650\u516c\u53f8\u4ee5\u670d\u52a1\u201c\u4e09\u519c\u201d\u4e3a\u5b97\u65e8\uff0c\u4e0d\u5438\u6536\u516c\u4f17\u5b58\u6b3e\uff0c\u4e3b\u8425\u4e1a\u52a1\u4e3a\u9762\u5411\u201c\u4e09\u519c\u201d\u53d1\u653e\u5c0f\u989d\u8d37\u6b3e\u3001\u63d0\u4f9b\u62c5\u4fdd\u3002<br>\u3000\u3000\u6839\u636e\u6b64\u524d\u53d1\u8d77\u8bbe\u7acb\u65f6\u7684\u9884\u60f3\uff0c\u5c0f\u8d37\u516c\u53f8\u5229\u7387\u4e0a\u9650\u8f83\u5176\u4ed6\u91d1\u878d\u673a\u6784\u9ad8\uff0c\u53ef\u83b7\u5f97\u7a33\u5b9a\u548c\u8f83\u597d\u7684\u6536\u76ca\u3002\u8f89\u4e30\u80a1\u4efd\u66f4\u9884\u671f\u5c0f\u8d37\u516c\u53f8\u6b63\u5e38\u7ecf\u84253\u5e74\u540e\uff0c\u6709\u671b\u6539\u5236\u4e3a\u6751\u9547\u94f6\u884c\uff0c\u521b\u9020\u66f4\u5927\u6548\u76ca\u3002<br>\u3000\u3000\u4e24\u516c\u53f8\u8868\u793a\uff0c\u5c06\u6309\u7167\u7b79\u5efa\u6279\u590d\u6587\u4ef6\u7684\u8981\u6c42\uff0c\u5c3d\u5feb\u5b8c\u6210\u9884\u5148\u6838\u51c6\u767b\u8bb0\u3001\u9009\u8058\u4e0e\u62a5\u5907\u9ad8\u7ba1\u53ca\u4ece\u4e1a\u4eba\u5458\u3001\u62df\u5b9a\u7ae0\u7a0b\u4e0e\u5236\u5ea6\u3001\u51fa\u8d44\u9a8c\u8d44\u3001\u7533\u8bf7\u5f00\u4e1a\u4ee5\u53ca\u5de5\u5546\u767b\u8bb0\u7b49\u5de5\u4f5c\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198061">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 7, 0, 0),
 'title': u'\u8f89\u4e30\u80a1\u4efd\u8054\u624b\u4e30\u4e1c\u80a1\u4efd\u7b79\u5efa\u519c\u6751\u5c0f\u8d37\u516c\u53f8\u83b7\u6279\u590d',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198061.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:10:46 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u4e25\u7fe0\uff09 \u8bd5\u56fe\u5927\u529b\u62d3\u5c55\u975e\u6d32\u5e02\u573a\u7684\u5168\u56fd\u5149\u7f06\u4e1a\u9996\u5bb6\u6c11\u8425\u4e0a\u5e02\u516c\u53f8\u6c38\u9f0e\u80a1\u4efd\uff0c\u5982\u4eca\u975e\u6d32\u5e02\u573a\u518d\u4e0b\u4e00\u57ce\u2014\u2014\u8d5e\u6bd4\u4e9a\u3002<br>\u3000\u3000\u6c38\u9f0e\u80a1\u4efd9\u670830\u65e5\u665a\u95f4\u516c\u544a\uff0c\u516c\u53f8\u63a7\u80a1\u5b50\u516c\u53f8\u6c5f\u82cf\u6c38\u9f0e\u6cf0\u5bcc\u5de5\u7a0b\u6709\u9650\u516c\u53f8\u8fd1\u65e5\u4e0e\u8d5e\u6bd4\u4e9a\u56fd\u6709\u7535\u529b\u516c\u53f8\u7b7e\u8ba2\u4e86\u201c\u8d5e\u6bd4\u4e9a\u65b0\u5efa\u3001\u6269\u5efa5\u4e2a132/33KV\u53d8\u7535\u7ad9\u548c\u65b0\u5efa6\u4e2a33/0.415KV\u53d8\u7535\u7ad9\u7684\u9879\u76ee\u5408\u540c\u201d\uff0c\u5408\u540c\u91d1\u989d\u7ea6\u6298\u5408\u4e3a2607\u4e07\u7f8e\u5143\u3002<br>\u3000\u3000\u6839\u636e\u534f\u8bae\uff0c\u8be5\u9879\u76ee\u672a\u63d0\u4f9b\u8bbe\u8ba1\uff0c\u4f9b\u8d27\uff0c\u571f\u5efa\u3001\u8c03\u8bd5\u7684\u4ea4\u94a5\u5319\u5de5\u7a0b\uff0c\u5de5\u671f2\u5e74\u3001\u8d28\u4fdd\u671f1\u5e74\uff0c\u4e1a\u4e3b\u4e3a\u8d5e\u6bd4\u4e9a\u56fd\u6709\u7535\u529b\u516c\u53f8ZESCO Limited\uff0c\u8d1f\u8d23\u8d5e\u6bd4\u4e9a\u5168\u56fd\u8f93\u7535\u8bbe\u65bd\u89c4\u5212\u3001\u5efa\u8bbe\u548c\u7ecf\u8425\u3002\u9879\u76ee\u7531\u6c38\u9f0e\u6cf0\u5bcc\u4e0e\u5317\u4eac\u4e2d\u7f06\u901a\u8fbe\u7535\u6c14\u6210\u5957\u6709\u9650\u516c\u53f8\uff0c\u8d5e\u6bd4\u4e9a\u5f53\u5730\u516c\u53f8Cavery Investment Limited\u7ec4\u6210\u7684\u8054\u5408\u4f53\u603b\u627f\u5305\u5efa\u9020\u3002<br>\u3000\u3000\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8be5\u5408\u540c\u4e3a\u6c38\u9f0e\u80a1\u4efd\u5728\u8d5e\u6bd4\u4e9a\u7684\u7b2c\u4e00\u4e2a\u603b\u627f\u5305\u5408\u540c\uff0c\u5408\u540c\u7684\u5229\u6da6\u9884\u8ba1\u4f4e\u4e8e\u516c\u53f8\u5728\u4f20\u7edf\u4e1c\u5357\u4e9a\u5e02\u573a\u540c\u7c7b\u5408\u540c\u7684\u5229\u6da6\uff0c\u5982\u672c\u5408\u540c\u5f97\u5230\u987a\u5229\u5c65\u884c\uff0c\u5c06\u5bf9\u6c38\u9f0e\u6cf0\u5bcc\u5f00\u62d3\u975e\u6d32\u65b0\u5e02\u573a\u5177\u6709\u8f83\u5927\u7684\u610f\u4e49\u3002<br>\u3000\u3000\u4e0d\u8fc7\uff0c\u6c38\u9f0e\u80a1\u4efd\u8868\u793a\uff0c\u8be5\u5408\u540c\u9884\u8ba1\u57282015\u5e74\u4e0b\u534a\u5e74\u5f00\u59cb\u6b63\u5f0f\u542f\u52a8\uff0c\u5bf9\u4e0a\u5e02\u516c\u53f8\u672c\u5e74\u5ea6\u7684\u8d44\u4ea7\u603b\u989d\u3001\u8d44\u4ea7\u51c0\u989d\u548c\u51c0\u5229\u6da6\u4e0d\u6784\u6210\u5f71\u54cd\u3002<br>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8bb0\u8005\u4e86\u89e3\u5230\uff0c\u53bb\u5e74\u4ee5\u6765\uff0c\u516c\u53f8\u975e\u6d32\u5e02\u573a\u5f00\u62d3\u8fdb\u5c55\u660e\u663e\uff0c\u5df2\u521d\u89c1\u6210\u6548\u3002\u4eca\u5e743\u6708\uff0c\u6c38\u9f0e\u80a1\u4efd\u63a7\u80a1\u5b50\u516c\u53f8\u6c5f\u82cf\u6c38\u9f0e\u6cf0\u5bcc\u5de5\u7a0b\u6709\u9650\u516c\u53f8\u521a\u521a\u7b7e\u4e0b\u975e\u6d32\u57c3\u585e\u4fc4\u6bd4\u4e9a972\u4e07\u7f8e\u5143\u8f93\u53d8\u7535\u5de5\u7a0b\u9879\u76ee\uff0c\u800c\u8fd9\u662f\u7ee7\u516c\u53f8\u53bb\u5e74\u7684\u5b5f\u52a0\u62c9KODDA 150MW\u7535\u5382\u9879\u76ee\u540e\u7684\u53c8\u4e00\u4e2a\u8f83\u5927\u91d1\u989d\u6d77\u5916\u5de5\u7a0b\u4e1a\u52a1\uff0c\u4e5f\u662f\u516c\u53f8\u4eca\u5e74\u5927\u529b\u62d3\u5c55\u975e\u6d32\u5e02\u573a\u7684\u91cd\u8981\u6536\u83b7\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3197668">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 30, 0, 0),
 'title': u'\u6c38\u9f0e\u80a1\u4efd\u975e\u6d32\u5e02\u573a\u518d\u4e0b\u4e00\u57ce \u83b7\u8d5e\u6bd4\u4e9a2607\u4e07\u7f8e\u5143\u5408\u540c',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3197668.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:11:16 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u4e25\u7fe0\uff09 2008\u5e74\u91d1\u878d\u5371\u673a\u4ee5\u6765\uff0c\u5168\u7403\u7ecf\u6d4e\u75b2\u8f6f\u3001\u4e2d\u56fd\u7ecf\u6d4e\u589e\u957f\u653e\u7f13\u3001\u822a\u8fd0\u5e02\u573a\u8fd0\u529b\u8fc7\u5269\u7b49\u5f71\u54cd\uff0c\u9677\u5165\u7ecf\u8425\u56f0\u5883\u7684\u4e2d\u56fd\u8fdc\u6d0b\uff0c\u4eca\u5e74\u6709\u671b\u56e0\u63a7\u80a1\u80a1\u4e1c\u7684\u503e\u56ca\u76f8\u52a9\u800c\u5b9e\u73b0\u626d\u4e8f\uff0c\u540c\u65f6\u6709\u671b\u201c\u6458\u5e3d\u201d<br>\u3000\u3000\u4e2d\u56fd\u8fdc\u6d0b9\u670830\u65e5\u665a\u95f4\u516c\u544a\uff0c\u516c\u53f8\u4e8e9\u670830\u65e5\u6536\u5230\u63a7\u80a1\u80a1\u4e1c\u4e2d\u56fd\u8fdc\u6d0b\u8fd0\u8f93(\u96c6\u56e2)\u603b\u516c\u53f8\u8f6c\u62e8\u4ed8\u7684\u8239\u8236\u62a5\u5e9f\u66f4\u65b0\u8865\u52a9\u8d44\u91d1\u4eba\u6c11\u5e0113.79\u4ebf\u5143\u3002 <br>\u3000\u3000\u516c\u53f8\u79f0\uff0c\u6839\u636e\u4f01\u4e1a\u4f1a\u8ba1\u51c6\u5219\u7684\u89c4\u5b9a\uff0c\u516c\u53f8\u5c06\u8be5\u7b14\u8865\u52a9\u8d44\u91d1\u786e\u8ba4\u4e3a\u8425\u4e1a\u5916\u6536\u5165\uff0c\u5e76\u8ba1\u51652014\u5e74\u5ea6\u635f\u76ca\uff0c\u5f25\u8865\u4f01\u4e1a\u56e0\u8239\u8236\u63d0\u524d\u62c6\u89e3\u5e26\u6765\u7684\u635f\u5931\uff0c\u5177\u4f53\u4f1a\u8ba1\u5904\u7406\u4ee5\u4f1a\u8ba1\u5e08\u4e8b\u52a1\u6240\u5e74\u5ea6\u5ba1\u8ba1\u786e\u8ba4\u540e\u7684\u7ed3\u679c\u4e3a\u51c6\u3002\u8be5\u7b14\u8865\u52a9\u8d44\u91d1\u7684\u53d6\u5f97\u5c06\u5bf9\u672c\u516c\u53f82014\u5e74\u5ea6\u7684\u7ecf\u8425\u4e1a\u7ee9\u4ea7\u751f\u4e00\u5b9a\u7684\u79ef\u6781\u5f71\u54cd\u3002<br>\u3000\u3000\u4e2d\u56fd\u8fdc\u6d0b\u662f\u4e2d\u8fdc\u96c6\u56e2\u65d7\u4e0b\u5927\u578b\u56fd\u4f01\uff0c\u4e5f\u662f\u5176\u91cd\u8981\u4e0a\u5e02\u5e73\u53f0\u30022008\u5e74\u4ee5\u6765\uff0c\u56e0\u822a\u8fd0\u5e02\u573a\u6574\u4f53\u4e0d\u666f\u6c14\u7b49\uff0c\u6301\u7eed\u9677\u5165\u4e8f\u635f\u5883\u51b5\u30022011\u5e74\u4e2d\u56fd\u8fdc\u6d0b\u5de8\u4e8f104\u4ebf\uff0c2012\u5e74\u518d\u4e8f95\u4ebf\uff0c\u8fde\u7eed\u4e24\u5e74\u5de8\u4e8f\u7684\u4e2d\u56fd\u8fdc\u6d0b\uff0c\u53d8\u6210\u4e86*ST\u8fdc\u6d0b\u3002\u597d\u5728\uff0c\u4e3a\u907f\u514d\u9000\u5e02\uff0c\u4e2d\u56fd\u8fdc\u6d0b\u53ca\u65f6\u901a\u8fc7\u5356\u8d44\u4ea7\u7684\u65b9\u5f0f\uff0c\u53bb\u5e74\u6210\u529f\u5b9e\u73b0\u4e86\u5fae\u5229\uff0c\u51c0\u5229\u6da6\u4e3a2.35\u4ebf\u3002<br>\u3000\u3000\u8d44\u6599\u663e\u793a\uff0c\u4e2d\u56fd\u8fdc\u6d0b\u5728\u53bb\u5e74\u5904\u7f6e\u8d44\u4ea7\u83b7\u5f97\u7684\u6536\u76ca\u9ad8\u8fbe84.26\u4ebf\u5143\uff0c\u88ab\u51fa\u552e\u7684\u8d44\u4ea7\u6709\u4e2d\u8fdc\u7269\u6d41100%\u80a1\u6743\u3001\u4e2d\u8fdc\u96c6\u88c5\u7bb1\u5de5\u4e1a\u516c\u53f8100%\u80a1\u6743\u4ee5\u53ca\u9752\u5c9b\uff08\u697c\u76d8\uff09\u3001\u4e0a\u6d77\uff08\u697c\u76d8\uff09\u7b49\u4e24\u5904\u7269\u4e1a\u8d44\u4ea7\u80a1\u6743\u9879\u76ee\u3002<br>\u3000\u3000\u7136\u800c\uff0c\u56e0\u56fd\u9645\u822a\u8fd0\u5e02\u573a\u4f9b\u6c42\u5931\u8861\u5c40\u9762\u4ecd\u65e0\u5b9e\u8d28\u6539\u5584\uff0c\u8fd0\u4ef7\u6c34\u5e73\u4f4e\u4f4d\u5f98\u5f8a\uff0c\u5e02\u573a\u7ade\u4e89\u6fc0\u70c8\uff0c\u540c\u65f6\uff0c\u71c3\u6cb9\u4ef7\u683c\u4ecd\u5904\u9ad8\u4f4d\uff0c\u4e2d\u56fd\u8fdc\u6d0b\u7ecf\u8425\u627f\u53d7\u5de8\u5927\u538b\u529b\uff0c\u4eca\u5e74\u4e00\u5b63\u5ea6\u53ca\u4eca\u5e74\u4e0a\u534a\u5e74\uff0c\u4e2d\u56fd\u8fdc\u6d0b\u4f9d\u7136\u5206\u522b\u4e8f\u635f18.8\u4ebf\u5143\u300128.8\u4ebf\u5143\u3002<br>\u3000\u3000\u5206\u6790\u4eba\u58eb\u6307\u51fa\uff0c\u6b64\u6b21\u63a7\u80a1\u80a1\u4e1c\u503e\u56ca\u76f8\u52a9\u8fd114\u4ebf\u5143\uff0c\u6709\u52a9\u4e8e\u4e2d\u56fd\u8fdc\u6d0b\u6539\u5584\u4e1a\u7ee9\uff0c\u4e14\u82e5\u540e\u7eed\u7ee7\u7eed\u83b7\u5f97\u8865\u52a9\u6216\u5356\u51fa\u4e00\u4e9b\u8d44\u4ea7\u83b7\u5f97\u6536\u76ca\uff0c\u4ee5\u53ca\u516c\u53f8\u4e3b\u4e1a\u7ecf\u8425\u6539\u5584\uff0c\u4e2d\u56fd\u8fdc\u6d0b\u4eca\u5e74\u6709\u671b\u626d\u4e8f\u4e3a\u76c8\uff0c\u4ece\u800c\u6210\u529f\u5b9e\u73b0\u8131\u5e3d\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3197669">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 30, 0, 0),
 'title': u'\u63a7\u80a1\u80a1\u4e1c\u503e\u529b\u8865\u52a913.8\u4ebf \u4e2d\u56fd\u8fdc\u6d0b\u626d\u4e8f\u5728\u671b',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3197669.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:11:16 [scrapy] INFO: Crawled 6414 pages (at 0 pages/min), scraped 6145 items (at 0 items/min)
2016-11-23 15:11:46 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u6ed5\u98de\uff09 \u5fb7\u68c9\u80a1\u4efd10\u67087\u65e5\u665a\u95f4\u516c\u544a\uff0c\u516c\u53f8\u4e8e9\u670830\u65e5\u4e0e\u5317\u4eac\u548c\u5408\u6c38\u5174\u79d1\u6280\u6709\u9650\u516c\u53f8\uff08\u4ee5\u4e0b\u7b80\u79f0\u201c\u548c\u5408\u6c38\u5174\u79d1\u6280\u201d\uff09\u4e24\u540d\u80a1\u4e1c\u674e\u690d\u3001\u5510\u8f89\u7b7e\u8ba2\u80a1\u6743\u8f6c\u8ba9\u534f\u8bae\u3002\u516c\u53f8\u62df\u4ee52700\u4e07\u5143\u6536\u8d2d\u548c\u5408\u6c38\u5174\u79d1\u6280100%\u7684\u80a1\u6743\u3002<br>\u3000\u3000\u636e\u4ecb\u7ecd\uff0c\u548c\u5408\u6c38\u5174\u79d1\u6280\u662f\u81f4\u529b\u4e8e\u65e0\u7eb8\u5316\u5f69\u7968\u4e1a\u52a1\u670d\u52a1\u7684\u516c\u53f8\uff0c\u7531\u5f69\u7968\u884c\u4e1a\u5185\u5177\u6709\u4e30\u5bcc\u7ecf\u9a8c\u7684\u4eba\u5458\u7ec4\u5efa\u800c\u6210\uff0c\u516c\u53f8\u548c\u767e\u5ea6\u4e50\u548c\u5f69\u3001\u5317\u4eac\u534e\u5f69\u8d62\u901a\u3001\u767e\u5b9d\u5f69\u7b49\u516c\u53f8\u7b7e\u8ba2\u5408\u4f5c\u534f\u8bae\u5e76\u5efa\u7acb\u4e86\u6218\u7565\u5408\u4f5c\u5173\u7cfb\u3002\u516c\u53f8\u5df2\u7ecf\u83b7\u5f97\u9ed1\u9f99\u6c5f\u4f53\u5f69\u65e0\u7eb8\u5316\u5f69\u7968\u9500\u552e\u6b63\u5f0f\u6388\u6743\uff0c\u5e76\u5728\u9ed1\u9f99\u6c5f\u5efa\u7acb\u4e86\u51fa\u7968\u57fa\u5730\uff0c\u57fa\u5730\u62e5\u6709\u6253\u7968\u673a30 \u53f0\u3002\u516c\u53f8\u5c06\u57282014\u5e74\u5e95\u63a8\u51fa\u81ea\u6709\u552e\u5f69\u7f51\u7ad9\u3001\u624b\u673a\u552e\u5f69\u5ba2\u6237\u7aef\u53ca O2O \u4e1a\u52a1\u5e73\u53f0\uff0c\u968f\u7740\u516c\u53f8\u4e1a\u52a1\u5168\u9762\u94fa\u5f00\uff0c\u516c\u53f8\u4e1a\u7ee9\u5c06\u5728\u672a\u6765\u51e0\u5e74\u83b7\u5f97\u5feb\u901f\u63d0\u9ad8\u3002<br>\u3000\u3000\u8d22\u52a1\u6570\u636e\u663e\u793a\uff0c\u8f83\u53bb\u5e74\u76f8\u6bd4\uff0c\u548c\u5408\u6c38\u5174\u79d1\u6280\u4e1a\u7ee9\u4eca\u5e74\u8fdb\u5165\u6210\u957f\u671f\u3002\u622a\u6b62\u4eca\u5e747\u6708\uff0c\u6807\u7684\u516c\u53f8\u8d44\u4ea7\u603b\u989d\u4e3a1419.26\u4e07\u5143\uff0c\u51c0\u8d44\u4ea71001.16\u4e07\u5143\uff0c\u5b9e\u73b0\u8425\u653693.94\u4e07\u5143\uff0c\u51c0\u5229\u6da610.99\u4e07\u5143\uff0c\u76f8\u8f83\u53bb\u5e74\u5168\u5e74\u6570\u636e\uff0c\u6807\u7684\u516c\u53f8\u5b9e\u73b0\u4e1a\u7ee9\u589e\u957f\uff0c2013\u5e74\u6807\u7684\u8d44\u4ea7\u8d44\u4ea7\u603b\u989d\u4e3a1003.89\u4e07\u5143\uff0c\u51c0\u8d44\u4ea7990.16\u4e07\u5143\uff0c\u8425\u6536\u4e3a3\u4e07\u5143\uff0c\u5168\u5e74\u4e8f\u635f9.8\u4e07\u5143\u3002<br>\u3000\u3000\u516c\u53f8\u8868\u793a\uff0c\u56fd\u5185\u5f69\u7968\u884c\u4e1a\u5e02\u573a\u548c\u53d1\u5c55\u6f5c\u529b\u5de8\u5927\uff0c\u4e14\u56fd\u5185\u5f69\u7968\u884c\u4e1a\u5904\u4e8e\u8f6c\u6298\u53d8\u9769\u65f6\u671f\uff0c\u673a\u4f1a\u5f88\u591a\u3002\u4e3a\u57f9\u80b2\u65b0\u7684\u5229\u6da6\u589e\u957f\u70b9\uff0c\u516c\u53f8\u901a\u8fc7\u6536\u8d2d\u548c\u5408\u6c38\u5174\u8fdb\u5165\u5f69\u7968\u884c\u4e1a\uff0c\u6b64\u6b21\u6536\u8d2d\u4f5c\u4e3a\u516c\u53f8\u591a\u5143\u5316\u7ecf\u8425\u6218\u7565\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u5c06\u6709\u52a9\u4e8e\u516c\u53f8\u8fc5\u901f\u8fdb\u5165\u79fb\u52a8\u4e92\u8054\u7f51\u7b49\u5f69\u7968\u9886\u57df\uff0c\u63d0\u9ad8\u516c\u53f8\u7684\u6574\u4f53\u76c8\u5229\u80fd\u529b\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198074">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 7, 0, 0),
 'title': u'\u5fb7\u68c9\u80a1\u4efd\u6536\u8d2d\u548c\u5408\u6c38\u5174\u79d1\u6280 \u5207\u5165\u4e92\u8054\u7f51\u5f69\u7968\u4e1a\u52a1',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198074.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:12:17 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u8d75\u78a7\u541b \u5218\u6d9b\uff09 \u505c\u724c\u4e8c\u5341\u4f59\u5929\u540e\uff0c\u592a\u9633\u9e1f10\u67087\u65e5\u665a\u95f4\u516c\u544a\uff0c\u62df\u5411\u674e\u8dc3\u5148\u3001\u6df1\u5733\u524d\u6d77\u745e\u8054\u4e09\u53f7\u6295\u8d44\u4e2d\u5fc3(\u6709\u9650\u5408\u4f19)\u3001\u4e45\u94f6\u6295\u8d44\u57fa\u91d1\u7ba1\u7406(\u5317\u4eac)\u6709\u9650\u516c\u53f8\u3001\u738b\u5927\u5bcc\u548c\u8096\u4e5d\u6210\u5171\u8ba1\u4e94\u540d\u7279\u5b9a\u5bf9\u8c61\u975e\u516c\u5f00\u53d1\u884c5072.46\u4e07\u80a1\uff0c\u53d1\u884c\u4ef7\u683c\u4e3a8.28\u5143/\u80a1\uff0c\u52df\u96c6\u8d44\u91d14.2\u4ebf\u5143\uff0c\u6263\u9664\u53d1\u884c\u8d39\u7528\u540e\u62df\u7528\u4e8e\u8865\u5145\u516c\u53f8\u6d41\u52a8\u8d44\u91d1\u3002\u516c\u53f8\u80a1\u7968\u4e8e10\u67088\u65e5\u5f00\u5e02\u8d77\u590d\u724c\u3002</p><p>\u3000\u3000\u503c\u5f97\u5173\u6ce8\u7684\u662f\uff0c\u672c\u6b21\u53d1\u884c\u5bf9\u8c61\u5747\u4e3a\u770b\u597d\u516c\u53f8\u672a\u6765\u53d1\u5c55\u3001\u62e5\u6709\u7b26\u5408\u516c\u53f8\u6218\u7565\u53d1\u5c55\u9700\u6c42\u8d44\u6e90\u7684\u7684\u6218\u7565\u6295\u8d44\u4eba\u3002\u5176\u4e2d\u674e\u8dc3\u5148\u4e3a\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\uff0c\u73b0\u91d1\u51fa\u8d4420,000.00\u4e07\u5143\uff0c\u8ba4\u8d2d24,154,589\u80a1\uff0c\u6784\u6210\u5173\u8054\u4ea4\u6613\uff0c\u53d1\u884c\u5b8c\u6210\u540e\uff0c\u5408\u8ba1\u63a7\u5236\u516c\u53f8\u80a1\u4efd42%\u80a1\u6743\u7684\u674e\u8dc3\u5148\u4ecd\u4e3a\u5b9e\u9645\u63a7\u5236\u4eba\uff1b\u6d77\u5929\u76db\u7b75\u5b9e\u9645\u63a7\u5236\u4eba\u738b\u5927\u5bcc\u51fa\u8d443,000.00\u4e07\u5143\uff0c\u8ba4\u8d2d3,623,188\u80a1\uff1b\u6e56\u5357\u4e5d\u57ce\u901a\u7528\u822a\u7a7a\u6709\u9650\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u8096\u4e5d\u6210\u51fa\u8d448,000.00\u4e07\u5143\uff0c\u8ba4\u8d2d9,661,835\u80a1\uff0c\u6df1\u5733\u524d\u6d77\u745e\u8054\u4e09\u53f7\u6295\u8d44\u4e2d\u5fc3(\u6709\u9650\u5408\u4f19)\u51fa\u8d448,000.00\u4e07\u5143\uff0c\u8ba4\u8d2d9,661,835\u80a1\uff0c\u5176\u57fa\u91d1\u7ba1\u7406\u4eba\u534e\u6cf0\u745e\u8054\u57fa\u91d1\u7ba1\u7406\u6709\u9650\u516c\u53f8\uff0c\u5728\u4e0a\u5e02\u516c\u53f8\u4ea7\u4e1a\u53d1\u5c55\u548c\u5e02\u503c\u7ba1\u7406\u65b9\u9762\u8f83\u6709\u5f71\u54cd\uff1b\u4e45\u94f6\u6295\u8d44\u51fa\u8d443,000.00\u4e07\u5143\uff0c\u8ba4\u8d2d3,623,188\u80a1\uff0c\u5176\u5b9e\u9645\u63a7\u5236\u4eba\u674e\u5b89\u6c11\u5728\u8d44\u672c\u5e02\u573a\u9887\u6709\u540d\u6c14\u3002</p><p>\u3000\u3000\u4ece\u672c\u6b21\u5b9a\u589e\u7684\u5b9e\u65bd\u9884\u6848\u770b\uff0c\u9664\u4e86\u73b0\u91d1\u8865\u88404.2\u4ebf\u5916\uff0c\u8ba4\u8d2d\u65b9\u5728\u8d44\u6e90\u5339\u914d\u65b9\u9762\u4e5f\u9887\u5177\u60f3\u8c61\u7a7a\u95f4\u3002\u516c\u544a\u79f0\uff0c\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u674e\u8dc3\u5148\u4e8e9\u670829\u65e5\u5206\u522b\u4e0e\u534e\u6cf0\u745e\u8054\u57fa\u91d1\u7ba1\u7406\u6709\u9650\u516c\u53f8\u3001\u738b\u5927\u5bcc\u548c\u8096\u4e5d\u6210\u5206\u522b\u7b7e\u8ba2\u300a\u6218\u7565\u5408\u4f5c\u534f\u8bae\u300b\uff0c\u7ea6\u5b9a\u5f15\u5165\u4e09\u65b9\u4e3a\u4ea7\u4e1a\u6218\u7565\u6295\u8d44\u8005\uff0c\u4ee5\u80a1\u6743\u4e3a\u7ebd\u5e26\uff0c\u5171\u540c\u63a8\u52a8\u4e0a\u5e02\u516c\u53f8\u901a\u8fc7\u8d44\u672c\u8fd0\u4f5c\u52a0\u5f3a\u5236\u9020\u4e3b\u4e1a\u548c\u5347\u7ea7\u670d\u52a1\u4e1a\uff0c\u4e0d\u65ad\u589e\u5f3a\u76c8\u5229\u80fd\u529b\u53ca\u63d0\u5347\u516c\u53f8\u4ef7\u503c\u3002</p><p>\u3000\u3000\u636e\u6089\uff0c\u572890\u5929\u5185\uff0c\u674e\u8dc3\u5148\u8ba4\u53ef\u5e76\u534f\u8c03\u534e\u6cf0\u745e\u8054\u63a8\u8350\u7684\u4e00\u540d\u719f\u6089\u8d44\u672c\u8fd0\u4f5c\u548c\u4ea7\u4e1a\u5e76\u8d2d\u4e13\u4e1a\u4eba\u58eb\uff0c\u901a\u8fc7\u5408\u6cd5\u5408\u89c4\u7a0b\u5e8f\u62c5\u4efb\u4e0a\u5e02\u516c\u53f8\u8463\u4e8b\uff0c\u53c2\u4e0e\u4e0a\u5e02\u516c\u53f8\u91cd\u5927\u4e8b\u9879\u51b3\u7b56\uff1b\u534e\u6cf0\u745e\u8054\u63a8\u8350\u7684\u8463\u4e8b\u4eba\u9009\u5c06\u4e0e\u4e0a\u5e02\u516c\u53f8\u5bc6\u5207\u914d\u5408\uff0c\u5728\u7b26\u5408\u4e0a\u5e02\u516c\u53f8\u6218\u7565\u53d1\u5c55\u601d\u8def\u548c\u5e02\u503c\u6700\u5927\u5316\u7684\u524d\u63d0\u4e0b\uff0c\u5728\u4e0a\u5e02\u516c\u53f8\u5185\u90e8\u7275\u5934\u8d1f\u8d23\u4e0a\u5e02\u516c\u53f8\u7684\u6e38\u8247\u7efc\u5408\u670d\u52a1\u6574\u5408\u65b9\u6848\u8bbe\u8ba1\u3001\u8de8\u754c\u5e76\u8d2d\u8d44\u672c\u8fd0\u4f5c\u548c\u6574\u4f53\u4f01\u4e1a\u4ef7\u503c\u4f20\u64ad\u5de5\u4f5c\uff0c\u5145\u5206\u53d1\u6325\u5176\u4e13\u6ce8\u5e76\u8d2d\u6210\u957f\u7684\u4e13\u4e1a\u4f18\u52bf\uff0c\u4e3a\u516c\u53f8\u63d0\u4f9b\u6301\u7eed\u3001\u4f18\u8d28\u3001\u5168\u9762\u7684\u91d1\u878d\u670d\u52a1\uff0c\u63a8\u52a8\u4e0a\u5e02\u516c\u53f8\u4ea7\u4e1a\u53d1\u5c55\u548c\u5e02\u503c\u6210\u957f\u3002</p><p>\u3000\u3000\u4f5c\u4e3a\u4e09\u4e9a\u9e3f\u6d32\u56fd\u9645\u6e38\u8247\u4f1a\u3001\u9e3f\u6d32\u7687\u5bb6\u9a6c\u672f\u4ff1\u4e50\u90e8\u3001\u9e3f\u6d32\u540d\u8f66\u4f1a\u3001\u9e3f\u9152\u4f1aSense Club\u7684\u5b9e\u9645\u63a7\u5236\u4eba\uff0c\u6d77\u5929\u76db\u7b75\u56fd\u9645\u751f\u6d3b\u65b9\u5f0f\u5c55\u521b\u529e\u4eba\uff0c\u738b\u5927\u5bcc\u5c06\u9002\u65f6\u63a8\u52a8\u9e3f\u6d32\u96c6\u56e2\u65d7\u4e0b\u805a\u7126\u4e2d\u9ad8\u7aef\u6536\u5165\u4eba\u7fa4\u7684\u670d\u52a1\u4e1a\u8d44\u4ea7\u4e0e\u516c\u53f8\u63a2\u8ba8\u4ea7\u4e1a\u5bf9\u63a5\u53ca\u8d44\u672c\u8fd0\u4f5c\uff1b\u800c\u62e5\u6709\u901a\u7528\u822a\u7a7a\u5404\u7c7b\u8fd0\u8425\u8d44\u8d28\uff0c\u6b63\u7b79\u5efa\u4e5d\u57ce\u822a\u7a7a\u57fa\u5730\u7684\u6e56\u5357\u4e5d\u57ce\u901a\u7528\u822a\u7a7a\u6709\u9650\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u7684\u8096\u4e5d\u6210\u4ea6\u5c06\u63a8\u52a8\u4e5d\u57ce\u96c6\u56e2\u65d7\u4e0b\u9ad8\u7aef\u670d\u52a1\u4e1a\u8d44\u4ea7\u4e0e\u516c\u53f8\u63a2\u8ba8\u4ea7\u4e1a\u5bf9\u63a5\u53ca\u8d44\u672c\u8fd0\u4f5c\u3002</p><p>\u3000\u3000\u516c\u53f8\u8463\u79d8\u590f\u4ea6\u624d\u5411\u4e2d\u56fd\u8bc1\u5238\u7f51\u8868\u793a\uff0c\u5f15\u8fdb\u4f18\u79c0\u4ea7\u4e1a\u8d44\u6e90\uff0c\u4fc3\u8fdb\u516c\u53f8\u5b9e\u73b0\u6218\u7565\u76ee\u6807\u662f\u672c\u6b21\u975e\u516c\u5f00\u53d1\u884c\u7684\u6839\u672c\u76ee\u7684\u3002\u901a\u8fc7\u52a0\u5f3a\u516c\u53f8\u5bf9\u5916\u5408\u4f5c\u3001\u4fc3\u8fdb\u4ea7\u4e1a\u94fe\u76f8\u5173\u62d3\u5c55\uff0c\u63d0\u5347\u4f01\u4e1a\u54c1\u724c\u5b9e\u529b\uff0c\u5c06\u6709\u5229\u4e8e\u516c\u53f8\u5feb\u901f\u5b9e\u73b0\u6218\u7565\u53d1\u5c55\u76ee\u6807\u3002\u6b64\u5916\uff0c\u52df\u96c6\u8d44\u91d1\u5230\u4f4d\u540e\uff0c\u5c06\u8fdb\u4e00\u6b65\u63d0\u5347\u516c\u53f8\u7ecf\u8425\u7684\u7075\u6d3b\u6027\uff0c\u4e3a\u516c\u53f8\u5404\u9879\u7ecf\u8425\u6d3b\u52a8\u63d0\u4f9b\u8d44\u91d1\u652f\u6301\uff0c\u589e\u5f3a\u516c\u53f8\u7684\u6838\u5fc3\u7ade\u4e89\u529b\u548c\u6297\u98ce\u9669\u80fd\u529b\uff0c\u52a0\u901f\u5411\u4e0b\u6e38\u53ca\u76f8\u5173\u4ea7\u4e1a\u62d3\u5c55\uff0c\u5de9\u56fa\u516c\u53f8\u7684\u884c\u4e1a\u5730\u4f4d\uff0c\u6709\u5229\u4e8e\u516c\u53f8\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002</p><p>\u3000\u3000\u516c\u53f8\u540c\u671f\u516c\u5e03\u4e862014\u5e74\u5ea6\u524d\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u9884\u544a\uff0c\u524d\u4e09\u5b63\u5ea6\uff0c\u516c\u53f8\u9884\u8ba1\u5f52\u5c5e\u4e8e\u4e0a\u5e02\u516c\u53f8\u80a1\u4e1c\u7684\u51c0\u5229\u6da6\u6bd4\u4e0a\u5e74\u540c\u671f\u53d8\u52a8\u4e3a-30%\u81f3-50%\uff0c\u76c8\u5229\u9884\u8ba1\u4e3a2180.97\u4e07\u5143\u81f33053.35\u4e07\u5143\uff0c\u4e0a\u5e74\u540c\u671f\u8fd9\u4e00\u6570\u636e\u4e3a4361.97\u4e07\u5143\u3002\u516c\u53f8\u8868\u793a\uff0c\u516c\u53f82014\u5e74\u4e09\u5b63\u5ea6\u516c\u53f8\u7ecf\u8425\u60c5\u51b5\u7a33\u5b9a\uff0c\u4e1a\u52a1\u7ed3\u6784\u672a\u53d1\u751f\u91cd\u5927\u53d8\u5316\u3002\u975e\u7ecf\u5e38\u6027\u635f\u76ca\u5bf92014\u5e741-3\u5b63\u5ea6\u7684\u51c0\u5229\u6da6\u5f71\u54cd\u91d1\u989d\u4e3a887\u4e07\u5143\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198094">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 7, 0, 0),
 'title': u'\u592a\u9633\u9e1f\u5b9a\u589e\u8865\u88404.2\u4ebf  \u6d77\u5929\u76db\u7b75\u5b9e\u9645\u63a7\u5236\u4eba\u7b49\u8ba4\u8d2d',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198094.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:12:47 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u9648\u5fd7\u5f3a\uff09 \u505c\u724c\u8fd12\u4e2a\u6708\uff0c\u4e2d\u5174\u5546\u4e1a\u505c\u724c\u516c\u544a\u7684\u91cd\u5927\u4e8b\u9879\u6682\u65f6\u6709\u4e86\u7709\u76ee\u300210\u67087\u65e5\u665a\u95f4\uff0c\u516c\u53f8\u516c\u544a\uff0c\u516c\u53f8\u6b63\u5728\u7b79\u5212\u91cd\u5927\u4e8b\u9879\u4e3a\u8d44\u4ea7\u6ce8\u5165\u4e8b\u9879\u3002</p><p>\u3000\u3000\u4eca\u5e746\u6708\u81f38\u6708\u95f4\uff0c\u56e0\u4e3a\u5927\u5546\u7cfb\u56db\u5ea6\u4e3e\u724c\uff0c\u4e14\u6301\u80a1\u6bd4\u4f8b\u5df2\u8fbe\u523020%\uff0c\u76f4\u903c\u5927\u80a1\u4e1c33.86%\u7684\u80a1\u4efd\uff0c\u516c\u53f8\u7d27\u6025\u505c\u724c\uff0c\u5171\u540c\u5546\u8bae\u5bf9\u7b56\u3002\u516c\u53f8\u80a1\u7968\u81ea8\u670819\u65e5\u8d77\u505c\u724c\uff0c\u671f\u95f4\u516c\u53f8\u5e76\u672a\u900f\u9732\u66f4\u591a\u6d88\u606f\uff0c\u53ea\u662f\u8868\u793a\u91cd\u5927\u4e8b\u9879\u4e00\u76f4\u5728\u78cb\u5546\u8bba\u8bc1\u8fc7\u7a0b\u4e2d\u3002\u516c\u53f8\u8868\u793a\uff0c\u516c\u53f8\u80a1\u7968\u5c06\u81ea10\u67088\u65e5\u8d77\u7ee7\u7eed\u505c\u724c\u3002\u516c\u53f8\u627f\u8bfa\u4e89\u53d6\u505c\u724c\u65f6\u95f4\u4e0d\u8d85\u8fc730\u4e2a\u81ea\u7136\u65e5\uff0c\u5373\u627f\u8bfa\u4e89\u53d6\u57282014\u5e7411\u67087\u65e5\u524d\u6309\u716726\u53f7\u683c\u5f0f\u51c6\u5219\u7684\u8981\u6c42\u62ab\u9732\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4fe1\u606f\u3002\u82e5\u516c\u53f8\u672a\u80fd\u5728\u4e0a\u8ff0\u671f\u9650\u5185\u53ec\u5f00\u8463\u4e8b\u4f1a\u5ba1\u8bae\u5e76\u62ab\u9732\u76f8\u5173\u4e8b\u9879\u4e14\u516c\u53f8\u672a\u63d0\u51fa\u5ef6\u671f\u590d\u724c\u7533\u8bf7\u6216\u7533\u8bf7\u672a\u83b7\u4ea4\u6613\u6240\u540c\u610f\u7684\uff0c\u516c\u53f8\u80a1\u7968\u6700\u665a\u5c06\u4e8e2014 \u5e7411 \u67087\u65e5\u6062\u590d\u4ea4\u6613\uff0c\u516c\u53f8\u627f\u8bfa\u5728\u80a1\u7968\u6062\u590d\u4ea4\u6613\u540e3\u4e2a\u6708\u5185\u4e0d\u518d\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4e8b\u9879\u3002</p><p>\u3000\u3000\u516c\u53f8\u79f0\uff0c\u82e5\u5728\u4e0a\u8ff0\u505c\u724c\u671f\u6ee1\u524d\u5411\u4ea4\u6613\u6240\u7533\u8bf7\u5ef6\u671f\u590d\u724c\uff0c\u516c\u53f8\u627f\u8bfa\u7d2f\u8ba1\u505c\u724c\u65f6\u95f4\u4e0d\u8d85\u8fc7 3 \u4e2a\u6708\uff1b\u5728\u4e0a\u8ff0\u671f\u9650\u5185\u82e5\u516c\u53f8\u4ecd\u672a\u80fd\u53ec\u5f00\u8463\u4e8b\u4f1a\u5ba1\u8bae\u5e76\u62ab\u9732\u76f8\u5173\u4e8b\u9879\u7684\uff0c\u516c\u53f8\u5c06\u53d1\u5e03\u7ec8\u6b62\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u516c\u544a\u5e76\u80a1\u7968\u590d\u724c\uff0c\u540c\u65f6\u627f\u8bfa\u81ea\u516c\u544a\u4e4b\u65e5\u8d77\u81f3\u5c11 6 \u4e2a\u6708\u5185\u4e0d\u518d\u7b79\u5212\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u4e8b\u9879\u3002</p><p>\u3000\u3000\u516c\u5f00\u8d44\u6599\u663e\u793a\uff0c\u6c88\u9633\u5e02\u56fd\u8d44\u59d4\u662f\u4e2d\u5174\u5546\u4e1a\u7684\u5b9e\u9645\u63a7\u5236\u4eba\uff0c\u901a\u8fc7\u6c88\u9633\u4e2d\u5174\u5546\u4e1a\u96c6\u56e2\u6301\u6709\u4e2d\u5174\u5546\u4e1a33.86%\u7684\u80a1\u4efd\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198069">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 7, 0, 0),
 'title': u'\u62df\u7b79\u5212\u8d44\u4ea7\u6ce8\u5165 \u4e2d\u5174\u5546\u4e1a\u7ee7\u7eed\u505c\u724c',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198069.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:13:17 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u5915\u989c\uff09 \u91d1\u79be\u5b9e\u4e1a10\u67087\u65e5\u665a\u95f4\u53d1\u5e03\u5173\u4e8e\u5a92\u4f53\u62a5\u9053\u7684\u6f84\u6e05\u516c\u544a\uff0c\u516c\u53f8\u5df2\u5bf9\u672c\u6b21\u91cd\u5927\u4e8b\u9879\u505c\u6b62\u6d3d\u8c08\uff0c\u81f3\u4e8e\u4eca\u540e\u662f\u5426\u6709\u7ee7\u7eed\u5408\u4f5c\u5c1a\u5b58\u5728\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u516c\u53f8\u80a1\u7968\u5c06\u4e8e2014\u5e7410\u67088\u65e5\u5f00\u5e02\u8d77\u590d\u724c\u3002<br>\u3000\u30009\u670830\u65e5\uff0c\u6709\u5173\u5a92\u4f53\u4ee5\u201c\u91d1\u79be\u5b9e\u4e1a\u5e76\u8d2d\u88ab\u8feb\u6401\u6d45\u201d\u4e3a\u9898\u62a5\u9053\u524d\u671f\u516c\u53f8\u7b79\u5212\u91cd\u5927\u4e8b\u9879\u76f8\u5173\u4e8b\u5b9c\uff0c\u6587\u4e2d\u8d28\u7591\uff1a\u4ee5\u6709\u5173\u7f51\u53cb\u5728\u4e1c\u65b9\u8d22\u5bcc\u7f51\u80a1\u5427\u7684\u53d1\u8d34\u4e3a\u4f9d\u636e\uff0c\u8bf4\u201c\u6709\u6295\u8d44\u8005\u8d28\u7591\u516c\u53f8\u590d\u724c\u7684\u65f6\u95f4\u4ee5\u53ca\u516c\u544a\u7684\u5185\u5bb9\u53ef\u80fd\u88ab\u63d0\u524d\u6cc4\u9732\u201d\uff1b\u516c\u53f8\u5de5\u4f5c\u4eba\u5458\u56de\u7b54\u6295\u8d44\u8005\u63d0\u95ee\u65f6\u8bf4\u201c\u88ab\u516c\u53f8\u7ec8\u6b62\u7684\u91cd\u5927\u4e8b\u9879\u8fd8\u5b58\u5728\u968f\u65f6\u6062\u590d\u7684\u53ef\u80fd\u3002\u201d\u4e0a\u8ff0\u5de5\u4f5c\u4eba\u5458\u8bf4\uff0c\u201c\u4e3b\u8981\u662f\u56e0\u4e3a\u6df1\u4ea4\u6240\u7ed9\u7684\u65f6\u95f4\u592a\u77ed\u4e86\uff0c\u4e0d\u5f97\u4e0d\u6682\u65f6\u590d\u724c\u3002\u7b49\u6536\u8d2d\u5bf9\u8c61\u5185\u90e8\u7684\u5173\u7cfb\u5904\u7406\u597d\uff0c\u8fd8\u53ef\u4ee5\u7ee7\u7eed\u64cd\u4f5c\u201d\u3002\u201c \u4e0d\u6392\u9664\u516c\u53f8\u6709\u518d\u6b21\u4e34\u65f6\u505c\u724c\u7684\u53ef\u80fd\u201d\u3002<br>\u3000\u3000\u516c\u53f8\u9488\u5bf9\u4e0a\u8ff0\u62a5\u9053\u4e8b\u9879\u6f84\u6e05\u8bf4\uff1a\u516c\u53f8\u6309\u7167\u6df1\u4ea4\u6240\u4fe1\u606f\u62ab\u9732\u76f8\u5173\u89c4\u5219\u53ca\u65f6\u62ab\u9732\u76f8\u5173\u4fe1\u606f\uff0c\u4e0d\u5b58\u5728\u63d0\u524d\u6cc4\u9732\u76f8\u5173\u4fe1\u606f\u7684\u60c5\u51b5\uff1b\u56e0\u5de5\u4f5c\u4eba\u5458\u5bf9\u6df1\u4ea4\u6240\u5173\u4e8e\u91cd\u5927\u4e8b\u9879\u505c\u590d\u724c\u89c4\u5219\u7406\u89e3\u6709\u8bef\uff0c\u56de\u7b54\u4e0d\u591f\u4e25\u8c28\uff0c\u7531\u6b64\u5bf9\u6295\u8d44\u8005\u9020\u6210\u7684\u8bef\u89e3\u8868\u793a\u8bda\u631a\u7684\u6b49\u610f\uff1b\u516c\u53f8\u5df2\u5bf9\u672c\u6b21\u91cd\u5927\u4e8b\u9879\u505c\u6b62\u6d3d\u8c08\uff0c\u81f3\u4e8e\u4eca\u540e\u662f\u5426\u6709\u7ee7\u7eed\u5408\u4f5c\u5c1a\u5b58\u5728\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8bf7\u6295\u8d44\u8005\u4ee5\u516c\u53f8\u516c\u544a\u4e3a\u51c6\u3002<br>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u516c\u544a\u5728\u89e3\u8bfb\u516c\u53f8\u53d1\u5e03\u7ec8\u6b62\u91cd\u5927\u4e8b\u9879\u65f6\uff0c\u66fe\u7279\u522b\u63d0\u5230\u201c\u516c\u53f8\u5728\u516c\u544a\u4e2d\u5e76\u672a\u63d0\u53ca3\u4e2a\u6708\u5185\u4e0d\u518d\u7b79\u5212\u91cd\u5927\u4e8b\u9879\u3002\u201d\u8fd9\u4e5f\u662f\u5a92\u4f53\u62a5\u9053\u7684\u89c2\u70b9\u4e4b\u4e00\uff0c\u516c\u53f8\u5728\u672c\u6b21\u6f84\u6e05\u516c\u544a\u4e2d\u672a\u5c313\u4e2a\u6708\u7684\u627f\u8bfa\u65f6\u95f4\u7ed9\u4e88\u6b63\u9762\u56de\u5e94\uff0c\u800c\u662f\u79f0\u201c\u81f3\u4e8e\u4eca\u540e\u662f\u5426\u6709\u7ee7\u7eed\u5408\u4f5c\u5c1a\u5b58\u5728\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u201d\u3002\u4e1a\u5185\u4eba\u58eb\u79f0\uff0c\u6b64\u4e3e\u503c\u5f97\u6295\u8d44\u8005\u5173\u6ce8\u3002\u6b64\u5916\uff0c\u516c\u53f8\u4e00\u76f4\u79f0\u4e4b\u4e3a\u201c\u91cd\u5927\u4e8b\u9879\u201d\u800c\u975e\u201c\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u201d\uff0c\u6216\u610f\u5473\u7740\u6b64\u4e8b\u4ef6\u8fbe\u4e0d\u5230\u91cd\u5927\u8d44\u4ea7\u91cd\u7ec4\u7684\u6807\u51c6\uff0c\u4f46\u5bf9\u516c\u53f8\u751f\u4ea7\u7ecf\u8425\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\u3002<br>\xa0</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198075">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 7, 0, 0),
 'title': u'\u91d1\u79be\u5b9e\u4e1a\uff1a\u91cd\u5927\u4e8b\u9879\u662f\u5426\u6709\u7ee7\u7eed\u5408\u4f5c\u5b58\u5728\u5f88\u5927\u4e0d\u786e\u5b9a\u6027',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198075.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:13:47 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'><font face="Times New Roman">\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08</font>\u8bb0\u8005</span> <span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u9ad8\u4e00\uff09</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u636e\u4e2d\u56fd\u5730\u9707\u53f0\u7f51\u4e2d\u5fc3\u7f51\u7ad9\u6700\u65b0\u6d88\u606f\uff0c\u5317\u4eac\u65f6\u95f4</span><chsdate year="2014" month="10" day="7" islunardate="False" isrocdate="False" w:st="on"><span lang="EN-US">10</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u6708</span><span lang="EN-US">7</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u65e5</span><span lang="EN-US">21</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u65f6</span><span lang="EN-US">49</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u5206</span></chsdate><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\uff0c\u4e91\u5357\u7701\u666e\u6d31\u5e02\u666f\u8c37\u50a3\u65cf\u5f5d\u65cf\u81ea\u6cbb\u53bf\u53d1\u751f</span><span lang="EN-US">6.6</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u7ea7\u5730\u9707\uff0c\u9707\u4e2d\u4f4d\u4e8e\u5317\u7eac</span><span lang="EN-US">23.4</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u5ea6\u3001\u4e1c\u7ecf</span><span lang="EN-US">100.5</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u5ea6\uff0c\u9707\u6e90\u6df1\u5ea6</span><chmetcnv w:st="on" unitname="\u516c\u91cc" sourcevalue="5" hasspace="False" negative="False" numbertype="1" tcsc="0"><span lang="EN-US">5.0</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u516c\u91cc</span></chmetcnv><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u3002</span></p><p class="MsoNormal"><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u3000\u3000\u636e\u4e86\u89e3\uff0c\u6b64\u6b21\u5730\u9707\u5fae\u89c2\u9707\u4e2d\u4f4d\u4e8e\u666f\u8c37\u53bf\u5883\u5185\u6c38\u5e73\u9547\u9644\u8fd1\uff0c\u8ddd\u79bb\u666f\u8c37\u6797\u4e1a\uff08</span><span lang="EN-US">600265</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\uff09\u6240\u5728\u5730\u666f\u8c37\u53bf\u5a01\u8fdc\u9547</span><chmetcnv w:st="on" unitname="\u516c\u91cc" sourcevalue="60" hasspace="False" negative="False" numbertype="1" tcsc="0"><span lang="EN-US">60</span><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u516c\u91cc</span></chmetcnv><span style=\'font-family: \u5b8b\u4f53; mso-ascii-font-family: "Times New Roman"; mso-hansi-font-family: "Times New Roman"\'>\u5de6\u53f3\uff0c\u76ee\u524d\u6682\u65e0\u76f8\u5173\u635f\u5931\u62a5\u544a\u3002</span></p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198501">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u4e91\u5357\u666e\u6d31\u53d1\u751f6.6\u7ea7\u5730\u9707 \u666f\u8c37\u6797\u4e1a\u8ddd\u9707\u4e2d60\u516c\u91cc',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198501.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:14:18 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u5f6d\u8d85\uff09\u8d5b\u4e3a\u667a\u80fd10\u67087\u65e5\u665a\u95f4\u53d1\u5e03\u516c\u544a\uff0c2014\u5e747\u67081\u65e5-9\u670830\u65e5\uff0c\u516c\u53f8\u65b0\u7b7e\u5408\u540c\u91d1\u989d\u7d2f\u8ba18300.85\u4e07\u5143\uff0c\u5df2\u4e2d\u6807\u4f46\u5c1a\u672a\u7b7e\u8ba2\u5408\u540c\u7684\u9879\u76ee\u91d1\u989d\u7d2f\u8ba13185.41\u4e07\u5143\uff0c\u5747\u96c6\u4e2d\u5728\u5efa\u7b51\u667a\u80fd\u5316\u9886\u57df\u3002<br>\u3000\u3000\u5176\u4e2d\uff0c\u516c\u53f8\u65b0\u7b7e\u5408\u540c\u91d1\u989d\u7d2f\u8ba18300.85\u4e07\u5143\uff0c\u5df2\u4e2d\u6807\u4f46\u5c1a\u672a\u7b7e\u8ba2\u5408\u540c\u7684\u9879\u76ee\u91d1\u989d\u7d2f\u8ba13185.41\u4e07\u5143\uff0c\u4e24\u8005\u5408\u8ba1\u8fc7\u4ebf\uff0c\u5747\u96c6\u4e2d\u5728\u5efa\u7b51\u667a\u80fd\u5316\u9886\u57df\uff0c\u8fd9\u4e5f\u662f\u516c\u53f8\u9664\u4e86\u8f68\u9053\u4ea4\u901a\u4e4b\u5916\u7684\u53e6\u4e00\u4e2a\u91cd\u70b9\u4e1a\u52a1\u9886\u57df\u3002<br>\u3000\u3000\u8d5b\u4e3a\u667a\u80fd\u8868\u793a\uff0c\u65b0\u7b7e\u5408\u540c\u9879\u76ee\u5bf9\u516c\u53f8\u672c\u5e74\u5ea6\u7ecf\u8425\u4e1a\u7ee9\u4f1a\u6709\u4e00\u5b9a\u7684\u63d0\u5347\u4f5c\u7528\uff1b\u800c\u5df2\u4e2d\u6807\u9879\u76ee\u5c1a\u672a\u4e0e\u4e1a\u4e3b\u65b9\u7b7e\u8ba2\u5408\u540c\uff0c\u5b58\u5728\u4e0d\u786e\u5b9a\u56e0\u7d20\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198999">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u8d5b\u4e3a\u667a\u80fd\u5efa\u7b51\u9886\u57df\u53d1\u529b \u524d\u4e09\u5b63\u8ba2\u5355\u8fc7\u4ebf',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198999.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:14:48 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u6731\u5148\u59ae\uff09 \u6c89\u5bc2\u4e00\u6bb5\u65f6\u95f4\u540e\uff0c\u751f\u547d\u4eba\u5bff\u518d\u5ea6\u589e\u6301\u519c\u4ea7\u54c1\uff0c\u76ee\u524d\u5176\u6301\u6709\u519c\u4ea7\u54c1\u80a1\u4efd\u6bd4\u4f8b\u5df2\u8fbe25.016%\u3002</p><p>\u3000\u30007\u65e5\uff0c\u519c\u4ea7\u54c1\u62ab\u9732\u80a1\u4efd\u8be6\u5f0f\u6743\u76ca\u62a5\u544a\u4e66\u663e\u793a\uff0c\u751f\u547d\u4eba\u5bff\u81ea4\u670810\u65e5\u81f39\u670830\u65e5\uff0c\u901a\u8fc7\u4e8c\u7ea7\u5e02\u573a\u8d2d\u5165\u516c\u53f8\u80a1\u4efd8511.62\u4e07\u80a1\uff0c\u8017\u8d449.02\u4ebf\u5143\u3002\u8fd9\u76f8\u5f53\u4e8e\u519c\u4ea7\u54c15.01%\u7684\u80a1\u4efd\uff0c\u52a0\u4e0a\u6b64\u524d\u5176\u6301\u6709\u7684\u4efd\u989d\uff0c\u622a\u81f3\u4e09\u5b63\u672b\uff0c\u751f\u547d\u4eba\u5bff\u6301\u6709\u519c\u4ea7\u54c1\u80a1\u4efd\u6bd4\u4f8b\u8fbe\u523025.016%\uff0c\u4e0e\u519c\u4ea7\u54c1\u63a7\u80a1\u80a1\u4e1c\u6df1\u5733\u5e02\u56fd\u8d44\u59d4\u4e4b\u95f4\u7684\u5dee\u8ddd\u8fdb\u4e00\u6b65\u7f29\u5c0f\u3002</p><p>\u3000\u30004\u670818\u65e5\uff0c\u751f\u547d\u4eba\u5bff\u7b2c\u56db\u5c4a\u8463\u4e8b\u4f1a\u6267\u884c\u59d4\u5458\u4f1a\u7b2c\u5341\u6b21\u4f1a\u8bae\u901a\u8fc7\u51b3\u8bae\uff0c\u540c\u610f\u516c\u53f8\u901a\u8fc7\u4e8c\u7ea7\u5e02\u573a\u7ee7\u7eed\u589e\u6301\u519c\u4ea7\u54c1\u80a1\u4efd\uff0c\u6301\u80a1\u6bd4\u4f8b\u4e0d\u8d85\u8fc7\u8be5\u4e0a\u5e02\u516c\u53f8\u603b\u80a1\u672c\u768430%\u3002\u800c\u519c\u4ea7\u54c1\u63a7\u80a1\u80a1\u4e1c\u6df1\u5733\u5e02\u56fd\u8d44\u59d4\u5219\u56de\u5e94\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7a33\u56fa\u5e02\u5c5e\u56fd\u6709\u63a7\u80a1\u6743\uff0c\u7d2f\u8ba1\u589e\u6301\u516c\u53f8\u80a1\u4efd1133.28\u4e07\u80a1\uff0c\u8fde\u540c\u5176\u4e00\u81f4\u884c\u52a8\u4eba\u6df1\u5733\u5e02\u8fdc\u81f4\u6295\u8d44\u6709\u9650\u516c\u53f8(\u7b80\u79f0\u8fdc\u81f4\u6295\u8d44)\u3001\u8fdc\u81f4\u6295\u8d44\u7684\u5168\u8d44\u5b50\u516c\u53f8\u6df1\u5733\u5e02\u4ebf\u946b\u6295\u8d44\u6709\u9650\u516c\u53f8\uff0c\u5408\u8ba1\u6301\u6709\u519c\u4ea7\u54c15.09\u4ebf\u80a1\uff0c\u5360\u603b\u80a1\u672c29.9999%\uff0c\u8ddd\u79bb30%\u7684\u8981\u7ea6\u6536\u8d2d\u7ea2\u7ebf\u4ec5\u4e00\u7ebf\u4e4b\u9694\u3002</p><p>\u3000\u3000\u4e1a\u5185\u4eba\u58eb\u5206\u6790\uff0c\u4ece\u751f\u547d\u4eba\u5bff\u4e3e\u724c\u7684\u666e\u904d\u6295\u8d44\u903b\u8f91\u6765\u770b\uff0c\u4e0d\u6392\u9664\u6b64\u4e3e\u610f\u5728\u8d22\u52a1\u6295\u8d44\u8005\u3002\u5305\u62ec\u519c\u4ea7\u54c1\u5728\u5185\uff0c\u751f\u547d\u4eba\u5bff\u6295\u8d44\u7684\u4e0a\u5e02\u516c\u53f8\u5747\u4e3a\u57fa\u672c\u9762\u8f83\u597d\u7684\u4f18\u8d28\u84dd\u7b79\u80a1\uff0c\u4e14\u76ee\u524d\u80a1\u4ef7\u5b58\u5728\u4f4e\u4f30\uff0c\u672a\u6765\u7684\u8d22\u52a1\u6536\u76ca\u53ef\u671f\u3002\u53e6\u5916\uff0c\u8fd9\u4e9b\u516c\u53f8\u5747\u5c5e\u56fd\u5bb6\u653f\u7b56\u652f\u6301\u7684\u884c\u4e1a\uff0c\u5951\u5408\u4ea7\u4e1a\u6d88\u8d39\u5347\u7ea7\u53d1\u5c55\u8d8b\u52bf\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198093">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 7, 0, 0),
 'title': u'\u751f\u547d\u4eba\u5bff\u518d\u5ea6\u4e3e\u724c\u519c\u4ea7\u54c1 \u6301\u80a1\u6bd4\u4f8b\u903e25%',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198093.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:15:18 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u674e\u7433\uff09 \u4e2d\u8d85\u7535\u7f0610\u67087\u65e5\u665a\u95f4\u516c\u544a\uff0c\u63a7\u80a1\u80a1\u4e1c\u4e2d\u8d85\u96c6\u56e2\u81ea8\u67088\u65e5\u8d77\u7d2f\u8ba1\u51cf\u6301\u516c\u53f8\u80a1\u4efd23.64%\uff0c\u76ee\u524d\u6301\u80a1\u6bd4\u4f8b\u4e3a37.08%\uff0c\u4ecd\u4e3a\u516c\u53f8\u63a7\u80a1\u80a1\u4e1c\u3002</p><p>\u3000\u3000\u516c\u53f8\u6b64\u524d8\u67084\u65e5\u516c\u544a\uff0c\u63a7\u80a1\u80a1\u4e1c\u4e2d\u8d85\u96c6\u56e2\u4e3a\u4e86\u5f52\u8fd8\u94f6\u884c\u501f\u6b3e\u53ca\u8865\u5145\u8fd0\u8425\u8d44\u91d1\uff0c\u540c\u65f6\u4f18\u5316\u516c\u53f8\u80a1\u4e1c\u7ed3\u6784\uff0c\u589e\u52a0\u4e8c\u7ea7\u5e02\u573a\u80a1\u7968\u7684\u6d41\u52a8\u6027\uff0c\u4f7f\u80a1\u7968\u4ef7\u683c\u80fd\u66f4\u597d\u5730\u4f53\u73b0\u516c\u53f8\u4ef7\u503c\uff0c\u62df\u81ea8\u67087\u65e5\u8d77\u7684\u672a\u6765\u516d\u4e2a\u6708\u5185\u51cf\u6301\u8d85\u8fc75%\u7684\u516c\u53f8\u80a1\u4efd\u3002</p><p>\u3000\u3000\u6b64\u524d\uff0c\u4e2d\u8d85\u96c6\u56e2\u6301\u6709\u516c\u53f8\u80a1\u4efd308,093,612\u80a1\uff0c\u5360\u516c\u53f8\u603b\u80a1\u672c\u768460.74%\u3002\u81ea\u4eca\u5e748\u67088\u65e5\u4ee5\u6765\uff0c\u4e2d\u8d85\u96c6\u56e2\u901a\u8fc7\u6df1\u4ea4\u6240\u5927\u5b97\u4ea4\u6613\u7cfb\u7edf\u7d2f\u8ba1\u51cf\u6301\u516c\u53f8\u80a1\u4efd\u5360\u603b\u80a1\u672c\u6bd4\u4f8b\u4e3a23.64%\uff1b\u622a\u6b629\u670830\u65e5\uff0c\u4e2d\u8d85\u96c6\u56e2\u8fd8\u6301\u6709\u516c\u53f8\u80a1\u4efd188,093,612\u80a1\uff0c\u5360\u516c\u53f8\u603b\u80a1\u672c\u768437.08%\uff0c\u5176\u4e2d\u65e0\u9650\u552e\u80a1\u4efd\u4e3a164,693,612\u80a1\uff0c\u5360\u516c\u53f8\u603b\u80a1\u672c32.47%\uff0c\u6709\u9650\u552e\u80a1\u4efd\u4e3a2,340\u4e07\u80a1\uff0c\u5360\u516c\u53f8\u603b\u80a1\u672c4.61%\uff0c\u4ecd\u4e3a\u516c\u53f8\u63a7\u80a1\u80a1\u4e1c\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3198086">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u4e2d\u8d85\u7535\u7f06\u63a7\u80a1\u80a1\u4e1c\u8fde\u7eed\u51cf\u6301 \u6301\u80a1\u6bd4\u4f8b\u964d\u4e3a37.08%',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3198086.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:15:18 [scrapy] INFO: Crawled 6414 pages (at 0 pages/min), scraped 6145 items (at 0 items/min)
2016-11-23 15:15:49 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u9ad8\u6587\u529b \u9648\u5fd7\u5f3a\uff09 \u7ecf\u8fc7\u77ed\u6682\u7684\u505c\u724c\uff0c10\u67088\u65e5\u665a\u95f4\uff0c\u6613\u4e16\u8fbe\u53d1\u5e03\u516c\u544a\uff0c\u516c\u53f8\u62df\u4f7f\u7528\u8d85\u52df\u8d44\u91d1\u53ca\u5229\u606f2.38\u4ebf\u6536\u8d2d\u795e\u5149\u65b0\u80fd\u6e90\u6709\u9650\u516c\u53f8\u6240\u6301\u7684\u683c\u5c14\u6728\u795e\u5149\u65b0\u80fd\u6e90\u6709\u9650\u516c\u53f8\u7684100%\u80a1\u6743\u3002 <br>\u3000\u3000\u8d44\u6599\u663e\u793a\uff0c\u683c\u5c14\u6728\u795e\u5149\u6210\u7acb\u4e8e2012\u5e7410\u6708\uff0c\u7ecf\u8425\u8303\u56f4\u4e3a\u592a\u9633\u80fd\u5149\u4f0f\u53d1\u7535\uff1b\u80fd\u6e90\u8bbe\u5907\u7684\u9500\u552e\u3001\u7ef4\u62a4\u7b49\uff0c\u622a\u81f32014\u5e746\u670830\u65e5\uff0c\u683c\u5c14\u6728\u795e\u5149\u603b\u8d44\u4ea7\u4e3a6.94\u4ebf\u5143\uff0c\u51c0\u8d44\u4ea7\u4e3a1.74\u4ebf\u5143\uff0c\u51762013\u5e74\u5ea6\u5b9e\u73b0\u8425\u4e1a\u6536\u51652185.19\u4e07\u5143\uff0c\u51c0\u5229\u6da6\u4e3a-1143.19\u4e07\u5143\u3002<br>\u3000\u3000\u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u5728\u8f6c\u8ba9\u534f\u8bae\u4e2d\uff0c\u8f6c\u8ba9\u65b9\u627f\u8bfa\uff0c\u76ee\u6807\u516c\u53f82015\u5e74\u5ea6\u30012016\u5e74\u5ea6\u7ecf\u5ba1\u8ba1\u51c0\u5229\u6da6\u5206\u522b\u4e0d\u4f4e\u4e8e2825\u4e07\u548c3080\u4e07\u3002\u5426\u5219\u5356\u65b9\u627f\u8bfa\u6309\u5b9e\u9645\u51c0\u5229\u6da6\u4e0e\u76ee\u6807\u51c0\u5229\u6da6\u4e4b\u5dee\u989d\u4ee5\u8d27\u5e01\u8d44\u91d1\u5411\u76ee\u6807\u516c\u53f8\u8fdb\u884c\u8865\u507f\u3002<br>\u3000\u3000\u6b64\u5916\uff0c\u4e3a\u4fdd\u8bc1\u4e0a\u8ff0\u627f\u8bfa\u7684\u5c65\u884c\uff0c\u5356\u65b9\u81ea\u6536\u5230\u7b2c\u4e00\u7b14\u80a1\u6743\u8f6c\u8ba9\u6b3e\u540e\uff0c\u5728\u4e09\u4e2a\u6708\u5185\u4f7f\u7528\u4e0d\u4f4e\u4e8e4000\u4e07\u5728\u4e8c\u7ea7\u5e02\u573a\u4e0a\u8d2d\u4e70\u6613\u4e16\u8fbe\u80a1\u7968\uff0c\u5728\u8d2d\u4e70\u5b8c\u6210\u540e\u627f\u8bfa\u9501\u5b9a2\u5e74\u5e76\u7531\u6613\u4e16\u8fbe\u5bf9\u5916\u516c\u544a\uff0c\u82e5\u5728\u4e1a\u7ee9\u627f\u8bfa\u671f\u5185\uff0c\u5356\u65b9\u4e0d\u5c65\u884c\u6216\u65e0\u529b\u5c65\u884c\u8d27\u5e01\u8d44\u91d1\u8865\u507f\u4e4b\u8d23\u4efb\uff0c\u5219\u4e0a\u8ff0\u80a1\u6743\u7684\u5904\u7f6e\u6743\u53ca\u6536\u76ca\u6743\u5f52\u6613\u4e16\u8fbe\u6240\u6709\uff0c\u7528\u4e8e\u8865\u507f\u4e0a\u8ff0\u51c0\u5229\u6da6\u76ee\u6807\u91d1\u989d\u3002<br>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8bb0\u8005\u4e86\u89e3\u5230\uff0c\u6613\u4e16\u8fbe\u4e3b\u8425\u4e1a\u52a1\u4e3a\u6c34\u6ce5\u3001\u94a2\u94c1\u7b49\u9ad8\u8017\u80fd\u884c\u4e1a\u7684\u4f59\u70ed\u4f59\u538b\u53d1\u7535\u7cfb\u7edf\u7684\u6280\u672f\u670d\u52a1\u3001\u5de5\u7a0b\u8bbe\u8ba1\u3001\u8bbe\u5907\u6210\u5957\u53ca\u5de5\u7a0b\u603b\u627f\u5305\u4e1a\u52a1\uff0c\u4ee5\u53ca\u7531\u4e0a\u8ff0\u4e1a\u52a1\u884d\u751f\u51fa\u7684\u5408\u540c\u80fd\u6e90\u7ba1\u7406\u7b49\u65b0\u578b\u4e1a\u52a1\u6a21\u5f0f\u3002<br>\u3000\u3000\u8fd1\u5e74\u6765\uff0c\u7531\u4e8e\u53d7\u5230\u5173\u8054\u884c\u4e1a\u4e0d\u666f\u6c14\u7b49\u8bf8\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u516c\u53f8\u4e3b\u8425\u4e1a\u52a1\u4f59\u70ed\u53d1\u7535\u53d7\u5230\u5f71\u54cd\u8f83\u5927\uff0c\u4e3a\u6b64\uff0c\u4ece2012\u5e74\u5f00\u59cb\uff0c\u516c\u53f8\u5236\u5b9a\u4e86\u201c\u7d27\u7d27\u56f4\u7ed5\u8282\u80fd\u3001\u6e05\u6d01\u80fd\u6e90\u53ca\u65b0\u80fd\u6e90\u9886\u57df\u8fdb\u884c\u4e1a\u52a1\u62d3\u5c55\u201d\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u6b64\u6b21\u6d89\u8db3\u5149\u4f0f\u53d1\u7535\uff0c\u4e5f\u662f\u7ee7\u516c\u53f8\u6d89\u8db3\u5929\u7136\u6c14\u4e4b\u540e\u7684\u53c8\u4e00\u6b21\u6709\u9488\u5bf9\u6027\u7684\u63a2\u7d22\u3002<br>\u3000\u3000\u516c\u53f8\u79f0\uff0c\u516c\u53f8\u4e00\u76f4\u81f4\u529b\u4e8e\u8282\u80fd\u3001\u6e05\u6d01\u80fd\u6e90\u53ca\u65b0\u80fd\u6e90\u9886\u57df\u7684\u63a8\u5e7f\u53ca\u5e94\u7528\u5de5\u4f5c\uff0c\u4e14\u5728\u7535\u7ad9\u8fd0\u8425\u65b9\u9762\u5177\u5907\u4e00\u5b9a\u7684\u4e13\u4e1a\u4eba\u5458\uff0c\u901a\u8fc7\u6b64\u6b21\u5e76\u8d2d\u53ef\u5b9e\u73b0\u4f18\u52bf\u4e92\u8865\uff0c\u6709\u5229\u4e8e\u589e\u5f3a\u4e0a\u5e02\u516c\u53f8\u7684\u76c8\u5229\u80fd\u529b\uff1b\u6709\u5229\u4e8e\u6613\u4e16\u8fbe\u628a\u63e1\u6e05\u6d01\u80fd\u6e90\u7684\u53d1\u5c55\u5951\u673a\uff0c\u62d3\u5c55\u65b0\u7684\u4e1a\u52a1\u53d1\u5c55\u9886\u57df\uff0c\u5bf9\u51b2\u7ecf\u6d4e\u5468\u671f\u548c\u5b8f\u89c2\u653f\u7b56\u5bf9\u516c\u53f8\u4f59\u70ed\u53d1\u7535\u4e1a\u52a1\u7684\u5f71\u54cd\uff0c\u6811\u7acb\u8d44\u672c\u5e02\u573a\u7684\u826f\u597d\u5f62\u8c61\uff1b\u6b64\u5916\uff0c\u6709\u52a9\u4e8e\u4e0a\u5e02\u516c\u53f8\u83b7\u5f97\u7a33\u5b9a\u7684\u73b0\u91d1\u6d41\uff1b\u8be5\u9879\u76ee\u5df2\u57fa\u672c\u5b9e\u73b0\u7a33\u5b9a\u8fd0\u884c\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u4e0a\u5e02\u516c\u53f8\u4e1a\u7ee9\u3002<br>\u3000\u3000\u516c\u53f8\u80a1\u7968\u5c06\u4e8e10\u67089\u65e5\u5f00\u59cb\u8d77\u590d\u724c\u3002\u622a\u6b62\u4e0a\u4e00\u4e2a\u4ea4\u6613\u65e5\uff0c\u516c\u53f8\u80a1\u4ef7\u62a5\u6536\u4e8e22.89\u5143\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3199631">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u5ef6\u4f38\u65b0\u80fd\u6e90\u4ea7\u4e1a\u94fe \u6613\u4e16\u8fbe\u62df2.38\u4ebf\u6536\u8d2d\u683c\u5c14\u6728\u5149\u4f0f\u9879\u76ee',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3199631.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:15:49 [scrapy] INFO: Crawled 6429 pages (at 15 pages/min), scraped 6145 items (at 0 items/min)
2016-11-23 15:16:19 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u8d75\u78a7\u541b \u5218\u6d9b\uff09 \u9686\u5e73\u9ad8\u79d19\u65e5\u665a\u95f4\u53d1\u5e03\u524d\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u9884\u589e\u516c\u544a\uff0c\u5f52\u5c5e\u4e8e\u4e0a\u5e02\u516c\u53f8\u80a1\u4e1c\u51c0\u5229\u6da6\u6bd4\u4e0a\u5e74\u540c\u671f\u589e\u957f80%\u81f3130%\uff0c\u516c\u53f8\u76c8\u522910,392.25\u4e07\u5143\u81f313,278.98 \u4e07\u5143\uff0c\u53bb\u5e74\u540c\u671f\u76c8\u5229\u4e3a5,773.47\u4e07\u5143\u3002</p><p>\u3000\u3000\u4e0a\u534a\u5e74\uff0c\u516c\u53f8\u5b9e\u73b0\u5f52\u5c5e\u4e8e\u4e0a\u5e02\u516c\u53f8\u80a1\u4e1c\u7684\u51c0\u5229\u6da61320.09\u4e07\u5143\uff0c\u8f83\u4e0a\u5e74\u540c\u671f\u589e\u957f 25.49%\uff1b\u663e\u7136\uff0c\u7b2c\u4e09\u5b63\u5ea6\u516c\u53f8\u4e1a\u7ee9\u51fa\u73b0\u663e\u8457\u63d0\u901f\u3002</p><p>\u3000\u3000\u503c\u5f97\u5173\u6ce8\u7684\u662f\uff0c\u516c\u53f8\u524d\u4e09\u5b63\u5ea6\u5229\u6da6\u4e2d\u67095,436.18\u4e07\u5143\uff08\u7a0e\u540e\uff09\u4e3a\u516c\u53f8\u8f6c\u8ba9\u65b0\u7586\u94f6\u9686\u519c\u4e1a\u56fd\u9645\u5408\u4f5c\u80a1\u4efd\u6709\u9650\u516c\u53f8\u6216\u6709\u6743\u76ca\u6240\u5f97\uff0c\u82e5\u6263\u9664\u8fd9\u90e8\u5206\u6536\u76ca\uff0c\u516c\u53f8\u524d\u4e09\u5b63\u5ea6\u76c8\u52294956.07\u4e07\u5143\u81f37842.8 \u4e07\u5143\uff0c\u6bd4\u53bb\u5e74\u540c\u671f\u5b9e\u9645\u589e\u957f-14.15%\u81f335.84%\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3201252">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 9, 0, 0),
 'title': u'\u9686\u5e73\u9ad8\u79d1\u524d\u4e09\u5b63\u5ea6\u5229\u6da6\u540c\u6bd4\u589e\u957f 80%\u81f3 130%',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3201252.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:16:50 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u738b\u5c79\uff09 \u957f\u5b89\u6c7d\u8f6610\u67088\u65e5\u665a\u95f4\u516c\u5e03\u4e869\u6708\u4efd\u4ea7\u9500\u5feb\u62a5\uff0c\u5f53\u6708\u516c\u53f8\u4ea7\u9500\u6c7d\u8f66\u5206\u522b\u4e3a22.4653\u4e07\u8f86\u548c22.6681\u4e07\u8f86\uff0c\u540c\u6bd4\u5206\u522b\u589e\u957f20.12%\u548c13.07%\uff0c\u867d\u7136\u4ea7\u91cf\u8f838\u6708\u6709\u660e\u663e\u589e\u957f\uff0c\u4f46\u9500\u91cf\u589e\u901f\u5374\u8f838\u6708\u7ee7\u7eed\u56de\u843d\uff0c\u663e\u793a\u76ee\u524d\u201c\u53bb\u5e93\u5b58\u201d\u538b\u529b\u72b9\u5b58\u3002</p><p>\u3000\u3000\u4eca\u5e74\u524d\u4e09\u5b63\u5ea6\uff0c\u957f\u5b89\u6c7d\u8f66\u7d2f\u8ba1\u6c7d\u8f66\u4ea7\u9500\u91cf\u5206\u522b\u4e3a190.7050\u4e07\u8f86\u548c190.2358\u4e07\u8f86\uff0c\u540c\u6bd4\u5206\u522b\u589e\u957f25.08%\u548c24.15%\uff0c\u603b\u4f53\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u589e\u957f\u901f\u5ea6\u3002</p><p>\u3000\u3000\u5206\u677f\u5757\u770b\uff0c9\u6708\u4efd\u957f\u5b89\u6c7d\u8f66\u672c\u90e8\u9500\u91cf\u8fbe7.7301\u4e07\u8f86\uff0c\u540c\u6bd4\u589e\u957f27.51%\uff0c\u589e\u901f\u73af\u6bd48\u6708\u63d0\u5347\u4e867\u4e2a\u591a\u767e\u5206\u70b9\uff0c\u663e\u793a\u957f\u5b89\u81ea\u4e3b\u54c1\u724c\u8f7f\u8f66\u4ecd\u5904\u4e8e\u653e\u91cf\u589e\u957f\u8d8b\u52bf\u4e4b\u4e2d\uff0c\u9038\u52a8\u3001CS35\u3001CS75\u7b49\u8f66\u578b\u6301\u7eed\u70ed\u9500\uff1b\u957f\u5b89\u94c3\u6728\u9500\u91cf\u8fbe1.2878\u4e07\u8f86\uff0c\u957f\u5b89\u9a6c\u81ea\u8fbe\u9500\u91cf1.1377\u4e07\u8f86\uff0c\u4e5f\u5904\u4e8e\u6301\u7eed\u589e\u957f\u4e2d\u3002\u4e0d\u8fc7\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u957f\u5b89\u798f\u7279\u5f53\u6708\u9500\u91cf6.9420\u4e07\u8f86\uff0c\u540c\u6bd4\u4e0b\u964d\u4e864.35%\uff0c\u8fd9\u4e5f\u662f\u8fd1\u4e24\u5e74\u6765\u957f\u798f\u9500\u91cf\u589e\u901f\u9996\u5ea6\u51fa\u73b0\u540c\u6bd4\u4e0b\u6ed1\u3002</p><p>\u3000\u3000\u6839\u636e\u534a\u5e74\u62a5\uff0c1-6\u6708\u957f\u5b89\u6c7d\u8f66\u5b8c\u6210\u9500\u552e\u6c7d\u8f66132\u4e07\u8f86\uff0c\u540c\u6bd4\u589e\u957f25%\uff0c\u5b9e\u73b0\u8425\u4e1a\u6536\u5165242.07\u4ebf\u5143\uff0c\u51c0\u5229\u6da636.28\u4ebf\u5143\uff0c\u5206\u522b\u540c\u6bd4\u589e\u957f19.77%\u548c194.85%\u3002\u7167\u6b64\u6d4b\u7b97\uff0c\u516c\u53f8\u4eca\u5e74\u524d\u4e09\u5b63\u5ea6\u4e1a\u7ee9\u4ecd\u80fd\u5b9e\u73b0\u8f83\u5927\u5e45\u5ea6\u589e\u957f\uff0c\u4f46\u4e09\u5b63\u5ea6\u7531\u4e8e\u53bb\u5e74\u57fa\u6570\u8f83\u9ad8\uff0c\u589e\u901f\u5e94\u8f83\u4e0a\u534a\u5e74\u6709\u6240\u653e\u7f13\u3002</p><p>\u3000\u3000\u5c55\u671b\u56db\u5b63\u5ea6\uff0c\u67d0\u5238\u5546\u6c7d\u8f66\u884c\u4e1a\u7814\u7a76\u5458\u5206\u6790\uff0c\u957f\u5b89\u6c7d\u8f66\u6700\u5927\u7684\u770b\u70b9\u5728\u81ea\u4e3b\u54c1\u724c\u8f7f\u8f66\u548c\u957f\u5b89\u9a6c\u81ea\u8fbe\u4e24\u65b9\u9762\uff0c\u957f\u5b89\u798f\u7279\u7531\u4e8e\u6ca1\u6709\u65b0\u8f66\u578b\u63a8\u51fa\uff0c\u4e14\u7b2c\u4e09\u5de5\u5382\u9884\u8ba1\u5230\u5e74\u5e95\u624d\u80fd\u6295\u4ea7\uff0c\u56e0\u6b64\u7ef4\u6301\u76ee\u524d\u7684\u5e02\u573a\u8868\u73b0\u5e94\u8be5\u53ef\u4ee5\u63a5\u53d7\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3199605">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u957f\u5b89\u6c7d\u8f66\u524d\u4e09\u5b63\u5ea6\u9500\u91cf\u589e\u957f24.15%',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3199605.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:17:20 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <div id="doc_3199621_0" style="display:none;"><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u738b\u6625\u6656\uff09 *ST\u5408\u6cf08\u65e5\u665a\u95f4\u516c\u544a\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63a8\u8fdb\u516c\u53f8\u6295\u8d44\u53ca\u6574\u5408\u667a\u80fd\u7a7f\u6234\u4ea7\u4e1a\u83b7\u5f97\u5916\u5ef6\u5f0f\u6269\u5f20\u7684\u7a7a\u95f4\uff0c\u516c\u53f8\u5168\u8d44\u5b50\u516c\u53f8\u6c5f\u897f\u5408\u529b\u6cf0\u4e0e\u6df1\u5733\u957f\u6da6\u8d44\u4ea7\u5171\u540c\u7ec4\u5efa\u6210\u7acb\u5408\u6cf0\u957f\u6da6\u667a\u80fd\u7a7f\u6234\u4ea7\u4e1a\u6295\u8d44\u57fa\u91d1\uff08\u6709\u9650\u5408\u4f19\uff09\u3002\u6839\u636e\u53cc\u65b9\u7b7e\u8ba2\u7684\u6846\u67b6\u534f\u8bae\uff0c\u57fa\u91d1\u603b\u89c4\u6a21\u4e3a10\u4ebf\u5143\uff0c\u62df\u5206\u671f\u52df\u96c6\uff0c\u4e00\u671f\u52df\u8d44\u603b\u989d1\u4ebf\u5143\u3002<br>\u3000\u3000\u6c5f\u897f\u5408\u529b\u6cf0\u4e3a\u4ea7\u4e1a\u57fa\u91d1\u7684\u6709\u9650\u5408\u4f19\u4eba\uff0c\u4ee5\u81ea\u6709\u8d44\u91d1\u8ba4\u7f34\u7cfb\u5217\u4ea7\u4e1a\u57fa\u91d1\u603b\u51fa\u8d44\u989d\u4e0d\u8d85\u8fc7\u4eba\u6c11\u5e01 8000 \u4e07\uff1b\u8ba4\u7f34\u4e00\u671f\u57fa\u91d1\u51fa\u8d44\u989d\u4e0d\u8d85\u8fc7\u4eba\u6c11\u5e01 3000 \u4e07\u5143\u3002\u8be5\u57fa\u91d1\u7684\u6295\u8d44\u9886\u57df\u5c06\u4e3b\u8981\u4e3a\u667a\u80fd\u7a7f\u6234\u4ea7\u4e1a\uff0c\u6295\u8d44\u5bf9\u8c61\u9996\u9009\u7b26\u5408\u6c5f\u897f\u5408\u529b\u6cf0\u7684\u53d1\u5c55\u6218\u7565\u548c\u5e76\u8d2d\u6295\u8d44\u65b9\u5411\u7684\u4f01\u4e1a\u3002 <br>\u3000\u3000\u516c\u53f8\u8868\u793a\uff0c\u901a\u8fc7\u4e0e\u957f\u6da6\u8d44\u4ea7\u5171\u540c\u8bbe\u7acb\u4ea7\u4e1a\u5e76\u8d2d\u57fa\u91d1\uff0c\u76ee\u7684\u662f\u5728\u516c\u53f8\u81ea\u8eab\u884c\u4e1a\u7ecf\u9a8c\u7684\u57fa\u7840\u4e0a\u5145\u5206\u5229\u7528\u957f\u6da6\u8d44\u4ea7\u7684\u4e13\u4e1a\u6295\u8d44\u56e2\u961f\u548c\u878d\u8d44\u6e20\u9053\uff0c\u901a\u8fc7\u5404\u79cd\u91d1\u878d\u5de5\u5177\u548c\u624b\u6bb5\u653e\u5927\u6295\u8d44\u80fd\u529b\uff0c\u6293\u4f4f\u667a\u80fd\u7a7f\u6234\u53d1\u5c55\u7684\u5e02\u573a\u673a\u9047\uff0c\u4e3a\u516c\u53f8\u672a\u6765\u53d1\u5c55\u50a8\u5907\u66f4\u591a\u5e76\u8d2d\u6807\u7684\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u516c\u53f8\u5728\u667a\u80fd\u7a7f\u6234\u9886\u57df\u7684\u5f00\u62d3\u80fd\u529b\u548c\u6838\u5fc3\u7ade\u4e89\u529b\u3002\u672c\u6b21\u5408\u4f5c\u5728\u4fdd\u8bc1\u516c\u53f8\u4e3b\u8425\u4e1a\u52a1\u53d1\u5c55\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u501f\u9274\u5408\u4f5c\u65b9\u7684\u6295\u8d44\u5e76\u8d2d\u7ecf\u9a8c\uff0c\u53ef\u4e3a\u516c\u53f8\u7684\u8d44\u672c\u8fd0\u4f5c\u63d0\u4f9b\u4e30\u5bcc\u7684\u7ecf\u9a8c\uff0c\u77ed\u671f\u5185\u5bf9\u516c\u53f8\u7684\u65e5\u5e38\u751f\u4ea7\u7ecf\u8425\u6d3b\u52a8\u4e0d\u4f1a\u4ea7\u751f\u5b9e\u8d28\u6027\u7684\u5f71\u54cd\uff0c\u957f\u671f\u5c06\u6709\u52a9\u4e8e\u516c\u53f8\u6210\u529f\u5e76\u8d2d\u5728\u667a\u80fd\u7a7f\u6234\u9886\u57df\u7684\u4f18\u8d28\u4f01\u4e1a\uff0c\u4e3a\u516c\u53f8\u6301\u7eed\u3001\u5feb\u901f\u3001\u7a33\u5b9a\u53d1\u5c55\u63d0\u4f9b\u4fdd\u969c\u3002</p><p>\u3000\u3000\u3010<span style="color: #666699"><strong>\u884c\u4e1a\u8d44\u8baf</strong></span>\u3011</p><p><strong>\u3000\u3000\u5916\u5a92\uff1a2014\u5e74\u5c06\u662f\u53ef\u7a7f\u6234\u8bbe\u5907\u5143\u5e74</strong></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u738b\u5b99\u6d01\uff09\u6d77\u5916\u5a92\u4f53\u8fd1\u65e5\u62a5\u9053\u79f0\uff0c2014\u5e74\u5c06\u4f1a\u662f\u53ef\u7a7f\u6234\u8ba1\u7b97\u8bbe\u5907\u4e4b\u5e74\u3002\u4f34\u968f\u773c\u955c\u3001\u5e3d\u5b50\u3001\u624b\u8868\u548c\u5176\u4ed6\u8bbe\u5907\u5927\u6d8c\u73b0\uff0c2014\u5e74\u201c\u7269\u8054\u7f51\u201d\u5c06\u8fc5\u901f\u53d1\u5c55\u3002\uff08<strong><a href="javascript:goPage(1)">\u8be6\u89c1\u5168\u6587</a></strong>\uff09</p><p><strong>\u3000\u3000IT\u5de8\u5934\u624e\u5806\u8fdb\u519b \u53ef\u7a7f\u6234\u8bbe\u5907\u767e\u4ebf\u91d1\u77ff\u5f85\u6398</strong></p><p>\u3000\u3000\u65e5\u524d\u56fd\u5185\u5916IT\u5de8\u5934\u7eb7\u7eb7\u8fdb\u519b\u53ef\u7a7f\u6234\u8bbe\u5907\u300226\u65e5\uff0cTCL\u901a\u8baf\u63a8\u51fa\u516b\u6838\u667a\u80fd\u624b\u673aidol X+\u53ca\u53ef\u7a7f\u6234\u8bbe\u5907Boom Band\u667a\u80fd\u624b\u73af\u3002\uff08<strong><a href="javascript:goPage(2)">\u8be6\u89c1\u5168\u6587</a></strong>\uff09</p><p>\u3000\u3000\u3010<span style="color: #666699"><strong>\u76f8\u5173\u6848\u4f8b</strong></span>\u3011</p><p><strong>\u3000\u3000\u73af\u65ed\u7535\u5b50\u5b9a\u589e\u52df\u8d44\u903e20\u4ebf\u5143\u52a0\u7801\u53ef\u7a7f\u6234\u8bbe\u5907</strong></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u674e\u9510\uff09 \u73af\u65ed\u7535\u5b50\u80a1\u4efd\u6709\u9650\u516c\u53f814\u65e5\u53d1\u5e03\u975e\u516c\u5f00\u53d1\u884c\u516c\u544a\uff0c\u516c\u53f8\u62df\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u4e0d\u8d85\u8fc7 11,444 \u4e07\u80a1\uff0c\u53d1\u884c\u4ef7\u683c\u6bcf\u80a1\u4e0d\u4f4e\u4e8e18.03 \u5143\u4eba\u6c11\u5e01\uff0c\u52df\u96c6\u8d44\u91d1\u603b\u989d\u9884\u8ba1\u4e0d\u8d85\u8fc7206,300 \u4e07\u5143\u3002\uff08<strong><a href="javascript:goPage(3)">\u8be6\u89c1\u5168\u6587</a></strong>\uff09</p><p><strong>\u3000\u3000\u4eac\u4e1c\u65b9\u53c2\u80a1\u7f8e\u56fdMeta\u516c\u53f8 \u5207\u5165\u53ef\u7a7f\u6234\u6280\u672f\u9886\u57df</strong></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u8d3a\u5efa\u4e1a\uff09 \u4eac\u4e1c\u65b9\u65e5\u524d\u901a\u8fc7\u4e0b\u5c5e\u5168\u8d44\u5b50\u516c\u53f8BOEOH\u51fa\u8d44\u7ea6500\u4e07\u7f8e\u5143\u8ba4\u8d2d\u4e86\u7f8e\u56fdMeta\u516c\u53f8\u90e8\u5206\u4f18\u5148\u80a1\u80a1\u6743\u3002\u5728\u516c\u53f8\u770b\u6765\uff0c\u6b64\u4e3e\u662f\u5b9e\u73b0\u5728\u53ef\u7a7f\u6234\u667a\u80fd\u8bbe\u5907\u548c\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u7b49\u521b\u65b0\u6027\u3001\u98a0\u8986\u6027\u6280\u672f\u9886\u57df\u7684\u6218\u7565\u5e03\u5c40\u53ca\u6280\u672f\u4eba\u624d\u7684\u79ef\u7d2f\u3002\uff08<strong><a href="javascript:goPage(4)">\u8be6\u89c1\u5168\u6587</a></strong>\uff09</p></div><div id="doc_3199621_1" style="display:none;"><p jquery1412780716737="2" jquery1412780710735="2" jquery1412780704255="2" jquery1412780699349="2"><strong>\u3000\u3000\u5916\u5a92\uff1a2014\u5e74\u5c06\u662f\u53ef\u7a7f\u6234\u8bbe\u5907\u5143\u5e74</strong></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u738b\u5b99\u6d01\uff09\u6d77\u5916\u5a92\u4f53\u8fd1\u65e5\u62a5\u9053\u79f0\uff0c2014\u5e74\u5c06\u4f1a\u662f\u53ef\u7a7f\u6234\u8ba1\u7b97\u8bbe\u5907\u4e4b\u5e74\u3002\u4f34\u968f\u773c\u955c\u3001\u5e3d\u5b50\u3001\u624b\u8868\u548c\u5176\u4ed6\u8bbe\u5907\u5927\u6d8c\u73b0\uff0c2014\u5e74\u201c\u7269\u8054\u7f51\u201d\u5c06\u8fc5\u901f\u53d1\u5c55\u3002<br>\u3000\u3000\u636e\u5168\u7403\u79fb\u52a8\u901a\u4fe1\u7cfb\u7edf\u534f\u4f1a\uff08GSMA\uff09\u9884\u8ba1\uff0c\u4eca\u5e74\u5168\u7403\u7269\u8054\u7f51\u5e02\u573a\u7684\u89c4\u6a21\u5c06\u8fbe\u5230100\u4ebf\u7f8e\u5143\uff0c\u800c\u52302017\u5e74\uff0c\u8fd9\u4e00\u89c4\u6a21\u5c06\u589e\u957f\u81f3440\u4ebf\u7f8e\u5143\u3002<br>\u3000\u3000\u4f5c\u4e3a\u53ef\u7a7f\u6234\u8bbe\u5907\u754c\u7684\u5143\u8001\uff0c\u8c37\u6b4c\u773c\u955c\u5c06\u8fdb\u4e00\u6b65\u5347\u7ea7\u52302.0\u7248\u672c\uff0c\u5e76\u4e14\u5c06\u4f1a\u642d\u8f7d\u533b\u5b66\u955c\u7247\u7b49\u914d\u4ef6\u6a2a\u7a7a\u51fa\u4e16\u3002\u800c\u6e38\u620f\u673a\u6d88\u4ea1\u7684\u9884\u8a00\u53ef\u80fd\u4e3a\u65f6\u8fc7\u65e9\u3002\u534e\u76db\u987f\u5927\u5b66\u57282013\u5e74\u53d1\u5e03\u7814\u7a76\u79f0\uff0c\u7535\u5b50\u6e38\u620f\u4e2d\u7684\u8fd0\u52a8\u6e38\u620f\u5c06\u6ee1\u8db3\u5efa\u8bae\u8fd0\u52a8\u91cf\u7684\u8981\u6c42\uff0c\u540c\u65f6\u4e5f\u662f\u4f20\u7edf\u6559\u5b66\u7684\u7406\u60f3\u66ff\u4ee3\u65b9\u6848\u3002<br>\u3000\u3000\u6b64\u5916\uff0c\u62a5\u9053\u8fd8\u79f0\uff0c\u865a\u62df\u663e\u793a\u8033\u673aOcculous Rift\u7684\u51fa\u73b0\u88ab\u89c6\u4e3a\u5c06\u628a\u865a\u62df\u73b0\u5b9e\u5e02\u573a\u6380\u5f00\u4e00\u4e2a\u5927\u53e3\u5b50\uff0c\u7ed9\u4e88\u5f00\u53d1\u4eba\u5458\u548c\u7528\u6237\u9996\u4e2a\u771f\u6b63\u5bf9\u6d88\u8d39\u8005\u53cb\u597d\u76843D\u73af\u5883\u3002<br>\u3000\u3000\u4e0d\u8fc7\uff0c\u4e00\u4e9b\u6311\u6218\u4e5f\u7ee7\u7eed\u5b58\u5728\uff0c\u76ee\u524d\u53ef\u7a7f\u6234\u8bbe\u5907\u9700\u8981\u9762\u5bf9\u7684\u4e24\u5927\u6280\u672f\u74f6\u9888\u662f\u7535\u6c60\u7eed\u822a\u80fd\u529b\u548c\u5c4f\u5e55\u5206\u8fa8\u7387\u3002</p></div><div id="doc_3199621_2" style="display:none;"><p jquery1412780716737="3" jquery1412780710735="3" jquery1412780704255="3" jquery1412780699349="3"><strong>\u3000\u3000IT\u5de8\u5934\u624e\u5806\u8fdb\u519b \u53ef\u7a7f\u6234\u8bbe\u5907\u767e\u4ebf\u91d1\u77ff\u5f85\u6398</strong></p><p>\u3000\u3000\u65e5\u524d\u56fd\u5185\u5916IT\u5de8\u5934\u7eb7\u7eb7\u8fdb\u519b\u53ef\u7a7f\u6234\u8bbe\u5907\u300226\u65e5\uff0cTCL\u901a\u8baf\u63a8\u51fa\u516b\u6838\u667a\u80fd\u624b\u673aidol X+\u53ca\u53ef\u7a7f\u6234\u8bbe\u5907Boom Band\u667a\u80fd\u624b\u73af\u3002\u516c\u53f8\u8463\u4e8b\u957f\u517cCEO\u674e\u4e1c\u751f\u4e0e\u8054\u53d1\u79d1\u8463\u4e8b\u957f\u8521\u660e\u4ecb\u3001\u5bbd\u5e26\u8d44\u672c\u8463\u4e8b\u957f\u7530\u6eaf\u5b81\u3001\u767e\u5ea6\u526f\u603b\u88c1\u6731\u5149\u3001\u4eac\u4e1c\u5546\u57ce\u526f\u603b\u88c1\u738b\u7b11\u677e\u7b49\u6218\u7565\u5408\u4f5c\u4f19\u4f34\u8054\u8882\u51fa\u5e2d\u53d1\u5e03\u4f1a\u3002<br>\u3000\u3000\u674e\u4e1c\u751f\u5728\u53d1\u5e03\u4f1a\u4e0a\u8868\u793a\uff0c\u968f\u7740\u667a\u80fd\u7ec8\u7aef\u3001\u53ef\u7a7f\u6234\u8bbe\u5907\u3001\u5927\u6570\u636e\u30014G\u7b49\u6210\u4e3a\u6d88\u8d39\u7535\u5b50\u7684\u4ef7\u503c\u6d3c\u5730\uff0c\u672a\u6765TCL\u96c6\u56e2(2.72,0.020,0.74%)\u5c06\u4f1a\u79c9\u6301\u66f4\u52a0\u5f00\u653e\u7684\u5fc3\u6001\u4e0e\u4ea7\u4e1a\u94fe\u4e0a\u4e0b\u6e38\u7684\u4f18\u79c0\u4f01\u4e1a\u5408\u4f5c\u3002<br>\u3000\u3000\u65e0\u72ec\u6709\u5076\uff0c\u534e\u4e3a\u7ec8\u7aef\u624b\u673a\u4ea7\u54c1\u7ebf\u603b\u88c1\u4f55\u521a\u65e5\u524d\u900f\u9732\uff0c\u534e\u4e3a\u6b63\u5728\u5bf9\u81ea\u4e3b\u7814\u5236\u7684\u53ef\u7a7f\u6234\u5f0f\u8bbe\u5907\u8fdb\u884c\u6d4b\u8bd5\uff0c\u672a\u6765\u4f1a\u9010\u6b65\u4e0a\u5e02\u3002\u636e\u6089\uff0c\u534e\u4e3a\u67092-3\u6b3e\u53ef\u7a7f\u6234\u8bbe\u5907\u6b63\u5728\u5f00\u53d1\u4e4b\u4e2d\uff0c\u672a\u67651-2\u4e2a\u6708\u5185\u4f1a\u53d1\u5e03\uff0c\u6700\u5feb\u53ef\u80fd\u57282014\u5e74\u7684\u7f8e\u56fd\u62c9\u65af\u7ef4\u52a0\u65af\u56fd\u9645\u6d88\u8d39\u7535\u5b50\u5c55(CES)\u4e0a\u4eae\u76f8\u3002\u4f55\u521a\u8868\u793a\uff0c\u4e0d\u6392\u9664\u63a8\u51fa\u667a\u80fd\u624b\u8868\u7684\u53ef\u80fd\u6027\u3002<br>\u3000\u3000\u800c\u6d77\u5916\u65b9\u9762\uff0c\u4e09\u661f\u7684\u53ef\u7a7f\u6234\u8bbe\u5907\u6280\u672f\u518d\u83b7\u7a81\u7834\u3002\u4e09\u661f\u65e5\u524d\u5411\u7f8e\u56fd\u4e13\u5229\u5c40\u63d0\u4ea4\u4e86\u4e00\u4efd\u5173\u4e8e\u53ef\u6298\u53e0\u53cc\u5c4f\u667a\u80fd\u673a\u7684\u4e13\u5229\u3002\u636e\u4e13\u5229\u663e\u793a\uff0c\u8fd9\u6b3e\u53cc\u5c4f\u667a\u80fd\u624b\u673a\u5c06\u4f1a\u5728\u5e94\u7528\u663e\u793a\u754c\u9762\u4e0a\u6709\u6240\u7a81\u7834\u3002\u8be5\u4e13\u5229\u6db5\u76d6\u4f17\u591a\u5185\u5bb9\uff0c\u5305\u62ec\u65e5\u5386\u663e\u793a\u3001\u89c6\u9891\u64ad\u653e\u3001\u56fe\u7247\u663e\u793a\u3001\u6e38\u620f\u754c\u9762\u7b49\u3002\u4ece\u8fd9\u4f17\u591a\u7ec6\u8282\u6765\u770b\uff0c\u4e09\u661f\u610f\u6b32\u7531\u5185\u5230\u5916\u6253\u9020\u4e00\u6b3e\u9769\u547d\u6027\u7684\u4ea7\u54c1\u3002<br>\u3000\u3000\u6b64\u524d\u6709\u673a\u6784\u53d1\u5e03\u7684\u62a5\u544a\u663e\u793a\uff0c\u827e\u5a92\u54a8\u8be2\u53d1\u5e03\u7684\u300a2013\u4e2d\u56fd\u53ef\u7a7f\u6234\u8bbe\u5907\u5e02\u573a\u7814\u7a76\u62a5\u544a\u300b\u663e\u793a\uff0c2012\u5e74\u4e2d\u56fd\u53ef\u7a7f\u6234\u8bbe\u5907\u5e02\u573a\u89c4\u6a21\u8fbe\u52306.1\u4ebf\u5143\uff0c\u9884\u8ba1\u52302015\u5e74\u4e2d\u56fd\u53ef\u7a7f\u6234\u8bbe\u5907\u5e02\u573a\u89c4\u6a21\u5c06\u8d85\u8fc7100\u4ebf\u5143\uff0c\u8fbe\u5230114.9\u4ebf\u5143\u3002</p></div><div id="doc_3199621_3" style="display:none;"><p jquery1412780716737="4" jquery1412780710735="4" jquery1412780704255="4" jquery1412780699349="4"><strong>\u3000\u3000\u73af\u65ed\u7535\u5b50\u5b9a\u589e\u52df\u8d44\u903e20\u4ebf\u5143\u52a0\u7801\u53ef\u7a7f\u6234\u8bbe\u5907</strong></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u674e\u9510\uff09 \u73af\u65ed\u7535\u5b50\u80a1\u4efd\u6709\u9650\u516c\u53f814\u65e5\u53d1\u5e03\u975e\u516c\u5f00\u53d1\u884c\u516c\u544a\uff0c\u516c\u53f8\u62df\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u4e0d\u8d85\u8fc7 11,444 \u4e07\u80a1\uff0c\u53d1\u884c\u4ef7\u683c\u6bcf\u80a1\u4e0d\u4f4e\u4e8e18.03 \u5143\u4eba\u6c11\u5e01\uff0c\u52df\u96c6\u8d44\u91d1\u603b\u989d\u9884\u8ba1\u4e0d\u8d85\u8fc7206,300 \u4e07\u5143\u3002\u52df\u96c6\u8d44\u91d1\u5c06\u4e3b\u8981\u7528\u4e8e\u73af\u7ef4\u7535\u5b50\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8\u4e00\u671f\u9879\u76ee\uff08\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u5236\u9020\u65b0\u5efa\u9879\u76ee\uff09\u3001\u9ad8\u4f20\u8f93\u9ad8\u5bc6\u5ea6\u5fae\u578b\u5316\u65e0\u7ebf\u901a\u4fe1\u6a21\u5757\u5236\u9020\u6280\u672f\u6539\u9020\u9879\u76ee\u4ee5\u53ca\u8865\u5145\u6d41\u52a8\u8d44\u91d1\u3002\u516c\u53f8\u80a1\u7968\u5c06\u4e8e4\u670815\u65e5\u590d\u724c\u3002<br>\u3000\u3000\u516c\u544a\u663e\u793a\uff0c\u672c\u6b21\u52df\u6295\u9879\u76ee\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u9879\u76ee\u8ba1\u5212\u603b\u6295\u8d4413 \u4ebf\u5143\uff0c\u62df\u65b0\u5efa3\u6761\u751f\u4ea7\u7ebf\uff0c\u4e3b\u8981\u7528\u4e8e\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u9879\u76ee\u65b0\u4ea7\u54c1\u7684\u7814\u53d1\u751f\u4ea7\uff0c\u6ee1\u8db3\u591a\u529f\u80fd\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u65b0\u4ea7\u54c1\u4ea7\u4e1a\u5316\u9700\u6c42\u3002\u76f8\u6bd4\u4e8e\u975e\u96c6\u6210\u5316\u7684\u7535\u8def\uff0c\u591a\u529f\u80fd\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u5177\u6709\u660e\u663e\u7684\u5fae\u578b\u5316\u3001\u6563\u70ed\u548c\u6297\u5e72\u6270\u4f18\u52bf\uff0c\u4ee5\u5fae\u5c0f\u5316\u6a21\u7ec4\u53d6\u4ee3\u4f20\u7edf\u624b\u6301\u88c5\u7f6e\u7684\u4e3b\u677f\u529f\u80fd\uff0c\u4f7f\u516c\u53f8\u4ea7\u54c1\u80fd\u66f4\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5bf9\u4f53\u79ef\u5fae\u5c0f\u5316\u8981\u6c42\u66f4\u9ad8\u3001\u8f7b\u8584\u77ed\u5c0f\u7684\u88c5\u7f6e\u7684\u5404\u7c7b\u9ad8\u7aef\u7535\u5b50\u4ea7\u54c1\u3002\u9879\u76ee\u6295\u4ea7\u5b9e\u65bd\u540e\uff0c\u5c06\u4e3b\u8981\u751f\u4ea7\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u5143\u4ef6\uff0c\u5e94\u7528\u4e8e\u9ad8\u7aef\u624b\u673a\u3001\u5e73\u677f\u7535\u8111\u3001\u53ef\u7a7f\u6234\u8bbe\u5907\u7b49\u5404\u7c7b\u7535\u5b50\u4ea7\u54c1\uff0c\u8fbe\u4ea7\u540e\u5c06\u5b9e\u73b0\u5e74\u751f\u4ea7\u65b0\u578b\u591a\u529f\u80fd\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u5143\u4ef63,600\u4e07\u4ef6\u7684\u751f\u4ea7\u80fd\u529b\u3002\u76ee\u524d\uff0c\u516c\u53f8\u5df2\u4e0e\u4f17\u591a\u56fd\u9645\u77e5\u540d\u7535\u5b50\u54c1\u724c\u4f01\u4e1a\u5efa\u7acb\u4e86\u957f\u671f\u7a33\u5b9a\u5408\u4f5c\u5173\u7cfb\uff0c\u800c\u8fd9\u4e9b\u5ba2\u6237\u6b63\u662f\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u4ea7\u54c1\u5e94\u7528\u7684\u5e02\u573a\u9886\u519b\u4f01\u4e1a\u3002\u901a\u8fc7\u4e0e\u4ed6\u4eec\u7684\u6df1\u5165\u5408\u4f5c\uff0c\u516c\u53f8\u80fd\u591f\u987a\u5229\u83b7\u5f97\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u4ea7\u54c1\u7684\u8ba2\u5355\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5fae\u5c0f\u5316\u7cfb\u7edf\u6a21\u7ec4\u4ea7\u54c1\u7684\u5e02\u573a\u5360\u6709\u7387\uff1b\u53e6\u4e00\u52df\u6295\u9879\u76ee\u9ad8\u4f20\u8f93\u9ad8\u5bc6\u5ea6\u5fae\u578b\u5316\u65e0\u7ebf\u901a\u4fe1\u6a21\u5757\u5236\u9020\u6280\u672f\u6539\u9020\u9879\u76ee\u6295\u8d44\u603b\u989d\u4e3a59,000\u4e07\u5143\uff0c\u9879\u76ee\u5efa\u8bbe\u5185\u5bb9\u4e3a\u65b0\u5efa\u5341\u6761\u65e0\u7ebf\u901a\u8baf\u6a21\u5757\u751f\u4ea7\u7ebf\uff0c\u5b8c\u6210\u516c\u53f8\u65e0\u7ebf\u6a21\u5757\u4ea7\u54c1\u7ebf\u7684\u6280\u672f\u5347\u7ea7\uff0c\u5b9e\u73b0\u6700\u65b0\u4e00\u4ee3\u7684\u65e0\u7ebf\u7f51\u7edc\u6807\u51c6\uff08IEEE 802.11ac\uff09\uff0c\u6ee1\u8db3\u65e0\u7ebf\u6a21\u7ec4\u65b0\u4ea7\u54c1\u4ea7\u4e1a\u5316\u9700\u6c42\u3002\u65e0\u7ebf\u901a\u8baf\u6a21\u5757\u4e3b\u8981\u5e94\u7528\u4e8e\u9ad8\u7aef\u667a\u80fd\u578b\u624b\u673a\u3001\u7535\u8111\uff08\u7b14\u8bb0\u672c\u3001\u5e73\u677f\uff09\u3001\u4e2a\u4eba\u5f71\u97f3\u5a31\u4e50\u88c5\u7f6e\uff08\u5305\u62ec MP3\u3001\u7f51\u7edc\u7535\u89c6\u53ca\u968f\u9009\u89c6\u8baf\u7b49\uff09\u548c\u6e38\u620f\u673a\uff08\u542b\u7f51\u7edc\u6e38\u620f\uff09\u3002\u8be5\u9879\u76ee\u4ea7\u54c1\u53ef\u5185\u5d4cWiFi\u3001\u84dd\u7259\u3001\u536b\u661f\u5bfc\u822a\uff08GPS\uff09\u3001NFC \u7b49\u591a\u79cd\u65e0\u7ebf\u53d1\u5c04\u6a21\u5757\uff0c\u80fd\u9002\u5e94\u65e0\u7ebf\u901a\u8baf\u4ea7\u54c1\u5411\u8f7b\u8584\u77ed\u5c0f\u65b9\u5411\u53d1\u5c55\u7684\u8d8b\u52bf\uff0c\u6ee1\u8db3\u9ad8\u6027\u4ef7\u6bd4\u3001\u9ad8\u901f\u7387\u3001\u4f4e\u80fd\u8017\u3001\u5c0f\u5c3a\u5bf8\u53ca\u591a\u529f\u80fd\u7684\u65e0\u7ebf\u901a\u8baf\u4ea7\u54c1\u9700\u6c42\u3002\u9879\u76ee\u6295\u4ea7\u540e\uff0c\u5c06\u5b9e\u73b0\u5e74\u751f\u4ea7\u65e0\u7ebf\u901a\u8baf\u6a21\u57579,720\u4e07\u4ef6\u7684\u751f\u4ea7\u80fd\u529b\u3002\u8be5\u9879\u76ee\u7684\u5b9e\u65bd\uff0c\u5c06\u6709\u52a9\u4e8e\u516c\u53f8\u5728\u65e0\u7ebf\u901a\u4fe1\u6a21\u7ec4\u6280\u672f\u7684\u7814\u7a76\u548c\u5f00\u53d1\u4e0a\u5efa\u7acb\u6838\u5fc3\u7ade\u4e89\u4f18\u52bf\uff0c\u63d0\u5347\u516c\u53f8\u7684\u4ea7\u54c1\u6280\u672f\u6c34\u5e73\uff0c\u6ee1\u8db3\u7ec8\u7aef\u5ba2\u6237\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u5e02\u573a\u5360\u6709\u7387\uff0c\u5de9\u56fa\u516c\u53f8\u5728\u65e0\u7ebf\u901a\u4fe1\u6a21\u7ec4\u9886\u57df\u7684\u5e02\u573a\u5730\u4f4d\uff1b\u516c\u53f8\u62df\u5c06\u672c\u6b21\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u52df\u96c6\u8d44\u91d1\u4e2d\u768447,300 \u4e07\u5143\u7528\u4e8e\u8865\u5145\u516c\u53f8\u6d41\u52a8\u8d44\u91d1\uff0c\u4ee5\u6ee1\u8db3\u516c\u53f8\u4e3b\u8425\u4e1a\u52a1\u6301\u7eed\u53d1\u5c55\u7684\u8d44\u91d1\u9700\u6c42\uff0c\u5e76\u6709\u52a9\u4e8e\u589e\u5f3a\u516c\u53f8\u6297\u98ce\u9669\u80fd\u529b\uff0c\u63d0\u5347\u7ecf\u8425\u6548\u76ca\u3002<br>\u3000\u3000\u516c\u53f8\u8868\u793a\uff0c\u968f\u77404G\u5e02\u573a\u7684\u5feb\u901f\u53d1\u5c55\u53ca\u53ef\u7a7f\u6234\u8bbe\u5907\u3001\u667a\u80fd\u7ec8\u7aef\u7b49\u4ea7\u4e1a\u5de8\u5927\u5e02\u573a\u524d\u666f\u7684\u91ca\u653e\uff0c\u516c\u53f8\u9700\u8fdb\u4e00\u6b65\u52a0\u5927\u5728\u4e0a\u8ff0\u4ea7\u54c1\u9886\u57df\u7684\u6295\u5165\uff0c\u4e3a\u5ba2\u6237\u63d0\u4f9b\u5b8c\u6574\u7684DMS\u670d\u52a1\u65b9\u6848\uff0c\u5e76\u529b\u4e89\u6210\u4e3a\u7535\u5b50\u8bbe\u8ba1\u4e0e\u5236\u9020\u670d\u52a1\u4e1a\u7684\u9886\u5bfc\u8005\u3002\u672c\u6b21\u52df\u6295\u9879\u76ee\u5efa\u6210\u6295\u4ea7\u540e\uff0c\u516c\u53f8\u7684\u76f8\u5173\u4ea7\u54c1\u7684\u7814\u53d1\u548c\u751f\u4ea7\u80fd\u529b\u5c06\u5f97\u5230\u589e\u5f3a\uff0c\u4ece\u800c\u4e3a\u516c\u53f8\u8fdb\u4e00\u6b65\u63d0\u5347\u6838\u5fc3\u7ade\u4e89\u529b\u6253\u4e0b\u575a\u5b9e\u57fa\u7840\u3002\u540c\u65f6\uff0c\u5229\u7528\u52df\u96c6\u8d44\u91d1\u8865\u5145\u516c\u53f8\u6d41\u52a8\u8d44\u91d1\uff0c\u5c06\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u589e\u5f3a\u516c\u53f8\u7684\u8d44\u91d1\u652f\u4ed8\u80fd\u529b\uff0c\u4f18\u5316\u516c\u53f8\u8d44\u4ea7\u8d1f\u503a\u7ed3\u6784\uff0c\u589e\u5f3a\u516c\u53f8\u53d1\u5c55\u540e\u52b2\u3002\u52df\u6295\u9879\u76ee\u5efa\u6210\u6295\u4ea7\u540e\uff0c\u968f\u7740\u516c\u53f8\u751f\u4ea7\u80fd\u529b\u7684\u63d0\u9ad8\u3001\u7814\u53d1\u6280\u672f\u5b9e\u529b\u7684\u589e\u5f3a\u4ee5\u53ca\u54c1\u724c\u7ade\u4e89\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u516c\u53f8\u7684\u8425\u4e1a\u6536\u5165\u6709\u671b\u8fdb\u4e00\u6b65\u589e\u52a0\uff0c\u516c\u53f8\u7684\u957f\u671f\u76c8\u5229\u80fd\u529b\u4e5f\u5c06\u83b7\u5f97\u63d0\u5347\uff0c\u6709\u5229\u4e8e\u516c\u53f8\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002</p></div><div id="doc_3199621_4" style="display:none;"><p jquery1412780716737="5" jquery1412780710735="5" jquery1412780704255="5" jquery1412780699349="5"><strong>\u3000\u3000\u4eac\u4e1c\u65b9\u53c2\u80a1\u7f8e\u56fdMeta\u516c\u53f8 \u5207\u5165\u53ef\u7a7f\u6234\u6280\u672f\u9886\u57df</strong></p><p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u8d3a\u5efa\u4e1a\uff09 \u4eac\u4e1c\u65b9\u65e5\u524d\u901a\u8fc7\u4e0b\u5c5e\u5168\u8d44\u5b50\u516c\u53f8BOEOH\u51fa\u8d44\u7ea6500\u4e07\u7f8e\u5143\u8ba4\u8d2d\u4e86\u7f8e\u56fdMeta\u516c\u53f8\u90e8\u5206\u4f18\u5148\u80a1\u80a1\u6743\u3002\u5728\u516c\u53f8\u770b\u6765\uff0c\u6b64\u4e3e\u662f\u5b9e\u73b0\u5728\u53ef\u7a7f\u6234\u667a\u80fd\u8bbe\u5907\u548c\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u7b49\u521b\u65b0\u6027\u3001\u98a0\u8986\u6027\u6280\u672f\u9886\u57df\u7684\u6218\u7565\u5e03\u5c40\u53ca\u6280\u672f\u4eba\u624d\u7684\u79ef\u7d2f\u3002<br>\u3000\u3000\u636e\u516c\u53f8\u4ecb\u7ecd\uff0c\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u662f\u901a\u8fc7\u7cfb\u7edf\u63d0\u4f9b\u7684\u865a\u62df\u4fe1\u606f\u589e\u52a0\u7528\u6237\u5bf9\u73b0\u5b9e\u4e16\u754c\u611f\u77e5\u7684\u6280\u672f\uff0c\u5b83\u5c06\u7cfb\u7edf\u6240\u751f\u6210\u7684\u865a\u62df\u7269\u4f53\u3001\u573a\u666f\u6216\u7cfb\u7edf\u63d0\u793a\u4fe1\u606f\u53e0\u52a0\u5230\u771f\u5b9e\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u7acb\u4f53\u89e6\u63a7\uff0c\u5b9e\u73b0\u771f\u5b9e\u73af\u5883\u4e0e\u865a\u62df\u4e16\u754c\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u4e3a\u865a\u62df\u73b0\u5b9e\u6280\u672f\u7684\u4e00\u4e2a\u7ec6\u5206\u9886\u57df\u3002Meta\u516c\u53f8\u4e3b\u8981\u4ea7\u54c1\u201cSpace Glasses\u201d\u662f\u4e00\u6b3e\u53ef\u4ee5\u201c\u62d3\u5c55\u73b0\u5b9e\u73af\u5883\u201d\u7684\u667a\u80fd\u773c\u955c\uff0c\u5b9a\u4f4d\u4e3a\u589e\u5f3a\u73b0\u5b9e\u73af\u5883\u5e73\u53f0\uff0c\u5c06\u4fe1\u606f\u4ee53D\u6210\u50cf\u5f62\u5f0f\u548c\u73b0\u5b9e\u5bf9\u63a5\uff0c\u6709\u671b\u6539\u53d8\u751f\u4ea7\u5236\u9020\u3001\u533b\u7597\u53ca\u6e38\u620f\u7b49\u4f17\u591a\u9886\u57df\u7684\u6280\u672f\u751f\u6001\u73af\u5883\u3002<br>\u3000\u3000Meta\u662f\u7f8e\u56fd\u4e00\u5bb6\u53ef\u7a7f\u6234\u667a\u80fd\u8bbe\u5907\u521d\u521b\u516c\u53f8\uff0c\u4e3b\u8981\u6d89\u8db3\u53ef\u7a7f\u6234\u8ba1\u7b97\u548c\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u9886\u57df\uff0c\u4e3b\u8425\u4e1a\u52a1\u662f\u53ef\u7a7f\u6234\u589e\u5f3a\u73b0\u5b9e\u667a\u80fd\u8bbe\u5907\u3002\u8be5\u516c\u53f8\u4f18\u52bf\u6280\u672f\u9886\u5148\uff0c\u638c\u63e1\u4e16\u754c\u9886\u5148\u7684\u589e\u5f3a\u73b0\u5b9e\uff08Augmented Reality\uff09\u6280\u672f\uff0c\u53ef\u4ee5\u8ba9\u7528\u6237\u5728\u865a\u62df\u73b0\u5b9e\u4e2d\u8fdc\u7a0b\u64cd\u7eb5\u624b\u673a\u548c\u7535\u8111\u3002\u540c\u65f6\uff0c\u8be5\u516c\u53f8\u56e2\u961f\u6838\u5fc3\u5f3a\u5927\uff0c\u5305\u62ecSteve Mann\uff08\u9996\u5e2d\u79d1\u5b66\u5bb6\uff0c\u7a7f\u6234\u5f0f\u8ba1\u7b97\u9886\u57df\u4e13\u5bb6\uff09\u3001Steven Feiner\uff08\u6280\u672f\u987e\u95ee\uff0c\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u9886\u57df\u4e13\u5bb6\uff09\u548cJayse Hansen\uff08\u66fe\u62c5\u4efb\u300a\u94a2\u94c1\u4fa0\u300b\u7cfb\u5217\u7535\u5f71\u4e2d\u5168\u606f\u56fe\u4ea4\u4e92\u754c\u9762\u7684\u8bbe\u8ba1\u8005\uff09\u3002\u6b64\u5916\uff0c\u8be5\u516c\u53f8\u8fd8\u5177\u6709\u5f3a\u5927\u7684\u4e13\u5229\u6c60\u548c\u8f6f\u786c\u4ef6\u7ed3\u5408\u7684\u5f3a\u5927\u5e73\u53f0\u5f00\u53d1\uff0c\u53ef\u5145\u5206\u5229\u7528\u5168\u7403\u8303\u56f4\u5185\u5f00\u53d1\u8005\u7684\u8d44\u6e90\u642d\u5efa\u5176\u751f\u6001\u7cfb\u7edf\u3002\u4f5c\u4e3a\u667a\u80fd\u773c\u955c\u5382\u5546\u4e4b\u4e00\uff0cMeta\u9009\u62e9\u4e86\u4e00\u6761\u4e0d\u540c\u4e8e\u5176\u4ed6\u5382\u5546\u7684\u8def\u7ebf\u2014\u2014\u4e0d\u4ec5\u5c06\u865a\u62df\u73b0\u5b9e\u4e0e\u771f\u5b9e\u4e16\u754c\u76f8\u7ed3\u5408\uff0c\u540c\u65f6\u8fd8\u5177\u6709\u4ea4\u4e92\u6027\u3002<br>\u3000\u3000\u636e\u7535\u5b50\u884c\u4e1a\u6743\u5a01\u7814\u7a76\u673a\u6784IMS\u4f30\u8ba1\uff0c\u53ef\u7a7f\u6234\u8bbe\u5907\u5c06\u6301\u7eed\u5347\u6e29\uff0c2016\u5e74\u53ef\u7a7f\u6234\u8bbe\u5907\u5e02\u573a\u89c4\u6a21\u53ef\u8fbe60\u4ebf\u7f8e\u5143\u3002<br>\u3000\u3000\u4eac\u4e1c\u65b9\u8ba4\u4e3a\uff0c\u865a\u62df\u73b0\u5b9e\u6280\u672f\u7ecf\u5386\u8fc7\u6ce1\u6cab\u671f\u540e\uff0c\u6b63\u5904\u4e8e\u590d\u82cf\u671f\uff0c\u5f53\u524d\u6295\u8d44\u65f6\u673a\u8f83\u597d\u3002Meta\u516c\u53f8\u6280\u672f\u53d1\u5c55\u8def\u7ebf\u6e05\u6670\uff0c\u5176\u4ea7\u54c1\u5728\u672a\u6765\u53ef\u4ee5\u53d6\u4ee3\u4e2a\u4eba\u7535\u8111\uff0c\u5e94\u7528\u8303\u56f4\u5e7f\u6cdb\u3002\u6295\u8d44Meta\u516c\u53f8\uff0c\u53ef\u5229\u7528\u5176\u73b0\u6709\u6280\u672f\u4f18\u52bf\u548c\u4eba\u624d\u56e2\u961f\u62d3\u5c55\u516c\u53f8\u5728\u865a\u62df\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u7684\u5e03\u5c40\uff0c\u5e76\u4e3a\u516c\u53f8\u5207\u5165\u8fd9\u4e2a\u4e1a\u52a1\u65b9\u5411\u79ef\u7d2f\u6280\u672f\u4eba\u624d\u7b49\u76f8\u5173\u8d44\u6e90\u3002<br>\u3000\u3000\u516c\u53f8\u540c\u65f6\u8868\u793a\uff0c\u5c06\u5229\u7528\u591a\u5e74\u6765\u5728\u534a\u5bfc\u4f53\u663e\u793a\u3001\u89e6\u63a7\u548c\u7cfb\u7edf\u96c6\u6210\u9886\u57df\u79ef\u6512\u7684\u6280\u672f\u7ecf\u9a8c\uff0c\u4e3a\u4eca\u540e\u865a\u62df\u4eba\u673a\u4ea4\u4e92\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u6709\u529b\u652f\u6491\u3002</p></div><div id="contentPager"><span id="span_previous_page"><a href="javascript:goPage(page-1);">\u4e0a\u4e00\u9875</a></span>\xa0\xa0\u7b2c<span id="span_pagerNumber_0" onclick="goPage(\'0\');">\xa0[1]</span><span id="span_pagerNumber_1" onclick="goPage(\'1\');">\xa0[2]</span><span id="span_pagerNumber_2" onclick="goPage(\'2\');">\xa0[3]</span><span id="span_pagerNumber_3" onclick="goPage(\'3\');">\xa0[4]</span><span id="span_pagerNumber_4" onclick="goPage(\'4\');">\xa0[5]</span>\xa0\u9875<span id="span_total_page" style="cursor: auto;color: #000;">\xa0(\u5171<strong>5</strong>\u9875)</span>\xa0\xa0<span id="span_next_page"><a href="javascript:goPage(page+1);">\u4e0b\u4e00\u9875</a></span></div><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="5"><input type="hidden" id="hid_docId" value="3199621">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 9, 0, 0),
 'title': u'*ST\u5408\u6cf0\u6210\u7acb\u603b\u89c4\u6a2110\u4ebf\u4ea7\u4e1a\u57fa\u91d1   \u5f00\u62d3\u667a\u80fd\u7a7f\u6234\u4e1a\u52a1',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3199621.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:17:50 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u66f9\u6500\u5cf0\uff09 \u4e2d\u987a\u6d01\u67d4\u4e8e10\u67088\u65e5\u665a\u53d1\u5e03\u5b9a\u589e\u9884\u6848\u3002\u8be5\u516c\u53f8\u62df\u4ee5\u6bcf\u80a18.11\u5143\u7684\u4ef7\u683c\uff0c\u5411\u8be5\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u9093\u6c0f\u5bb6\u65cf\u6210\u5458\u5b9a\u589e2466\u4e07\u80a1\u80a1\u4efd\uff0c\u52df\u8d44\u8fd12\u4ebf\u5143\uff0c\u8865\u5145\u6d41\u52a8\u8d44\u91d1\u3002<br>\u3000\u3000\u63d0\u53ca\u6b64\u6b21\u542f\u52a8\u5b9a\u589e\u7684\u80cc\u666f\uff0c\u4e2d\u987a\u6d01\u67d4\u8868\u793a\uff0c\u867d\u7136\u6b27\u503a\u5371\u673a\u53ca\u5168\u7403\u7ecf\u6d4e\u653e\u7f13\u7ee7\u7eed\u56f0\u6270\u5168\u7403\u7ecf\u6d4e\uff0c\u4f46\u751f\u6d3b\u7528\u7eb8\u4ea7\u54c1\u5c5e\u4e8e\u5feb\u901f\u6d88\u8d39\u54c1\uff0c\u53d7\u56fd\u9645\u7ecf\u6d4e\u73af\u5883\u5f71\u54cd\u8f83\u5c0f\uff0c\u6574\u4f53\u5e02\u573a\u89c4\u6a21\u4ecd\u5448\u9010\u5e74\u589e\u957f\u6001\u52bf\u3002\u8fd1\u5e74\u6765\u884c\u4e1a\u65b0\u589e\u4ea7\u80fd\u8fc7\u591a\uff0c\u51fa\u73b0\u9636\u6bb5\u6027\u7684\u4f9b\u5927\u4e8e\u6c42\uff0c\u5bfc\u81f4\u5e02\u573a\u7ade\u4e89\u52a0\u5267\u3002\u62a5\u544a\u671f\u5185\uff0c\u4e3a\u5e94\u5bf9\u4e0d\u65ad\u52a0\u5267\u7684\u5e02\u573a\u7ade\u4e89\u73af\u5883\uff0c\u8be5\u516c\u53f8\u4e0d\u65ad\u52a0\u5f3a\u5168\u56fd\u96f6\u552e\u7cfb\u7edf\u7684\u5f00\u62d3\u5e76\u5feb\u901f\u586b\u8865\u7a7a\u767d\u7f51\u70b9\uff0c\u540c\u65f6\u79ef\u6781\u901a\u8fc7\u5404\u79cd\u5a92\u4ecb\u8fdb\u884c\u54c1\u724c\u8425\u9500\u548c\u4ea7\u54c1\u63a8\u4ecb\uff0c\u8be5\u516c\u53f8\u9500\u552e\u89c4\u6a21\u6301\u7eed\u589e\u957f\uff0c2013\u5e74\u5ea6\u516c\u53f8\u5b9e\u73b0\u9500\u552e\u6536\u516525.02\u4ebf\u5143\uff0c\u8f832011\u5e74\u5ea6\u589e\u957f34.77%\u3002\u672a\u6765\uff0c\u968f\u7740\u516c\u53f8\u4ea7\u80fd\u7684\u8fdb\u4e00\u6b65\u91ca\u653e\uff0c\u8be5\u516c\u53f8\u5c06\u8fdb\u4e00\u6b65\u52a0\u5f3a\u8425\u9500\u7f51\u7edc\u7684\u5efa\u8bbe\uff0c\u52a0\u5927\u54c1\u724c\u8425\u9500\u529b\u5ea6\uff0c\u5bf9\u8425\u8fd0\u8d44\u91d1\u7684\u9700\u6c42\u4e5f\u5c06\u76f8\u5e94\u589e\u52a0\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u6269\u5927\u516c\u53f8\u89c4\u6a21\uff0c\u63d0\u5347\u516c\u53f8\u7efc\u5408\u7ade\u4e89\u5b9e\u529b\uff0c\u8be5\u516c\u53f8\u62df\u63d0\u51fa\u672c\u6b21\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u7533\u8bf7\u3002<br>\u3000\u3000\u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u8be5\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u4e3a\u9093\u6c0f\u5bb6\u65cf\uff0c\u5176\u6210\u5458\u4e3a\u9093\u9896\u5fe0\u3001\u9093\u51a0\u5f6a\u548c\u9093\u51a0\u6770\uff0c\u5176\u4e2d\u9093\u9896\u5fe0\u4e0e\u9093\u51a0\u5f6a\u3001\u9093\u51a0\u6770\u7cfb\u7236\u5b50\u5173\u7cfb\uff0c\u9093\u51a0\u5f6a\u548c\u9093\u51a0\u6770\u7cfb\u5144\u5f1f\u5173\u7cfb\u3002\u9093\u9896\u5fe0\u3001\u9093\u51a0\u5f6a\u548c\u9093\u51a0\u6770\u5206\u522b\u6301\u6709\u516c\u53f8\u63a7\u80a1\u80a1\u4e1c\u4e2d\u987a\u96c6\u56e260%\u300120%\u548c20%\u7684\u80a1\u6743\uff1b\u9093\u9896\u5fe0\u6301\u6709\u4e2d\u987a\u516c\u53f8100%\u7684\u80a1\u6743\u3002\u6b64\u6b21\u5b9a\u589e\u5bf9\u8c61\u4e3a\u8be5\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u9093\u6c0f\u5bb6\u65cf\u6210\u5458\u9093\u9896\u5fe0\uff0c\u6b64\u6b21\u975e\u516c\u5f00\u53d1\u884c\u5b8c\u6210\u540e\uff0c\u516c\u53f8\u80a1\u4efd\u603b\u6570\u4e3a43026\u4e07\u80a1\uff0c\u9093\u6c0f\u5bb6\u65cf\u5408\u8ba1\u63a7\u5236\u516c\u53f854.64%\u7684\u80a1\u4efd\uff0c\u4ecd\u4e3a\u516c\u53f8\u5b9e\u9645\u63a7\u5236\u4eba\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3199629">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u4e2d\u987a\u6d01\u67d4\u5b9a\u589e\u52df\u8d442\u4ebf \u5b9e\u9645\u63a7\u5236\u4eba\u9093\u9896\u5fe0\u4e00\u4eba\u5305\u63fd',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3199629.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:18:20 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u9648\u5fd7\u5f3a\uff09 10\u67088\u65e5\u665a\u95f4\uff0c\u4e2d\u5174\u5546\u4e1a\u53d1\u5e03\u516c\u544a\uff0c\u6839\u636e\u6c88\u9633\u5e02\u548c\u5e73\u533a\u653f\u5e9c\u300a\u5173\u4e8e\u7ed9\u4e88\u4e2d\u5174\u2014\u6c88\u9633\u5546\u4e1a\u5927\u53a6\uff08\u96c6\u56e2\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8\u653f\u7b56\u6276\u6301\u8d44\u91d1\u7684\u590d\u51fd\u300b\uff0c\u4e3a\u652f\u6301\u516c\u53f8\u6301\u7eed\u53d1\u5c55\uff0c\u4f9d\u636e\u76f8\u5173\u73b0\u4ee3\u670d\u52a1\u4e1a\u53ca\u79d1\u6280\u6587\u5316\u878d\u5408\u6276\u6301\u653f\u7b56\uff0c\u7ed9\u4e88\u516c\u53f8\u653f\u7b56\u8865\u8d341400\u4e07\u3002<br>\u3000\u3000\u516c\u53f8\u79f0\uff0c\u4e0a\u8ff0\u6b3e\u9879\u5df2\u5212\u62e8\u5230\u516c\u53f8\u8d26\u6237\u3002\u516c\u53f8\u5c06\u6309\u7167\u300a\u4f01\u4e1a\u4f1a\u8ba1\u51c6\u5219\u7b2c16\u53f7-\u653f\u5e9c\u8865\u52a9\u300b\u7684\u6709\u5173\u89c4\u5b9a\uff0c\u5bf9\u4e0a\u8ff0\u8865\u8d34\u8d44\u91d1\u8fdb\u884c\u4f1a\u8ba1\u5904\u7406\uff0c\u8ba1\u51652014\u5e74\u5ea6\u5f53\u671f\u635f\u76ca\u3002\u5177\u4f53\u4f1a\u8ba1\u5904\u7406\u5c06\u4ee5\u4f1a\u8ba1\u5e08\u4e8b\u52a1\u6240\u5e74\u5ea6\u5ba1\u8ba1\u7ed3\u679c\u4e3a\u51c6\u3002<br>\u3000\u3000\u6570\u636e\u663e\u793a,\u4eca\u5e74\u4e0a\u534a\u5e74\uff0c\u516c\u53f8\u5b9e\u73b0\u5f52\u5c5e\u4e8e\u4e0a\u5e02\u516c\u53f8\u80a1\u4e1c\u7684\u51c0\u5229\u6da6\u4e3a4273\u4e07\u5143\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3199612">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u4e2d\u5174\u5546\u4e1a\u83b71400\u4e07\u5143\u653f\u5e9c\u8865\u52a9',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3199612.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:18:51 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u7f51\u8baf\uff08\u8bb0\u8005 \u9648\u5fd7\u5f3a\uff09 \u7ee7\u5b9a\u589e\u65b9\u6848\u83b7\u5f97\u5317\u4eac\u56fd\u8d44\u59d4\u540c\u610f\u540e\uff0c10\u67088\u65e5\u665a\u95f4\uff0c\u677e\u8fbd\u6c7d\u8f66\u516c\u544a\uff0c\u516c\u53f8\u4e8e10 \u67088\u65e5\u6536\u5230\u4e86\u4e2d\u56fd\u8bc1\u5238\u76d1\u7763\u7ba1\u7406\u59d4\u5458\u4f1a\u300a\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u884c\u653f\u8bb8\u53ef\u7533\u8bf7\u53d7\u7406\u901a\u77e5\u4e66\u300b\uff08141253 \u53f7\uff09\uff0c\u8bc1\u76d1\u4f1a\u4f9d\u6cd5\u5bf9\u516c\u53f8\u63d0\u4ea4\u7684\u300a\u4e0a\u5e02\u516c\u53f8\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u300b\u884c\u653f\u8bb8\u53ef\u7533\u8bf7\u6750\u6599\u8fdb\u884c\u4e86\u5ba1\u67e5\uff0c\u8ba4\u4e3a\u8be5\u7533\u8bf7\u6750\u6599\u9f50\u5168\uff0c\u7b26\u5408\u6cd5\u5b9a\u5f62\u5f0f\uff0c\u51b3\u5b9a\u5bf9\u8be5\u884c\u653f\u8bb8\u53ef\u7533\u8bf7\u4e88\u4ee5\u53d7\u7406\u3002<br>\u3000\u3000\u516c\u53f8\u79f0\uff0c\u6b64\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u4e8b\u5b9c\u80fd\u5426\u83b7\u5f97\u6838\u51c6\u4ecd\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u516c\u53f8\u5c06\u53ca\u65f6\u62ab\u9732\u6b64\u6b21\u975e\u516c\u5f00\u53d1\u884c\u80a1\u7968\u4e8b\u5b9c\u7684\u540e\u7eed\u8fdb\u5c55\u60c5\u51b5\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3199616">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 10, 8, 0, 0),
 'title': u'\u677e\u8fbd\u6c7d\u8f66\u5b9a\u589e\u65b9\u6848\u83b7\u5f97\u8bc1\u76d1\u4f1a\u53d7\u7406',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201410/3199616.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:18:51 [scrapy] INFO: Crawled 6429 pages (at 0 pages/min), scraped 6145 items (at 0 items/min)
2016-11-23 15:19:21 [scrapy] ERROR: Error processing {'content': u'<div class="content" id="qmt_content_div">\r\n                        <p>\u3000\u3000\u4e2d\u56fd\u8bc1\u5238\u73a9\u8baf\uff08\u8bb0\u8005 \u5b8b\u5143\u4e1c\uff09 \u5927\u897f\u6d0b\uff08600558\uff0929\u65e5\u665a\u95f4\u53d1\u5e03\u4e1a\u7ee9\u9884\u589e\u516c\u544a\uff0c\u7ecf\u516c\u53f8\u8d22\u52a1\u90e8\u95e8\u521d\u6b65\u6d4b\u7b97\uff0c\u9884\u8ba1\u516c\u53f82014\u5e741-9\u6708\u5b9e\u73b0\u7684\u51c0\u5229\u6da6\u4e0e\u540c\u6bd4\u589e\u957f50%\u5de6\u53f3\u3002</p><p>\u3000\u3000\u5927\u897f\u6d0b\u8868\u793a\uff0c\u4e0a\u5e74\u540c\u671f\u5f52\u5c5e\u4e8e\u4e0a\u5e02\u516c\u53f8\u80a1\u4e1c\u7684\u51c0\u5229\u6da62374.46\u4e07\u5143\u3002\u4eca\u5e74\u516c\u53f8\u51c0\u5229\u6da6\u540c\u6bd4\u8f83\u5927\u5e45\u5ea6\u589e\u957f\uff0c\u4e3b\u8981\u4e3a\u516c\u53f8\u4e3b\u8425\u4e1a\u52a1\u6bdb\u5229\u7387\u589e\u957f\u6240\u81f4\u3002\u5206\u6790\u4eba\u58eb\u8ba4\u4e3a\uff0c\u4f5c\u4e3a\u56fd\u5185\u7279\u79cd\u710a\u6750\u9886\u57df\u7684\u9f99\u5934\u4f01\u4e1a\uff0c\u516c\u53f8\u5df2\u7ecf\u6210\u529f\u8fdb\u5165\u6838\u7535\u3001\u519b\u5de5\u7528\u7b49\u7279\u79cd\u710a\u6750\u5e02\u573a\uff1b \u540c\u65f6\uff0c\u4e3a\u6ee1\u8db3\u516c\u53f8\u672a\u6765\u53d1\u5c55\u6218\u7565\uff0c\u516c\u53f8\u5c06\u672c\u7740\u201c\u505a\u597d\u7279\u79cd\u710a\u6750\uff0c\u5411\u4e24\u4e2a\u65b9\u5411\u5ef6\u4f38\u201d\u7684\u65b9\u9488\u52a0\u5feb\u6269\u5f20\u3002\u76ee\u524d\uff0c\u5927\u897f\u6d0b\u6838\u7535\u5e38\u89c4\u5c9b\u710a\u6750\u5df2\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\uff0c\u6838\u5c9b\u710a\u6750\u4e3a\u56fd\u5185\u72ec\u5bb6\u751f\u4ea7\u4f01\u4e1a\uff0c\u5e76\u5df2\u5177\u5907\u9879\u76ee\u7ecf\u9a8c\uff0c\u968f\u7740\u519b\u5de5\u710a\u6750\u968f\u7740\u6211\u56fd\u6d77\u519b\u88c5\u5907\u7684\u53d1\u5c55\uff0c\u672a\u6765\u9700\u6c42\u91cf\u6709\u671b\u6301\u7eed\u589e\u957f\u3002\u516c\u53f8\u76f8\u5173\u4eba\u58eb\u66fe\u8868\u793a\uff0c\u5927\u897f\u6d0b\u5c06\u5411\u4ea7\u4e1a\u94fe\u4e0b\u6e38\u5ef6\u4f38\uff0c\u79ef\u6781\u5e03\u5c40\u81ea\u52a8\u5316\u710a\u63a5\u8bbe\u5907\u3001\u710a\u63a5\u5de5\u827a\u603b\u5305\u7b49\u4e1a\u52a1\uff0c\u8ba1\u5212\u4ee5\u517c\u5e76\u91cd\u7ec4\u7b49\u5f62\u5f0f\u5b9e\u73b0\u5feb\u901f\u7a81\u7834\u3002</p><div id="output_hangqing_div" style="text-align:center;" class="visible-md-block visible-lg-block"></div><input type="hidden" id="hid_totalPage" value="1"><input type="hidden" id="hid_docId" value="3196232">\r\n                        \r\n                    </div>',
 'time': datetime.datetime(2014, 9, 29, 0, 0),
 'title': u'\u5927\u897f\u6d0b\u4e09\u5b63\u62a5\u51c0\u5229\u6da6\u9884\u589e50%',
 'url': 'http://ggjd.cnstock.com/company/scp_ggjd/tjd_bbdj/201409/3196232.htm'}
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/twisted/internet/defer.py", line 649, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/yuweifu/spiders/news/news/pipelines.py", line 32, in process_item
    self.db[self.collection_name].create_index("url", unique=True)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1387, in create_index
    self.__create_index(keys, kwargs)
  File "/Library/Python/2.7/site-packages/pymongo/collection.py", line 1294, in __create_index
    with self._socket_for_writes() as sock_info:
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/Library/Python/2.7/site-packages/pymongo/mongo_client.py", line 762, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 210, in select_server
    address))
  File "/Library/Python/2.7/site-packages/pymongo/topology.py", line 186, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 61] Connection refused
2016-11-23 15:19:25 [scrapy] ERROR: Spider error processing <GET http://ggjd.cnstock.com/gglist/search/qmtbbdj/29> (referer: http://ggjd.cnstock.com/gglist/search/qmtbbdj/28)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 29, in parse
    if words[-2] == u'下一页':
IndexError: list index out of range
2016-11-23 15:19:33 [scrapy] INFO: Crawled 6760 pages (at 331 pages/min), scraped 6477 items (at 332 items/min)
2016-11-23 15:19:46 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/company/scp_ggjd/gszhuanti/2015bnb/> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/26)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3283082.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/76)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278178.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3280014.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3281519.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3280033.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3276450.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:14 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3276453.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:15 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3273173.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/79)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:15 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3274832.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/79)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:17 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201411/3258128.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/84)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:22 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201411/3246942.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/88)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3274684.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/79)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278159.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3278232.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/78)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:24 [scrapy] ERROR: Spider error processing <GET http://company.cnstock.com/gszj/rdgs/201412/3281562.htm> (referer: http://company.cnstock.com/company/scp_dsy/tcsy_rdgs/77)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/cnstock.py", line 36, in parse_item
    item['time'] = response.xpath('//span[@class="timer"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:20:33 [scrapy] INFO: Crawled 9055 pages (at 2295 pages/min), scraped 8666 items (at 2189 items/min)
2016-11-23 15:20:37 [scrapy] INFO: Closing spider (finished)
2016-11-23 15:20:37 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 16,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 8,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 8,
 'downloader/request_bytes': 2925977,
 'downloader/request_count': 9220,
 'downloader/request_method_count/GET': 9220,
 'downloader/response_bytes': 85488211,
 'downloader/response_count': 9204,
 'downloader/response_status_count/200': 9189,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/404': 14,
 'dupefilter/filtered': 940,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 23, 7, 20, 37, 215665),
 'item_scraped_count': 8814,
 'log_count/ERROR': 47,
 'log_count/INFO': 16,
 'request_depth_max': 207,
 'response_received_count': 9201,
 'scheduler/dequeued': 9220,
 'scheduler/dequeued/memory': 9220,
 'scheduler/enqueued': 9220,
 'scheduler/enqueued/memory': 9220,
 'spider_exceptions/IndexError': 1,
 'spider_exceptions/TypeError': 23,
 'start_time': datetime.datetime(2016, 11, 23, 7, 5, 33, 386074)}
2016-11-23 15:20:37 [scrapy] INFO: Spider closed (finished)
2016-11-23 15:20:38 [scrapy] INFO: Scrapy 1.2.1 started (bot: news)
2016-11-23 15:20:38 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'news.spiders', 'SPIDER_MODULES': ['news.spiders'], 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'news'}
2016-11-23 15:20:38 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-11-23 15:20:38 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-11-23 15:20:38 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-11-23 15:20:38 [scrapy] INFO: Enabled item pipelines:
['news.pipelines.MongoDBPipeline']
2016-11-23 15:20:38 [scrapy] INFO: Spider opened
2016-11-23 15:20:38 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-11-23 15:21:38 [scrapy] INFO: Crawled 1556 pages (at 1556 pages/min), scraped 1491 items (at 1491 items/min)
2016-11-23 15:22:18 [scrapy] ERROR: Spider error processing <GET http://www.stcn.com> (referer: http://company.stcn.com/cjnews/14.shtml)
Traceback (most recent call last):
  File "/Library/Python/2.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Library/Python/2.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/yuweifu/spiders/news/news/spiders/stcn.py", line 36, in parse_item
    item['time'] = response.xpath('//div[@class="intal_tit"]/div[@class="info"]/text()').extract_first()[:10]
TypeError: 'NoneType' object has no attribute '__getitem__'
2016-11-23 15:22:38 [scrapy] INFO: Crawled 3633 pages (at 2077 pages/min), scraped 3531 items (at 2040 items/min)
2016-11-23 15:23:18 [scrapy] INFO: Closing spider (finished)
2016-11-23 15:23:18 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1402125,
 'downloader/request_count': 4913,
 'downloader/request_method_count/GET': 4913,
 'downloader/response_bytes': 72167689,
 'downloader/response_count': 4913,
 'downloader/response_status_count/200': 4906,
 'downloader/response_status_count/302': 7,
 'dupefilter/filtered': 14,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 11, 23, 7, 23, 18, 601796),
 'item_scraped_count': 4785,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'request_depth_max': 20,
 'response_received_count': 4906,
 'scheduler/dequeued': 4913,
 'scheduler/dequeued/memory': 4913,
 'scheduler/enqueued': 4913,
 'scheduler/enqueued/memory': 4913,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2016, 11, 23, 7, 20, 38, 727607)}
2016-11-23 15:23:18 [scrapy] INFO: Spider closed (finished)
